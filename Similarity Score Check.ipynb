{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789f3796",
   "metadata": {},
   "source": [
    "# Code below import the data from local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "26e367a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5ac0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test data\n",
    "trainInput = pd.read_csv('/Users/eesoonhang/Desktop/capstone_data/train_in.csv')\n",
    "trainOutput = pd.read_csv('/Users/eesoonhang/Desktop/capstone_data/train_out.csv')\n",
    "testInput = pd.read_csv('/Users/eesoonhang/Desktop/capstone_data/test_in.csv')\n",
    "testOutput = pd.read_csv('/Users/eesoonhang/Desktop/capstone_data/test_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b718e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of train data input: (304661, 1001)\n",
      "Dimension of train data output: (304661, 12)\n",
      "Dimension of test data input: (1200, 1001)\n",
      "Dimension of test data output: (1200, 12)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimension\n",
    "print(\"Dimension of train data input: {}\".format(trainInput.shape))\n",
    "print(\"Dimension of train data output: {}\".format(trainOutput.shape))\n",
    "print(\"Dimension of test data input: {}\".format(testInput.shape))\n",
    "print(\"Dimension of test data output: {}\".format(testOutput.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a312736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hAm', 'hCm', 'hGm', 'hTm', 'hm1A', 'hm5C', 'hm5U', 'hm6A', 'hm6Am', 'hm7G', 'hPsi', 'Atol']\n",
      "class hAm : 0.4566%\n",
      "class hCm : 0.5508%\n",
      "class hGm : 0.4172%\n",
      "class hTm : 0.6739%\n",
      "class hm1A : 5.2997%\n",
      "class hm5C : 0.9870%\n",
      "class hm5U : 1.1475%\n",
      "class hm6A : 21.3280%\n",
      "class hm6Am : 0.7375%\n",
      "class hm7G : 0.2744%\n",
      "class hPsi : 0.9640%\n",
      "class Atol : 17.2054%\n",
      "total modified data: 50.0418%\n"
     ]
    }
   ],
   "source": [
    "# extract the modification class\n",
    "modification_class = trainOutput.columns.tolist()\n",
    "print(modification_class)\n",
    "\n",
    "# check the proportion of dataset for each class from trainOutput\n",
    "total_modified_data = 0\n",
    "for cls in modification_class:\n",
    "    modified_data_count = trainOutput[cls].sum()\n",
    "    total_modified_data += modified_data_count\n",
    "    print(\"class %s : %.4f\" %(cls, modified_data_count / trainOutput.shape[0] * 100) + \"%\")\n",
    "print(\"total modified data: %.4f\" %(total_modified_data / trainOutput.shape[0] * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "050dcd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full train dataset: \n",
      "  V1 V2 V3 V4 V5 V6 V7 V8 V9 V10  ...  hGm  hTm hm1A hm5C hm5U hm6A hm6Am  \\\n",
      "0  C  C  C  C  A  T  A  C  C   C  ...  0.0  0.0  0.0  0.0  0.0  0.0   0.0   \n",
      "1  T  C  T  C  C  T  G  C  C   T  ...  0.0  0.0  0.0  0.0  0.0  0.0   0.0   \n",
      "2  C  A  G  A  T  A  G  T  A   A  ...  0.0  0.0  0.0  0.0  0.0  0.0   0.0   \n",
      "3  T  G  T  C  T  T  T  T  A   C  ...  0.0  0.0  0.0  0.0  0.0  0.0   0.0   \n",
      "4  A  T  T  A  C  T  T  A  A   T  ...  0.0  0.0  0.0  0.0  0.0  0.0   0.0   \n",
      "\n",
      "  hm7G hPsi Atol  \n",
      "0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 1013 columns]\n"
     ]
    }
   ],
   "source": [
    "# join the input and output data\n",
    "trainFull = trainInput.join(trainOutput)\n",
    "testFull = testInput.join(testOutput)\n",
    "print(\"full train dataset: \\n\" + str(trainFull.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "98e5261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a target column for easy identification of binary class of the modification class (yes or no)\n",
    "trainFull['target'] = trainFull[modification_class].sum(axis=1)\n",
    "testFull['target'] = testFull[modification_class].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0bb2e2",
   "metadata": {},
   "source": [
    "# Code below make use of modified train dataset to split it into 12 subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "90df65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to split the modified data to 12 sub classes\n",
    "def split_into_12ModifiedClass(data, sub_classes_list):\n",
    "    outputDic = {}\n",
    "    for cls in modification_class:\n",
    "        drop_irrelevant = [c for c in modification_class if c!= cls]\n",
    "        outputDic[cls] = data[data[cls] == 1].drop(columns=drop_irrelevant).rename(columns={cls:\"target\"}) \n",
    "    return outputDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "efa024f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the datasets into 12 subsets of modified classes\n",
    "trainFull_modifiedDic = split_into_12ModifiedClass(trainFull, modification_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "da164a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size for class hAm: 1391\n",
      "Data size for class hCm: 1678\n",
      "Data size for class hGm: 1271\n",
      "Data size for class hTm: 2053\n",
      "Data size for class hm1A: 16146\n",
      "Data size for class hm5C: 3007\n",
      "Data size for class hm5U: 3496\n",
      "Data size for class hm6A: 64978\n",
      "Data size for class hm6Am: 2247\n",
      "Data size for class hm7G: 836\n",
      "Data size for class hPsi: 2937\n",
      "Data size for class Atol: 52418\n"
     ]
    }
   ],
   "source": [
    "# check the size of the subsets\n",
    "for cls in modification_class:\n",
    "    print(\"Data size for class %s: %d\" %(cls, trainFull_dic[cls].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "98fe657d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V994</th>\n",
       "      <th>V995</th>\n",
       "      <th>V996</th>\n",
       "      <th>V997</th>\n",
       "      <th>V998</th>\n",
       "      <th>V999</th>\n",
       "      <th>V1000</th>\n",
       "      <th>V1001</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     V1 V2 V3 V4 V5 V6 V7 V8 V9 V10  ... V994 V995 V996 V997 V998 V999 V1000  \\\n",
       "2782  T  T  T  C  T  T  C  A  T   G  ...    C    T    G    C    C    C     C   \n",
       "2783  C  T  T  T  T  T  T  T  T   T  ...    A    T    G    G    A    G     T   \n",
       "2784  A  G  T  A  G  G  C  C  C   A  ...    C    T    T    T    C    A     T   \n",
       "2785  G  G  G  A  G  G  T  T  T   G  ...    T    G    T    A    T    T     A   \n",
       "2786  G  G  T  C  A  T  G  C  C   T  ...    T    A    A    C    A    A     A   \n",
       "\n",
       "     V1001 target target  \n",
       "2782     C    1.0    1.0  \n",
       "2783     C    1.0    1.0  \n",
       "2784     C    1.0    1.0  \n",
       "2785     A    1.0    1.0  \n",
       "2786     C    1.0    1.0  \n",
       "\n",
       "[5 rows x 1003 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display a sample data\n",
    "df = trainFull_modifiedDic[modification_class[1]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64c20574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the index of the modified-groups based on the 12 subsets formed\n",
    "# this will help to split the entire train dataset into 2 major groups of modified and non-modified\n",
    "index_modifiedData = [v.index.tolist() for k,v in trainFull_modifiedDic.items()]\n",
    "flatten_index_modifiedData = [idx for index_set in index_modifiedData for idx in index_set]\n",
    "len(flatten_index_modifiedData)\n",
    "\n",
    "# split into 2 major groups of data\n",
    "# drop the individual modification class column to reduce the dataset size\n",
    "trainFull_MD = trainFull[trainFull.index.isin(flatten_index_modifiedData)].drop(columns=modification_class).reset_index(drop=True)\n",
    "trainFull_NMD = trainFull[trainFull.index.isin(list(set(trainFull.index)-set(flatten_index_modifiedData)))].drop(columns=modification_class).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "583c243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified dataset size: (152453, 1002)\n",
      "non-modified dataset size: (152208, 1002)\n",
      "total dataset size: 304661\n"
     ]
    }
   ],
   "source": [
    "# check the dimension of data\n",
    "print(\"modified dataset size: \" + str(trainFull_MD.shape))\n",
    "print(\"non-modified dataset size: \" + str(trainFull_NMD.shape))\n",
    "print(\"total dataset size: \" + str(trainFull_MD.shape[0]+ trainFull_NMD.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53855ac5",
   "metadata": {},
   "source": [
    "# Code below run test by randomly picking an input from the test dataset\n",
    "# Then compute #hits based on position-to-position match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e19df55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to visualize statistical data for different sample poolsize (e.g. 100, 1000, 2000, 5000, 10000)\n",
    "def compute_statistical_data(sample_size):\n",
    "    \n",
    "    # randomly pick a test sample for computation purpose\n",
    "    sample_input = testFull.sample(n=1).drop(columns=modification_class)\n",
    "    sample_input_type = \"is modified\" if (sample_input['target'].get('target') == 1) else \"is non-modified\"\n",
    "    print(\"selected test sample \" + sample_input_type)\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # define a dictionary each to hold the hits count against each train sample\n",
    "    hitMD = {}\n",
    "    hitNMD = {}\n",
    "    \n",
    "    sample_MD = []\n",
    "    sample_NMD = []\n",
    "    # check hits count through position-position check\n",
    "    for size in sample_size:\n",
    "        \n",
    "        # randomly create a sample pool for each group\n",
    "        modified_data = trainFull_MD.sample(n=size, replace=False)\n",
    "        non_modified_data = trainFull_NMD.sample(n=size, replace=False)\n",
    "        \n",
    "        # append the data to the sample list\n",
    "        sample_MD.append(modified_data)\n",
    "        sample_NMD.append(non_modified_data)\n",
    "        \n",
    "    # compute the hits statistics against modified pool\n",
    "    print(\"against modified pool:\\n\")    \n",
    "    for data in sample_MD:\n",
    "        size = data.shape[0]\n",
    "        for idx, row in data.iterrows():\n",
    "            hit = 0\n",
    "            for col, data in row.iteritems():\n",
    "                if (col != 'target') & (demo_input[col].values[0] == data):\n",
    "                    hit += 1\n",
    "            hitMD[idx] = hit\n",
    "\n",
    "        top10_hitMD = sorted(hitMD.items(), key=lambda kv : kv[1], reverse=True)[:10]\n",
    "        #print(\"top10 hits:\\n\" + str(top10_hitMD) + \"\\n\")\n",
    "        hitMD_list = [kv[1] for kv in hitMD.items()]\n",
    "        avg_hits = reduce(lambda a,b : a+b, hitMD_list) / len(hitMD_list)\n",
    "        std_hits = np.std(hitMD_list, ddof=1)\n",
    "        print(\"n=%d, \" %size + \"avg hits:%.2f, \" %avg_hits + \"std hits:%.2f \" %std_hits)\n",
    "     \n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    print(\"against non-modified pool:\\n\")\n",
    "    for data in sample_NMD:\n",
    "        size = data.shape[0]\n",
    "        for idx, row in data.iterrows():\n",
    "            hit = 0\n",
    "            for col, data in row.iteritems():\n",
    "                if (col != 'target') & (demo_input[col].values[0] == data):\n",
    "                    hit += 1\n",
    "            hitNMD[idx] = hit\n",
    "\n",
    "        top10_hitNMD = sorted(hitNMD.items(), key=lambda kv : kv[1], reverse=True)[:10]\n",
    "        #print(\"top10 hits:\\n\" + str(top10_hitNMD) + \"\\n\")\n",
    "        hitNMD_list = [kv[1] for kv in hitNMD.items()]\n",
    "        avg_hits = reduce(lambda a,b : a+b, hitNMD_list) / len(hitNMD_list)\n",
    "        std_hits = np.std(hitNMD_list, ddof=1)\n",
    "        print(\"n=%d, \" %size + \"avg hits:%.2f, \" %avg_hits + \"std hits:%.2f\" %std_hits)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "672001ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected test sample is non-modified\n",
      "--------------------------------------------------\n",
      "against modified pool:\n",
      "\n",
      "n=10, avg hits:247.50, std hits:63.84 \n",
      "n=100, avg hits:236.00, std hits:55.43 \n",
      "n=1000, avg hits:232.03, std hits:55.05 \n",
      "n=2000, avg hits:232.99, std hits:54.79 \n",
      "--------------------------------------------------\n",
      "against non-modified pool:\n",
      "\n",
      "n=10, avg hits:194.60, std hits:50.47\n",
      "n=100, avg hits:220.96, std hits:53.18\n",
      "n=1000, avg hits:219.09, std hits:50.68\n",
      "n=2000, avg hits:219.17, std hits:50.81\n"
     ]
    }
   ],
   "source": [
    "# show statistical analysis\n",
    "sample_size = [10, 100, 1000, 2000]\n",
    "compute_statistical_data(sample_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
