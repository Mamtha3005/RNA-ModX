{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca4bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import swifter\n",
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1438face",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "train_X = pd.read_csv('/Users/eesoonhang/Desktop/capstone_data/train_in_encodedToNacSeq.csv', usecols=lambda x: x!= '*Unnamed*')\n",
    "train_y = pd.read_csv('/Users/eesoonhang/Desktop/capstone_data/train_out.csv', usecols=lambda x: x!= '*Unnamed*')\n",
    "test_X = pd.read_csv('/Users/eesoonhang/Desktop/capstone_data/test_in_encodedToNacSeq.csv', usecols=lambda x: x!= '*Unnamed*')\n",
    "test_y = pd.read_csv('/Users/eesoonhang/Desktop/capstone_data/test_out.csv', usecols=lambda x: x!= '*Unnamed*')\n",
    "\n",
    "# split to respective input datasets\n",
    "train_X_nac = train_X.iloc[:, 0:4]\n",
    "train_X_dac = train_X.iloc[:, 4:20]\n",
    "train_X_tac = train_X.iloc[:, 20:]\n",
    "test_X_nac = test_X.iloc[:, 0:4]\n",
    "test_X_dac = test_X.iloc[:, 4:20]\n",
    "test_X_tac = test_X.iloc[:, 20:]\n",
    "\n",
    "# compressed output y\n",
    "# transform target >=1 to 1\n",
    "def normalize_output(x):\n",
    "    return np.where(x.target>1, x.target/x.target, x.target)\n",
    "    \n",
    "# compressed y-variable\n",
    "compressed_train_y = train_y.sum(axis=1).to_frame(name='target')\n",
    "compressed_test_y = test_y.sum(axis=1).to_frame(name='target')\n",
    "compressed_train_y.target = compressed_train_y.swifter.apply(normalize_output, axis=1)\n",
    "compressed_test_y.target = compressed_test_y.swifter.apply(normalize_output, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f59cf",
   "metadata": {},
   "source": [
    "### train without scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e69273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "def train_Model(k='rbf', c=1, g='scale'):\n",
    "    \n",
    "    print('scaling data')\n",
    "    #apply scaler\n",
    "    scaler = StandardScaler()\n",
    "    train_X_scaled = scaler.fit_transform(train_X, compressed_train_y)\n",
    "    train_X_scaled = pd.DataFrame(train_X_scaled, columns=train_X.columns)\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(train_X_scaled, compressed_train_y, test_size = 0.5, random_state = 1234, stratify=compressed_train_y)\n",
    "    \n",
    "    print('selecting feature via RFE..')\n",
    "    # instantiate model\n",
    "    svc = SVC(kernel=k, C=c, gamma=g)\n",
    "    \n",
    "    print('fit model...')\n",
    "    # Perform RandomForestClassification\n",
    "    svc.fit(X_train, Y_train.values.ravel())\n",
    "    y_predict = svc.predict(X_valid)\n",
    "    \n",
    "    print('evaluate model...')\n",
    "#     # print ranking based on rfe\n",
    "#     columns = X_train.columns\n",
    "#     ranking = rfe.ranking_\n",
    "#     rfe_selected = pd.concat([pd.DataFrame(columns), \n",
    "#                               pd.DataFrame(ranking)], axis=1)\n",
    "#     rfe_selected.columns = ['Feature Name', 'Ranking']\n",
    "#     print('rankings: ' + str(ranking) + '\\n' + 'RFE selected features: \\n' + '-'*20 + '\\n' + str(rfe_selected[(rfe_selected.Ranking == 1)]['Feature Name']))\n",
    "\n",
    "    rmse = math.sqrt(mean_squared_error(Y_valid, y_predict))\n",
    "    print('rmse: %4.2f' %rmse)\n",
    "    \n",
    "    score = svc.score(X_valid, Y_valid)\n",
    "    print('score: %4.2f' %score)\n",
    "    \n",
    "    return rmse, score, svc, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a7d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling data\n",
      "selecting feature via RFE..\n",
      "fit model...\n",
      "evaluate model...\n",
      "rmse: 0.50\n",
      "score: 0.75\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_rfe_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sc/sfl3h7fj3252fxyys_m5td0w0000gn/T/ipykernel_3041/1010436373.py\u001b[0m in \u001b[0;36mtrain_Model\u001b[0;34m(k, c, g)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score: %4.2f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mn_rfe_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n_rfe_features' is not defined"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "%time model = train_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "import pickle \n",
    "pickle.dump(model[2], open('/Users/eesoonhang/Desktop/capstone_data/SVC_ovo_withScaler.pkl', 'wb'))\n",
    "pickle.dump(model[3], open('/Users/eesoonhang/Desktop/capstone_data/SVC_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy\n",
    "clf = model[3]\n",
    "scaler = model[4]\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "clf.score(test_X_scaled, compressed_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ec587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cfm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# visualize confusion matrix\n",
    "cnf_matrix = cfm(compressed_test_y, clf.predict(rfe_test_X)) \n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots() \n",
    "tick_marks = np.arange(len(class_names)) \n",
    "plt.xticks(tick_marks, class_names) \n",
    "plt.yticks(tick_marks, class_names) \n",
    "\n",
    "# create heatmap \n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g') \n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "plt.tight_layout() \n",
    "plt.title('Confusion matrix for SVC_ovo & RFE with 33 selected features', y=1.1) \n",
    "plt.ylabel('Actual label') \n",
    "plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
