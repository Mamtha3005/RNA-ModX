{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkDJ1UJK69ON",
    "outputId": "c1eec5ea-65de-40a5-9c79-41a472c445ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gensim\n",
      "  Downloading gensim-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xgboost\n",
      "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cmaes>=0.10.0\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0)\n",
      "Collecting sqlalchemy>=1.3.0\n",
      "  Downloading SQLAlchemy-2.0.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.24.3)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.11.2-py3-none-any.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (23.0)\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing<3.1,>=2.3.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.7/613.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: tzdata, threadpoolctl, smart-open, scipy, pyparsing, Mako, kiwisolver, joblib, greenlet, fonttools, cycler, contourpy, colorlog, cmaes, xgboost, sqlalchemy, scikit-learn, pandas, matplotlib, gensim, imbalanced-learn, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.11.2 cmaes-0.10.0 colorlog-6.7.0 contourpy-1.1.0 cycler-0.11.0 fonttools-4.42.0 gensim-4.3.1 greenlet-2.0.2 imbalanced-learn-0.11.0 joblib-1.3.2 kiwisolver-1.4.4 matplotlib-3.7.2 optuna-3.3.0 pandas-2.0.3 pyparsing-3.0.9 scikit-learn-1.3.0 scipy-1.11.1 smart-open-6.3.0 sqlalchemy-2.0.19 threadpoolctl-3.2.0 tzdata-2023.3 xgboost-1.7.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install optuna  scikit-learn gensim imbalanced-learn xgboost torch pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ohWCGHSq5BVM"
   },
   "outputs": [],
   "source": [
    " #Import All Libraries Here\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score ,  roc_curve, auc , classification_report\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time\n",
    "from collections import Counter\n",
    "# PyTorch Import\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "\n",
    "WINDOW_SIZE = 50\n",
    "\n",
    "# 1 - One Hot Encoding with Pytorch in build Emnedding\n",
    "# 2 - 3-mer coding with number encoding\n",
    "ENCODING_METHOD = 2\n",
    "\n",
    "# 1- Random Over Sampling\n",
    "# 2 - Weighted Over Sampler\n",
    "SAMPLING_METHOD =1\n",
    "\n",
    "# 1 - LSTM with Cross Entropy\n",
    "MODEL = 1\n",
    "\n",
    "\n",
    "FRAMEWORK = \"PYTORCH\"\n",
    "\n",
    "# Startegy to Crop Sequene\n",
    "# MID - Modification is present at Mid of cropped Sequence\n",
    "# END - Modification is present at End of cropepd Sequence\n",
    "CROP_STRATEGY = 'MID'\n",
    "\n",
    "# Y Category Encoding Method\n",
    "# LABEL or ONE_HOT\n",
    "TARGET_ENCODING = 'LABEL'\n",
    "\n",
    "ENCODING_FILE = '3-mer-dictionary.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQvMm5lH5BVO",
    "outputId": "442f7e0b-129a-4add-f95e-c353acecda48"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# INPUT_TRAIN_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/train_in.csv\"\n",
    "# INPUT_TRAIN_OUT = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/train_out.csv\"\n",
    "# INPUT_TEST_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/test_in.csv\"\n",
    "# INPUT_TEST_OUT = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/test_out.csv\"\n",
    "# INPUT_VALIDATION_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/valid_in_nucleo.csv\"\n",
    "# INPUT_VALIDATION_OUT  = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/valid_out.csv\"\n",
    "\n",
    "# Record Constants\n",
    "# Record Constants\n",
    "INPUT_TRAIN_IN = \"train_in.csv\"\n",
    "INPUT_TRAIN_OUT = \"train_out.csv\"\n",
    "INPUT_TEST_IN = \"test_in.csv\"\n",
    "INPUT_TEST_OUT = \"test_out.csv\"\n",
    "INPUT_VALIDATION_IN = \"valid_in_nucleo.csv\"\n",
    "INPUT_VALIDATION_OUT  = \"valid_out.csv\"\n",
    "\n",
    "# TARGET_MODEL_PATH = '../../webapp/model_files'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcUOufcj5BVO",
    "outputId": "10cc65ec-1618-4a0f-dcc7-0727a3a71f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape of X : (304661, 1001) and Tranin Shape of Y : (304661, 1001)\n",
      "Test Shape of X : (1200, 1001) and Test Shape of Y : (1200, 12)\n",
      "Validation Shape of X : (3599, 1001) and Validation Shape of Y : (3599, 12)\n"
     ]
    }
   ],
   "source": [
    "#Read X Varaibles and Y Varaibles\n",
    "\n",
    "x_train_raw =  pd.read_csv(INPUT_TRAIN_IN, header=None , skiprows=1 )\n",
    "y_train_raw =  pd.read_csv(INPUT_TRAIN_OUT, header=None , skiprows=1 )\n",
    "\n",
    "x_test_raw =  pd.read_csv(INPUT_TEST_IN, header=None , skiprows=1 )\n",
    "y_test_raw =  pd.read_csv(INPUT_TEST_OUT, header=None , skiprows=1)\n",
    "\n",
    "x_valid_raw =  pd.read_csv(INPUT_VALIDATION_IN, header=None , skiprows=1 )\n",
    "y_valid_raw =  pd.read_csv(INPUT_VALIDATION_OUT, header=None , skiprows=1 )\n",
    "\n",
    "x_data = pd.concat([x_train_raw, x_test_raw, x_valid_raw], axis=0, ignore_index=True)\n",
    "y_data = pd.concat([y_train_raw, y_test_raw, y_valid_raw], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Train Shape of X : {x_train_raw.shape} and Tranin Shape of Y : {x_train_raw.shape}\")\n",
    "print(f\"Test Shape of X : {x_test_raw.shape} and Test Shape of Y : {y_test_raw.shape}\")\n",
    "print(f\"Validation Shape of X : {x_valid_raw.shape} and Validation Shape of Y : {y_valid_raw.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwZ2AFCo5BVO"
   },
   "source": [
    "### Calculate Sequence Positions to extracted from Original Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uWqxeK7J5BVP"
   },
   "outputs": [],
   "source": [
    "middle_index = (x_train_raw.shape[1] // 2) + 1 # This is location for Modified Sequence . Use this as Y Target\n",
    "\n",
    "if CROP_STRATEGY == 'MID':\n",
    "    STRAT_INEDX =middle_index - WINDOW_SIZE -1\n",
    "    END_INDEX =middle_index + WINDOW_SIZE\n",
    "\n",
    "if CROP_STRATEGY == 'END':\n",
    "    STRAT_INEDX =middle_index - (WINDOW_SIZE*2) -1\n",
    "    END_INDEX =middle_index\n",
    "\n",
    "x_data_cropped =  x_data.iloc[:,STRAT_INEDX :END_INDEX]\n",
    "concatenated_column= x_data_cropped.apply(lambda row: ''.join(map(str, row)), axis=1)\n",
    "x_data_cropped = x_data_cropped.assign(Sequence=concatenated_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "jRDnwbiM5BVP",
    "outputId": "0d007b12-6da3-4cca-814a-57e8a3c5e5ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>...</th>\n",
       "      <th>542</th>\n",
       "      <th>543</th>\n",
       "      <th>544</th>\n",
       "      <th>545</th>\n",
       "      <th>546</th>\n",
       "      <th>547</th>\n",
       "      <th>548</th>\n",
       "      <th>549</th>\n",
       "      <th>550</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>TTGCCACACTGCTGGACGCCTGCAAGGCCAAGGGTACGGAGGTCAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>TTTGAAAAAATATTAGCAATGTGAGGACACTTAAGCAGTTTTGTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>AGAAACATTCAACCTCCCTTCTTTTTATTCCAGTTGTCCTTTTCTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>TTAGTTTTACTATGGAATCATAATAACCCACATAGAAGACTGATAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>CAACAGAAGTTTCTCATCTATAATCAGTAGCACTAAACTCTTGGTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309455</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>CCAAACTCTTTATCTCTTGAGTTCTCAGCCAATAGGGCCATTGTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309456</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>GATCCAGTTGAAAACGTATCCCTCTACTTTCTTCAGTTGTAGAAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309457</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>GCCAGGGCAAAGCTGGCTGATTTTACGTGTTTAAGGATGAAATATC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309458</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>CTGGGTGCGACAGGCCACTGGACAAGGGCTTGAGTGGATGGGATGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309459</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>GGCTGCTAAGGCAATGTGCTCTCCTAATTTCCCTTTTTCCTTTGTG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309460 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       450 451 452 453 454 455 456 457 458 459  ... 542 543 544 545 546 547  \\\n",
       "0        T   T   G   C   C   A   C   A   C   T  ...   C   A   G   T   A   T   \n",
       "1        T   T   T   G   A   A   A   A   A   A  ...   T   C   A   T   C   G   \n",
       "2        A   G   A   A   A   C   A   T   T   C  ...   T   T   C   T   G   T   \n",
       "3        T   T   A   G   T   T   T   T   A   C  ...   A   A   A   A   A   T   \n",
       "4        C   A   A   C   A   G   A   A   G   T  ...   A   A   A   A   T   G   \n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "309455   C   C   A   A   A   C   T   C   T   T  ...   G   G   G   C   A   G   \n",
       "309456   G   A   T   C   C   A   G   T   T   G  ...   A   C   A   G   G   T   \n",
       "309457   G   C   C   A   G   G   G   C   A   A  ...   C   A   A   G   C   T   \n",
       "309458   C   T   G   G   G   T   G   C   G   A  ...   G   C   A   G   A   G   \n",
       "309459   G   G   C   T   G   C   T   A   A   G  ...   C   T   C   A   A   A   \n",
       "\n",
       "       548 549 550                                           Sequence  \n",
       "0        C   T   C  TTGCCACACTGCTGGACGCCTGCAAGGCCAAGGGTACGGAGGTCAT...  \n",
       "1        T   G   C  TTTGAAAAAATATTAGCAATGTGAGGACACTTAAGCAGTTTTGTCA...  \n",
       "2        T   C   A  AGAAACATTCAACCTCCCTTCTTTTTATTCCAGTTGTCCTTTTCTC...  \n",
       "3        T   T   C  TTAGTTTTACTATGGAATCATAATAACCCACATAGAAGACTGATAT...  \n",
       "4        T   A   C  CAACAGAAGTTTCTCATCTATAATCAGTAGCACTAAACTCTTGGTT...  \n",
       "...     ..  ..  ..                                                ...  \n",
       "309455   A   G   A  CCAAACTCTTTATCTCTTGAGTTCTCAGCCAATAGGGCCATTGTAG...  \n",
       "309456   A   A   T  GATCCAGTTGAAAACGTATCCCTCTACTTTCTTCAGTTGTAGAAAA...  \n",
       "309457   G   A   T  GCCAGGGCAAAGCTGGCTGATTTTACGTGTTTAAGGATGAAATATC...  \n",
       "309458   T   C   A  CTGGGTGCGACAGGCCACTGGACAAGGGCTTGAGTGGATGGGATGG...  \n",
       "309459   C   G   A  GGCTGCTAAGGCAATGTGCTCTCCTAATTTCCCTTTTTCCTTTGTG...  \n",
       "\n",
       "[309460 rows x 102 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KLuiCU2X5BVP"
   },
   "outputs": [],
   "source": [
    "x_train_raw = None\n",
    "y_train_raw = None\n",
    "x_test_raw = None\n",
    "y_test_raw = None\n",
    "x_valid_raw = None\n",
    "y_valid_raw = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIM49qM75BVP"
   },
   "source": [
    "### Apply One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tf17dHN95BVP"
   },
   "outputs": [],
   "source": [
    "number_of_unique_kmers = set()\n",
    "def encode_seq(kmer_token):\n",
    "\n",
    "    # A 1 0 0 0\n",
    "    # C 0 1 0 0\n",
    "    # T/U 0 0 0 1\n",
    "    # G 0 0 1 0\n",
    "    # N 0 0 0 0\n",
    "\n",
    "    encoding_dict = {\n",
    "        'A': [1, 0, 0, 0],\n",
    "        'C': [0, 1, 0, 0],\n",
    "        'G': [0, 0, 1, 0],\n",
    "        'T': [0, 0, 0, 1],\n",
    "        'U': [0, 0, 0, 1],\n",
    "        'N': [0, 0, 0, 0],\n",
    "    }\n",
    "\n",
    "    encoded_sequence = []\n",
    "    number_of_unique_kmers.add(kmer_token)\n",
    "    for  base in kmer_token:\n",
    "        encoded_sequence.append(encoding_dict[base])\n",
    "    return np.array(encoded_sequence).flatten()\n",
    "\n",
    "def applyOneHotEncoding(tokenized_sequences):\n",
    "    encoded_sequences = []\n",
    "    for seq in tokenized_sequences:\n",
    "        encoded_sequences.append(encode_seq(seq))\n",
    "\n",
    "    return np.array(encoded_sequences).flatten()\n",
    "\n",
    "def encode_with_one_hot_encoding(x_train_raw):\n",
    "    truncated_df =  x_train_raw.iloc[:,STRAT_INEDX :END_INDEX] # Window Starts from V501 with 50 window size\n",
    "    concatenated_column= truncated_df.apply(lambda row: ''.join(map(str, row)), axis=1)\n",
    "    df_result = truncated_df.assign(Sequence=concatenated_column)\n",
    "    tokenized_sequences =  df_result['Sequence'].apply(applyOneHotEncoding).tolist()\n",
    "\n",
    "    return tokenized_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk_WaSe35BVP"
   },
   "source": [
    "### 3 mer coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JwIzW5gY5BVQ"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "kmer_dict = {}\n",
    "k = 3\n",
    "with open(ENCODING_FILE, 'rb') as f:\n",
    "    kmer_dict = pickle.load(f)\n",
    "\n",
    "\n",
    "def encode_with_k_mer_codon(sequence):\n",
    "    #print(sequence)\n",
    "    encoded_sequence = []\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        if sequence[i:i+k] not in kmer_dict:\n",
    "            print(\"Key Not Found\" , kmer_dict)\n",
    "        encoded_sequence.append(kmer_dict[sequence[i:i+k]] )\n",
    "    return np.array(encoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ds7NWJtl5BVQ"
   },
   "outputs": [],
   "source": [
    "## Filter Dataset to Keep only Target Binary Class\n",
    "\n",
    "RMs = ['hAm','hCm','hGm','hTm','hm1A','hm5C','hm5U','hm6A','hm6Am','hm7G','hPsi','Atol','NonMoD']\n",
    "RMEncoding = [12,1,2,3,4,5,6,7,8,9,10,11,0]\n",
    "\n",
    "eligible_class_list = ['hm5C', 'hCm']\n",
    "ARMEncoding = [0,1]\n",
    "\n",
    "def convert_y_to_original_labels(row):\n",
    "    label = \"\"  \n",
    "    for index , n in enumerate(row.tolist()) :\n",
    "        if n == 1 :\n",
    "            label = RMs[index]\n",
    "    if label == '':\n",
    "        return 'NonMoD'\n",
    "    return label\n",
    "\n",
    "def get_original_y_lables( y_data ):\n",
    "    # Convert One Hot Encoded Y to to Original Labels\n",
    "    y_original_labels = y_data.apply(convert_y_to_original_labels,axis=1)\n",
    "    return y_original_labels\n",
    "\n",
    "\n",
    "\n",
    "def encode_target(y_data):\n",
    "    # Write Customer Lable Encoder . This is required since we have train and test alreday splitted. Always creating a new instanc of label encoder will change encoding.\n",
    "\n",
    "    y_encoded = []\n",
    "    for y in y_data:\n",
    "        index = eligible_class_list.index(y)\n",
    "        encoding =  ARMEncoding[index]\n",
    "        y_encoded.append(encoding)\n",
    "    return y_encoded\n",
    "\n",
    "def prepare_data_for_binary_classification(x_data , y_data , prediction_class):\n",
    "    # Convert One Hot Encoded Y to to Original Labels\n",
    "    y_original_labels = y_data.apply(convert_y_to_original_labels,axis=1)\n",
    "    x_data['Label'] = y_original_labels\n",
    "\n",
    "    selected_rna_data = x_data[x_data['Label'].isin(prediction_class)]\n",
    "\n",
    "    y_filtered = selected_rna_data['Label']\n",
    "    x_filtered = selected_rna_data.drop('Label', axis=1)\n",
    "\n",
    "    return x_filtered , y_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zJEu1A4c5BVQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_data_filtered , y_data_filtered = prepare_data_for_binary_classification(x_data_cropped , y_data , eligible_class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akLbxB6z5BVQ",
    "outputId": "faaf160a-ff4f-4f06-f16d-29667a37b997"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>...</th>\n",
       "      <th>542</th>\n",
       "      <th>543</th>\n",
       "      <th>544</th>\n",
       "      <th>545</th>\n",
       "      <th>546</th>\n",
       "      <th>547</th>\n",
       "      <th>548</th>\n",
       "      <th>549</th>\n",
       "      <th>550</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>TTTTAACACAATACTTTAATAAGACACATTTAAACTCAACTTCTGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>CCTTTGGGGGGCTAATAGCTCCTATATTCATTCAAAGAAGGAATAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>GGCGCAGGGAAGAGGAAGCGGAGGCACTCGGAAGGTAAGTGGCTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>AATTATTTTTTTAGGGCCGGGCGCGGTGGCTCACGTCTGTAATCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>TGTATTTTTCATGTATGGCCTTTATCATGTTGAGTAAGTTTCTTTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>TCTGTTGTCATCCTATCATTGACCTGAGATACCAGAGATCGCCAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>GGAAAGAGAACACACACCCCAGGTGTCATGCACACCCTCGGAAGAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>TTTGGAAAAAGAGATATCCTAGCTCAGGGCAAGCCGTTTGATGGAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>TTCAAGCGATTCTCCTGCCTCAGCCTCCCGAGTAGCTGGGATTACA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>CTGAGCCCAGCACAGCACCAGAGCTTACCCAAGAATTGCAGTTCTT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5085 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       450 451 452 453 454 455 456 457 458 459  ... 542 543 544 545 546 547  \\\n",
       "2782     T   T   T   T   A   A   C   A   C   A  ...   T   T   T   T   T   T   \n",
       "2783     C   C   T   T   T   G   G   G   G   G  ...   A   A   C   A   G   A   \n",
       "2784     G   G   C   G   C   A   G   G   G   A  ...   G   G   A   T   A   T   \n",
       "2785     A   A   T   T   A   T   T   T   T   T  ...   C   G   A   G   A   C   \n",
       "2786     T   G   T   A   T   T   T   T   T   C  ...   A   T   T   T   C   T   \n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "307506   T   C   T   G   T   T   G   T   C   A  ...   G   T   C   T   G   A   \n",
       "307507   G   G   A   A   A   G   A   G   A   A  ...   T   G   T   G   C   A   \n",
       "307508   T   T   T   G   G   A   A   A   A   A  ...   A   G   A   G   G   G   \n",
       "307509   T   T   C   A   A   G   C   G   A   T  ...   C   A   G   G   G   T   \n",
       "307510   C   T   G   A   G   C   C   C   A   G  ...   T   T   G   C   C   C   \n",
       "\n",
       "       548 549 550                                           Sequence  \n",
       "2782     T   G   A  TTTTAACACAATACTTTAATAAGACACATTTAAACTCAACTTCTGA...  \n",
       "2783     T   C   T  CCTTTGGGGGGCTAATAGCTCCTATATTCATTCAAAGAAGGAATAG...  \n",
       "2784     T   T   A  GGCGCAGGGAAGAGGAAGCGGAGGCACTCGGAAGGTAAGTGGCTAG...  \n",
       "2785     C   A   T  AATTATTTTTTTAGGGCCGGGCGCGGTGGCTCACGTCTGTAATCCC...  \n",
       "2786     T   G   C  TGTATTTTTCATGTATGGCCTTTATCATGTTGAGTAAGTTTCTTTC...  \n",
       "...     ..  ..  ..                                                ...  \n",
       "307506   T   T   T  TCTGTTGTCATCCTATCATTGACCTGAGATACCAGAGATCGCCAAA...  \n",
       "307507   G   A   G  GGAAAGAGAACACACACCCCAGGTGTCATGCACACCCTCGGAAGAC...  \n",
       "307508   C   C   A  TTTGGAAAAAGAGATATCCTAGCTCAGGGCAAGCCGTTTGATGGAA...  \n",
       "307509   T   T   C  TTCAAGCGATTCTCCTGCCTCAGCCTCCCGAGTAGCTGGGATTACA...  \n",
       "307510   A   T   G  CTGAGCCCAGCACAGCACCAGAGCTTACCCAAGAATTGCAGTTCTT...  \n",
       "\n",
       "[5085 rows x 102 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "hm5C    3207\n",
       "hCm     1878\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_filtered.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "EJjCTy9m5BVQ",
    "outputId": "a5b4a34b-0f23-4ff6-cb26-b9aa16851f7e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAIjCAYAAAD1OgEdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABBiUlEQVR4nO3deVhV5f7//9cWAccNmkwmKphzqEmlZJomgYaViXksS3NqAkspNU/O1bFjOWROdTpmnSOnsjJNTyJiZiXOkUPqV02zUsAh2A4JCuv3x/mxP21xArndIM/Hda3rcq/7vdZ637Avdq/WsG2WZVkCAAAAAJSoCu5uAAAAAACuR4QtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQC4jhw4cEA2m03z5893dys4z7/+9S81adJEnp6e8vX1dXc7LgreN2+88YbxY/DeBFCeELYAwE3uv/9+ValSRSdOnLhoTZ8+feTl5aVjx45dw86uTz/++KPGjx+vAwcOXPNj79q1S48//rgaNGigf/zjH3rnnXeueQ8AgGuPsAUAbtKnTx/98ccfWrRo0QXHT58+rcWLF6tLly664YYbrnF3158ff/xREyZMcEvYWr16tfLz8/Xmm2/q8ccfV69eva55DwCAa4+wBQBucv/996t69epKTEy84PjixYt16tQp9enT5xp3hpKWmZkpSaXu8kEAgFmELQBwk8qVK6tHjx5KSUlx/sf4nyUmJqp69eq6//77dfz4cb3wwgsKCwtTtWrVZLfb1bVrV/3www+XPU7Hjh3VsWPHQusff/xx1a9f32Vdfn6+pk+frubNm6tSpUoKCAjQk08+qd9///2K5rRr1y716tVLfn5+qly5sho3bqyXXnrJpeb7779X165dZbfbVa1aNXXu3Fnr1q1zqRk/frxsNluh/c+fP182m83l7FT9+vXVrVs3ffvtt7r99ttVqVIlhYaG6oMPPnDZ7qGHHpIkderUSTabTTabTatXr5Ykbdq0SdHR0apVq5YqV66skJAQDRgw4IrmPHv2bDVv3lze3t6qXbu24uLilJWV5dLfuHHjJEl+fn6y2WwaP378Jfe5a9cu9ezZUzVr1lSlSpV06623asmSJS41RXlPnDlzRuPHj1ejRo1UqVIlBQUFqUePHtq3b1+h2nfeeUcNGjSQt7e3brvtNm3cuPGKfg5ZWVkaNmyY6tevL29vb9WpU0d9+/bV0aNHL7rN1q1b9fjjjys0NFSVKlVSYGCgBgwYUOiy2RMnTmjo0KHOffv7++uee+7Rli1bnDV79uxRbGysAgMDValSJdWpU0e9e/dWdnb2FfUPACZUdHcDAFCe9enTR++//74+/vhjxcfHO9cfP35cSUlJevjhh1W5cmXt2LFDn3/+uR566CGFhIQoIyNDb7/9tu666y79+OOPql27don08+STT2r+/Pnq37+/nn32We3fv18zZ87U999/r++++06enp4X3Xbr1q1q3769PD099cQTT6h+/frat2+fvvjiC7366quSpB07dqh9+/ay2+0aMWKEPD099fbbb6tjx476+uuv1aZNm2L1vXfvXvXs2VMDBw5Uv379NG/ePD3++OMKDw9X8+bN1aFDBz377LOaMWOG/vrXv6pp06aSpKZNmyozM1NRUVHy8/PTiy++KF9fXx04cECfffbZZY87fvx4TZgwQZGRkXr66ae1e/duzZkzRxs3bnT+vKZPn64PPvhAixYt0pw5c1StWjW1aNHiovvcsWOH2rVrpxtvvFEvvviiqlatqo8//ljdu3fXp59+qgcffFCS9NNPP13ReyIvL0/dunVTSkqKevfureeee04nTpxQcnKytm/frgYNGjiPnZiYqBMnTujJJ5+UzWbT5MmT1aNHD/3000+X/N2fPHlS7du3186dOzVgwAC1bt1aR48e1ZIlS/Trr7+qVq1aF9wuOTlZP/30k/r376/AwEDt2LFD77zzjnbs2KF169Y5A/dTTz2lTz75RPHx8WrWrJmOHTumb7/9Vjt37lTr1q2Vm5ur6Oho5eTkaMiQIQoMDNRvv/2mpUuXKisrSz4+Ppf9XQKAERYAwG3OnTtnBQUFWRERES7r586da0mykpKSLMuyrDNnzlh5eXkuNfv377e8vb2tiRMnuqyTZL333nvOdXfddZd11113FTp2v379rHr16jlff/PNN5Yka8GCBS51y5cvv+D683Xo0MGqXr269fPPP7usz8/Pd/67e/fulpeXl7Vv3z7nukOHDlnVq1e3OnTo4Fw3btw460IfUe+9954lydq/f79zXb169SxJ1po1a5zrMjMzLW9vb+v55593rlu4cKElyfrqq69c9rlo0SJLkrVx48ZLzu98mZmZlpeXlxUVFeXyu5k5c6YlyZo3b16h+Rw5cuSy++3cubMVFhZmnTlzxrkuPz/fuuOOO6yGDRs6113pe2LevHmWJGvq1KmFjlXwuyl439xwww3W8ePHneOLFy+2JFlffPHFJXseO3asJcn67LPPLnuMP783T58+Xaj+P//5T6Hfp4+PjxUXF3fR43///feWJGvhwoWX7BMArjUuIwQAN/Lw8FDv3r2VmprqcmlcYmKiAgIC1LlzZ0mSt7e3KlT435/svLw8HTt2TNWqVVPjxo1dLqW6GgsXLpSPj4/uueceHT161LmEh4erWrVq+uqrry667ZEjR7RmzRoNGDBAdevWdRkrODuRl5enFStWqHv37goNDXWOBwUF6ZFHHtG3334rh8NRrN6bNWum9u3bO1/7+fmpcePG+umnny67bcF9VEuXLtXZs2ev+JgrV65Ubm6uhg4d6vzdSNLgwYNlt9u1bNmyK5/A/+/48eNatWqVevXqpRMnTjh/B8eOHVN0dLT27Nmj3377TdKVvyc+/fRT1apVS0OGDCl0vPMv1fzLX/6iGjVqOF8X/Ewv93P89NNP1bJlS+dZt0sd488qV67s/PeZM2d09OhRtW3bVpJc5uDr66v169fr0KFDF9xPwZmrpKQknT59+pK9AsC1RNgCADcreABGwYMyfv31V33zzTfq3bu3PDw8JP3vXqpp06apYcOG8vb2Vq1ateTn56etW7eW2D0pe/bsUXZ2tvz9/eXn5+eynDx58oL3lRUo+I/xm2+++aI1R44c0enTp9W4ceNCY02bNlV+fr5++eWXYvV+fsCTpBo1alzRvWZ33XWXYmNjNWHCBNWqVUsPPPCA3nvvPeXk5Fxyu59//lmSCs3Hy8tLoaGhzvGi2Lt3ryzL0pgxYwr9Dgru+yr4PVzpe2Lfvn1q3LixKla8/J0D5/8cC4LX5X6O+/btu+Tv/mKOHz+u5557TgEBAapcubL8/PwUEhIiSS5zmDx5srZv367g4GDdfvvtGj9+vEsADAkJUUJCgt59913VqlVL0dHRmjVrFvdrAXA77tkCADcLDw9XkyZN9J///Ed//etf9Z///EeWZbk8hfBvf/ubxowZowEDBujll19WzZo1VaFCBQ0dOlT5+fmX3L/NZpNlWYXW5+XlubzOz8+Xv7+/FixYcMH9+Pn5FWN2xXOxsyHn91ygIJSe70LzvtCxPvnkE61bt05ffPGFkpKSNGDAAE2ZMkXr1q1TtWrVrrzxq1Twu3zhhRcUHR19wZqbbrpJ0tW9Jy7man6OxdGrVy+tXbtWw4cPV6tWrVStWjXl5+erS5cuLnPo1auX2rdvr0WLFmnFihV6/fXX9fe//12fffaZunbtKkmaMmWKHn/8cS1evFgrVqzQs88+q0mTJmndunWqU6eOkf4B4HIIWwBQCvTp00djxozR1q1blZiYqIYNG+q2225zjn/yySfq1KmT/vnPf7psl5WVddGHDxSoUaPGBS8DO//MS4MGDbRy5Uq1a9fO5fKuK1FwWeD27dsvWuPn56cqVapo9+7dhcZ27dqlChUqKDg42Nmz9L/5/flx6cU5W1TgUpezSVLbtm3Vtm1bvfrqq0pMTFSfPn304YcfatCgQResr1evniRp9+7dLpdF5ubmav/+/YqMjCxyjwX78fT0vOz2V/qeaNCggdavX6+zZ89e8iEXV6NBgwaX/N1fyO+//66UlBRNmDBBY8eOda7fs2fPBeuDgoL0zDPP6JlnnlFmZqZat26tV1991Rm2JCksLExhYWEaPXq01q5dq3bt2mnu3Ll65ZVXijcxALhKXEYIAKVAwVmssWPHKi0trdB3a3l4eBQ6u7Bw4ULn/TuX0qBBA+3atUtHjhxxrvvhhx/03XffudT16tVLeXl5evnllwvt49y5cy6PMz+fn5+fOnTooHnz5ungwYMuYwV9e3h4KCoqSosXL3a5Py0jI0OJiYm68847ZbfbnT1L0po1a5x1p06d0vvvv3/Z+V5M1apVJanQPH7//fdCP9tWrVpJ0iUvJYyMjJSXl5dmzJjhsv0///lPZWdnKyYmpsg9+vv7q2PHjnr77bd1+PDhQuN//h1e6XsiNjZWR48e1cyZMwvtr6TOWMXGxuqHH3644Bd0X+wYBWfRzh+fPn26y+u8vLxClwP6+/urdu3azt+Pw+HQuXPnXGrCwsJUoUKFy14OCgAmcWYLAEqBkJAQ3XHHHVq8eLEkFQpb3bp108SJE9W/f3/dcccd2rZtmxYsWOByRuViBgwYoKlTpyo6OloDBw5UZmam5s6dq+bNm7s8kOKuu+7Sk08+qUmTJiktLU1RUVHy9PTUnj17tHDhQr355pvq2bPnRY8zY8YM3XnnnWrdurWeeOIJhYSE6MCBA1q2bJnS0tIkSa+88oqSk5N155136plnnlHFihX19ttvKycnR5MnT3buKyoqSnXr1tXAgQM1fPhweXh4aN68efLz8ysU5q5Uq1at5OHhob///e/Kzs6Wt7e37r77biUmJmr27Nl68MEH1aBBA504cUL/+Mc/ZLfbde+99150f35+fho1apQmTJigLl266P7779fu3bs1e/Zs3XbbbXr00UeL1eesWbN05513KiwsTIMHD1ZoaKgyMjKUmpqqX3/91fk9Wlf6nujbt68++OADJSQkaMOGDWrfvr1OnTqllStX6plnntEDDzxQrD7/bPjw4frkk0/00EMPacCAAQoPD9fx48e1ZMkSzZ07Vy1btiy0jd1uV4cOHTR58mSdPXtWN954o1asWKH9+/e71J04cUJ16tRRz5491bJlS1WrVk0rV67Uxo0bNWXKFEnSqlWrFB8fr4ceekiNGjXSuXPn9K9//UseHh6KjY296vkBQLG55RmIAIBCZs2aZUmybr/99kJjZ86csZ5//nkrKCjIqly5stWuXTsrNTW10GPdL/R4bcuyrH//+99WaGio5eXlZbVq1cpKSkoq9Oj3Au+8844VHh5uVa5c2apevboVFhZmjRgxwjp06NBl57B9+3brwQcftHx9fa1KlSpZjRs3tsaMGeNSs2XLFis6OtqqVq2aVaVKFatTp07W2rVrC+1r8+bNVps2bSwvLy+rbt261tSpUy/66PeYmJhC21/okff/+Mc/rNDQUMvDw8P5GPgtW7ZYDz/8sFW3bl3L29vb8vf3t7p162Zt2rTpsvO1rP896r1JkyaWp6enFRAQYD399NPW77//7lJTlEe/W5Zl7du3z+rbt68VGBhoeXp6WjfeeKPVrVs365NPPnHWXOl7wrL+94j1l156yQoJCbE8PT2twMBAq2fPns5H8Be8b15//fVCvUiyxo0bd9mejx07ZsXHx1s33nij5eXlZdWpU8fq16+fdfToUZdj/Pm9+euvvzrfLz4+PtZDDz1kHTp0yOWYOTk51vDhw62WLVta1atXt6pWrWq1bNnSmj17tnM/P/30kzVgwACrQYMGVqVKlayaNWtanTp1slauXHlFP28AMMVmWYbuegUAAACAcox7tgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABfKnxFcjPz9ehQ4dUvXp12Ww2d7cDAAAAwE0sy9KJEydUu3ZtVahw6XNXhK0rcOjQIQUHB7u7DQAAAAClxC+//KI6depcsoawdQWqV68u6X8/ULvd7uZuAAAAALiLw+FQcHCwMyNcCmHrChRcOmi32wlbAAAAAK7o9iIekAEAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYUNHdDaB46r+4zN0tAIAxB16LcXcLAABcNc5sAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGCAW8PWnDlz1KJFC9ntdtntdkVEROjLL790jp85c0ZxcXG64YYbVK1aNcXGxiojI8NlHwcPHlRMTIyqVKkif39/DR8+XOfOnXOpWb16tVq3bi1vb2/ddNNNmj9//rWYHgAAAIByzK1hq06dOnrttde0efNmbdq0SXfffbceeOAB7dixQ5I0bNgwffHFF1q4cKG+/vprHTp0SD169HBun5eXp5iYGOXm5mrt2rV6//33NX/+fI0dO9ZZs3//fsXExKhTp05KS0vT0KFDNWjQICUlJV3z+QIAAAAoP2yWZVnubuLPatasqddff109e/aUn5+fEhMT1bNnT0nSrl271LRpU6Wmpqpt27b68ssv1a1bNx06dEgBAQGSpLlz52rkyJE6cuSIvLy8NHLkSC1btkzbt293HqN3797KysrS8uXLr6gnh8MhHx8fZWdny263l/yki6H+i8vc3QIAGHPgtRh3twAAwAUVJRuUmnu28vLy9OGHH+rUqVOKiIjQ5s2bdfbsWUVGRjprmjRporp16yo1NVWSlJqaqrCwMGfQkqTo6Gg5HA7n2bHU1FSXfRTUFOzjQnJycuRwOFwWAAAAACgKt4etbdu2qVq1avL29tZTTz2lRYsWqVmzZkpPT5eXl5d8fX1d6gMCApSeni5JSk9PdwlaBeMFY5eqcTgc+uOPPy7Y06RJk+Tj4+NcgoODS2KqAAAAAMoRt4etxo0bKy0tTevXr9fTTz+tfv366ccff3RrT6NGjVJ2drZz+eWXX9zaDwAAAICyp6K7G/Dy8tJNN90kSQoPD9fGjRv15ptv6i9/+Ytyc3OVlZXlcnYrIyNDgYGBkqTAwEBt2LDBZX8FTyv8c835TzDMyMiQ3W5X5cqVL9iTt7e3vL29S2R+AAAAAMont5/ZOl9+fr5ycnIUHh4uT09PpaSkOMd2796tgwcPKiIiQpIUERGhbdu2KTMz01mTnJwsu92uZs2aOWv+vI+CmoJ9AAAAAIAJbj2zNWrUKHXt2lV169bViRMnlJiYqNWrVyspKUk+Pj4aOHCgEhISVLNmTdntdg0ZMkQRERFq27atJCkqKkrNmjXTY489psmTJys9PV2jR49WXFyc88zUU089pZkzZ2rEiBEaMGCAVq1apY8//ljLlvE0PwAAAADmuDVsZWZmqm/fvjp8+LB8fHzUokULJSUl6Z577pEkTZs2TRUqVFBsbKxycnIUHR2t2bNnO7f38PDQ0qVL9fTTTysiIkJVq1ZVv379NHHiRGdNSEiIli1bpmHDhunNN99UnTp19O677yo6OvqazxcAAABA+VHqvmerNOJ7tgDg2uJ7tgAApVWZ/J4tAAAAALieELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAt4atSZMm6bbbblP16tXl7++v7t27a/fu3S41HTt2lM1mc1meeuopl5qDBw8qJiZGVapUkb+/v4YPH65z58651KxevVqtW7eWt7e3brrpJs2fP9/09AAAAACUY24NW19//bXi4uK0bt06JScn6+zZs4qKitKpU6dc6gYPHqzDhw87l8mTJzvH8vLyFBMTo9zcXK1du1bvv/++5s+fr7Fjxzpr9u/fr5iYGHXq1ElpaWkaOnSoBg0apKSkpGs2VwAAAADlS0V3Hnz58uUur+fPny9/f39t3rxZHTp0cK6vUqWKAgMDL7iPFStW6Mcff9TKlSsVEBCgVq1a6eWXX9bIkSM1fvx4eXl5ae7cuQoJCdGUKVMkSU2bNtW3336radOmKTo62twEAQAAAJRbpeqerezsbElSzZo1XdYvWLBAtWrV0s0336xRo0bp9OnTzrHU1FSFhYUpICDAuS46OloOh0M7duxw1kRGRrrsMzo6WqmpqRfsIycnRw6Hw2UBAAAAgKJw65mtP8vPz9fQoUPVrl073Xzzzc71jzzyiOrVq6fatWtr69atGjlypHbv3q3PPvtMkpSenu4StCQ5X6enp1+yxuFw6I8//lDlypVdxiZNmqQJEyaU+BwBAAAAlB+lJmzFxcVp+/bt+vbbb13WP/HEE85/h4WFKSgoSJ07d9a+ffvUoEEDI72MGjVKCQkJztcOh0PBwcFGjgUAAADg+lQqLiOMj4/X0qVL9dVXX6lOnTqXrG3Tpo0kae/evZKkwMBAZWRkuNQUvC64z+tiNXa7vdBZLUny9vaW3W53WQAAAACgKNwatizLUnx8vBYtWqRVq1YpJCTkstukpaVJkoKCgiRJERER2rZtmzIzM501ycnJstvtatasmbMmJSXFZT/JycmKiIgooZkAAAAAgCu3hq24uDj9+9//VmJioqpXr6709HSlp6frjz/+kCTt27dPL7/8sjZv3qwDBw5oyZIl6tu3rzp06KAWLVpIkqKiotSsWTM99thj+uGHH5SUlKTRo0crLi5O3t7ekqSnnnpKP/30k0aMGKFdu3Zp9uzZ+vjjjzVs2DC3zR0AAADA9c2tYWvOnDnKzs5Wx44dFRQU5Fw++ugjSZKXl5dWrlypqKgoNWnSRM8//7xiY2P1xRdfOPfh4eGhpUuXysPDQxEREXr00UfVt29fTZw40VkTEhKiZcuWKTk5WS1bttSUKVP07rvv8th3AAAAAMbYLMuy3N1EaedwOOTj46Ps7OxSc/9W/ReXubsFADDmwGsx7m4BAIALKko2KBUPyAAAAACA6w1hCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGCAW8PWpEmTdNttt6l69ery9/dX9+7dtXv3bpeaM2fOKC4uTjfccIOqVaum2NhYZWRkuNQcPHhQMTExqlKlivz9/TV8+HCdO3fOpWb16tVq3bq1vL29ddNNN2n+/PmmpwcAAACgHHNr2Pr6668VFxendevWKTk5WWfPnlVUVJROnTrlrBk2bJi++OILLVy4UF9//bUOHTqkHj16OMfz8vIUExOj3NxcrV27Vu+//77mz5+vsWPHOmv279+vmJgYderUSWlpaRo6dKgGDRqkpKSkazpfAAAAAOWHzbIsy91NFDhy5Ij8/f319ddfq0OHDsrOzpafn58SExPVs2dPSdKuXbvUtGlTpaamqm3btvryyy/VrVs3HTp0SAEBAZKkuXPnauTIkTpy5Ii8vLw0cuRILVu2TNu3b3ceq3fv3srKytLy5csv25fD4ZCPj4+ys7Nlt9vNTL6I6r+4zN0tAIAxB16LcXcLAABcUFGyQam6Zys7O1uSVLNmTUnS5s2bdfbsWUVGRjprmjRporp16yo1NVWSlJqaqrCwMGfQkqTo6Gg5HA7t2LHDWfPnfRTUFOzjfDk5OXI4HC4LAAAAABRFqQlb+fn5Gjp0qNq1a6ebb75ZkpSeni4vLy/5+vq61AYEBCg9Pd1Z8+egVTBeMHapGofDoT/++KNQL5MmTZKPj49zCQ4OLpE5AgAAACg/Sk3YiouL0/bt2/Xhhx+6uxWNGjVK2dnZzuWXX35xd0sAAAAAypiK7m5AkuLj47V06VKtWbNGderUca4PDAxUbm6usrKyXM5uZWRkKDAw0FmzYcMGl/0VPK3wzzXnP8EwIyNDdrtdlStXLtSPt7e3vL29S2RuAAAAAMont57ZsixL8fHxWrRokVatWqWQkBCX8fDwcHl6eiolJcW5bvfu3Tp48KAiIiIkSREREdq2bZsyMzOdNcnJybLb7WrWrJmz5s/7KKgp2AcAAAAAlDS3ntmKi4tTYmKiFi9erOrVqzvvsfLx8VHlypXl4+OjgQMHKiEhQTVr1pTdbteQIUMUERGhtm3bSpKioqLUrFkzPfbYY5o8ebLS09M1evRoxcXFOc9OPfXUU5o5c6ZGjBihAQMGaNWqVfr444+1bBlP9AMAAABghlvPbM2ZM0fZ2dnq2LGjgoKCnMtHH33krJk2bZq6deum2NhYdejQQYGBgfrss8+c4x4eHlq6dKk8PDwUERGhRx99VH379tXEiROdNSEhIVq2bJmSk5PVsmVLTZkyRe+++66io6Ov6XwBAAAAlB+l6nu2Siu+ZwsAri2+ZwsAUFqV2e/ZAgAAAIDrBWELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMqOjuBgAAQMlYtC7D3S0AgDEPtg1wdwtFxpktAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAHFCluhoaE6duxYofVZWVkKDQ296qYAAAAAoKwrVtg6cOCA8vLyCq3PycnRb7/9dtVNAQAAAEBZV7EoxUuWLHH+OykpST4+Ps7XeXl5SklJUf369UusOQAAAAAoq4oUtrp37y5Jstls6tevn8uYp6en6tevrylTppRYcwAAAABQVhUpbOXn50uSQkJCtHHjRtWqVctIUwAAAABQ1hUpbBXYv39/SfcBAAAAANeVYoUtSUpJSVFKSooyMzOdZ7wKzJs376obAwAAAICyrFhha8KECZo4caJuvfVWBQUFyWazlXRfAAAAAFCmFStszZ07V/Pnz9djjz1W0v0AAAAAwHWhWN+zlZubqzvuuKOkewEAAACA60axwtagQYOUmJhY0r0AAAAAwHWjWJcRnjlzRu+8845WrlypFi1ayNPT02V86tSpJdIcAAAAAJRVxQpbW7duVatWrSRJ27dvdxnjYRkAAAAAUMyw9dVXX5V0HwAAAABwXSnWPVsAAAAAgEsr1pmtTp06XfJywVWrVhW7IQAAAAC4HhQrbBXcr1Xg7NmzSktL0/bt29WvX7+S6AsAAAAAyrRiha1p06ZdcP348eN18uTJq2oIAAAAAK4HJXrP1qOPPqp58+aV5C4BAAAAoEwq0bCVmpqqSpUqleQuAQAAAKBMKtZlhD169HB5bVmWDh8+rE2bNmnMmDEl0hgAAAAAlGXFCls+Pj4urytUqKDGjRtr4sSJioqKKpHGAAAAAKAsK1bYeu+990q6DwAAAAC4rhQrbBXYvHmzdu7cKUlq3ry5brnllhJpCgAAAADKumKFrczMTPXu3VurV6+Wr6+vJCkrK0udOnXShx9+KD8/v5LsEQAAAADKnGI9jXDIkCE6ceKEduzYoePHj+v48ePavn27HA6Hnn322ZLuEQAAAADKnGKd2Vq+fLlWrlyppk2bOtc1a9ZMs2bN4gEZAAAAAKBintnKz8+Xp6dnofWenp7Kz8+/6qYAAAAAoKwrVti6++679dxzz+nQoUPOdb/99puGDRumzp07l1hzAAAAAFBWFStszZw5Uw6HQ/Xr11eDBg3UoEEDhYSEyOFw6K233irpHgEAAACgzCnWPVvBwcHasmWLVq5cqV27dkmSmjZtqsjIyBJtDgAAAADKqiKd2Vq1apWaNWsmh8Mhm82me+65R0OGDNGQIUN02223qXnz5vrmm29M9QoAAAAAZUaRwtb06dM1ePBg2e32QmM+Pj568sknNXXq1BJrDgAAAADKqiKFrR9++EFdunS56HhUVJQ2b9581U0BAAAAQFlXpLCVkZFxwUe+F6hYsaKOHDly1U0BAAAAQFlXpLB14403avv27Rcd37p1q4KCgq66KQAAAAAo64oUtu69916NGTNGZ86cKTT2xx9/aNy4cerWrVuJNQcAAAAAZVWRHv0+evRoffbZZ2rUqJHi4+PVuHFjSdKuXbs0a9Ys5eXl6aWXXjLSKAAAAACUJUUKWwEBAVq7dq2efvppjRo1SpZlSZJsNpuio6M1a9YsBQQEGGkUAAAAAMqSIl1GKEn16tXTf//7Xx09elTr16/XunXrdPToUf33v/9VSEhIkfa1Zs0a3Xfffapdu7ZsNps+//xzl/HHH39cNpvNZTn/aYjHjx9Xnz59ZLfb5evrq4EDB+rkyZMuNVu3blX79u1VqVIlBQcHa/LkyUWdNgAAAAAUSZHObP1ZjRo1dNttt13VwU+dOqWWLVtqwIAB6tGjxwVrunTpovfee8/52tvb22W8T58+Onz4sJKTk3X27Fn1799fTzzxhBITEyVJDodDUVFRioyM1Ny5c7Vt2zYNGDBAvr6+euKJJ66qfwAAAAC4mGKHrZLQtWtXde3a9ZI13t7eCgwMvODYzp07tXz5cm3cuFG33nqrJOmtt97SvffeqzfeeEO1a9fWggULlJubq3nz5snLy0vNmzdXWlqapk6dStgCAAAAYEyRLyO81lavXi1/f381btxYTz/9tI4dO+YcS01Nla+vrzNoSVJkZKQqVKig9evXO2s6dOggLy8vZ010dLR2796t33///YLHzMnJkcPhcFkAAAAAoChKddjq0qWLPvjgA6WkpOjvf/+7vv76a3Xt2lV5eXmSpPT0dPn7+7tsU7FiRdWsWVPp6enOmvMf2lHwuqDmfJMmTZKPj49zCQ4OLumpAQAAALjOufUywsvp3bu3899hYWFq0aKFGjRooNWrV6tz587Gjjtq1CglJCQ4XzscDgIXAAAAgCIp1We2zhcaGqpatWpp7969kqTAwEBlZma61Jw7d07Hjx933ucVGBiojIwMl5qC1xe7F8zb21t2u91lAQAAAICiKFNh69dff9WxY8cUFBQkSYqIiFBWVpY2b97srFm1apXy8/PVpk0bZ82aNWt09uxZZ01ycrIaN26sGjVqXNsJAAAAACg33Bq2Tp48qbS0NKWlpUmS9u/fr7S0NB08eFAnT57U8OHDtW7dOh04cEApKSl64IEHdNNNNyk6OlqS1LRpU3Xp0kWDBw/Whg0b9N133yk+Pl69e/dW7dq1JUmPPPKIvLy8NHDgQO3YsUMfffSR3nzzTZfLBAEAAACgpLk1bG3atEm33HKLbrnlFklSQkKCbrnlFo0dO1YeHh7aunWr7r//fjVq1EgDBw5UeHi4vvnmG5fv2lqwYIGaNGmizp07695779Wdd96pd955xznu4+OjFStWaP/+/QoPD9fzzz+vsWPH8th3AAAAAEa59QEZHTt2lGVZFx1PSkq67D5q1qzp/ALji2nRooW++eabIvcHAAAAAMVVpu7ZAgAAAICygrAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGuDVsrVmzRvfdd59q164tm82mzz//3GXcsiyNHTtWQUFBqly5siIjI7Vnzx6XmuPHj6tPnz6y2+3y9fXVwIEDdfLkSZearVu3qn379qpUqZKCg4M1efJk01MDAAAAUM65NWydOnVKLVu21KxZsy44PnnyZM2YMUNz587V+vXrVbVqVUVHR+vMmTPOmj59+mjHjh1KTk7W0qVLtWbNGj3xxBPOcYfDoaioKNWrV0+bN2/W66+/rvHjx+udd94xPj8AAAAA5VdFdx68a9eu6tq16wXHLMvS9OnTNXr0aD3wwAOSpA8++EABAQH6/PPP1bt3b+3cuVPLly/Xxo0bdeutt0qS3nrrLd1777164403VLt2bS1YsEC5ubmaN2+evLy81Lx5c6WlpWnq1KkuoQwAAAAASlKpvWdr//79Sk9PV2RkpHOdj4+P2rRpo9TUVElSamqqfH19nUFLkiIjI1WhQgWtX7/eWdOhQwd5eXk5a6Kjo7V79279/vvvFzx2Tk6OHA6HywIAAAAARVFqw1Z6erokKSAgwGV9QECAcyw9PV3+/v4u4xUrVlTNmjVdai60jz8f43yTJk2Sj4+PcwkODr76CQEAAAAoV0pt2HKnUaNGKTs727n88ssv7m4JAAAAQBlTasNWYGCgJCkjI8NlfUZGhnMsMDBQmZmZLuPnzp3T8ePHXWoutI8/H+N83t7estvtLgsAAAAAFEWpDVshISEKDAxUSkqKc53D4dD69esVEREhSYqIiFBWVpY2b97srFm1apXy8/PVpk0bZ82aNWt09uxZZ01ycrIaN26sGjVqXKPZAAAAAChv3Bq2Tp48qbS0NKWlpUn630Mx0tLSdPDgQdlsNg0dOlSvvPKKlixZom3btqlv376qXbu2unfvLklq2rSpunTposGDB2vDhg367rvvFB8fr969e6t27dqSpEceeUReXl4aOHCgduzYoY8++khvvvmmEhIS3DRrAAAAAOWBWx/9vmnTJnXq1Mn5uiAA9evXT/Pnz9eIESN06tQpPfHEE8rKytKdd96p5cuXq1KlSs5tFixYoPj4eHXu3FkVKlRQbGysZsyY4Rz38fHRihUrFBcXp/DwcNWqVUtjx47lse8AAAAAjLJZlmW5u4nSzuFwyMfHR9nZ2aXm/q36Ly5zdwsAYMyB12Lc3UKZtGhdxuWLAKCMerBtwOWLroGiZINSe88WAAAAAJRlhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAaU6bI0fP142m81ladKkiXP8zJkziouL0w033KBq1aopNjZWGRkZLvs4ePCgYmJiVKVKFfn7+2v48OE6d+7ctZ4KAAAAgHKmorsbuJzmzZtr5cqVztcVK/5fy8OGDdOyZcu0cOFC+fj4KD4+Xj169NB3330nScrLy1NMTIwCAwO1du1aHT58WH379pWnp6f+9re/XfO5AAAAACg/Sn3YqlixogIDAwutz87O1j//+U8lJibq7rvvliS99957atq0qdatW6e2bdtqxYoV+vHHH7Vy5UoFBASoVatWevnllzVy5EiNHz9eXl5e13o6AAAAAMqJUn0ZoSTt2bNHtWvXVmhoqPr06aODBw9KkjZv3qyzZ88qMjLSWdukSRPVrVtXqampkqTU1FSFhYUpICDAWRMdHS2Hw6EdO3Zc9Jg5OTlyOBwuCwAAAAAURakOW23atNH8+fO1fPlyzZkzR/v371f79u114sQJpaeny8vLS76+vi7bBAQEKD09XZKUnp7uErQKxgvGLmbSpEny8fFxLsHBwSU7MQAAAADXvVJ9GWHXrl2d/27RooXatGmjevXq6eOPP1blypWNHXfUqFFKSEhwvnY4HAQuAAAAAEVSqs9snc/X11eNGjXS3r17FRgYqNzcXGVlZbnUZGRkOO/xCgwMLPR0woLXF7oPrIC3t7fsdrvLAgAAAABFUabC1smTJ7Vv3z4FBQUpPDxcnp6eSklJcY7v3r1bBw8eVEREhCQpIiJC27ZtU2ZmprMmOTlZdrtdzZo1u+b9AwAAACg/SvVlhC+88ILuu+8+1atXT4cOHdK4cePk4eGhhx9+WD4+Pho4cKASEhJUs2ZN2e12DRkyRBEREWrbtq0kKSoqSs2aNdNjjz2myZMnKz09XaNHj1ZcXJy8vb3dPDsAAAAA17NSHbZ+/fVXPfzwwzp27Jj8/Px05513at26dfLz85MkTZs2TRUqVFBsbKxycnIUHR2t2bNnO7f38PDQ0qVL9fTTTysiIkJVq1ZVv379NHHiRHdNCQAAAEA5YbMsy3J3E6Wdw+GQj4+PsrOzS839W/VfXObuFgDAmAOvxbi7hTJp0bqMyxcBQBn1YNuAyxddA0XJBmXqni0AAAAAKCsIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYABhCwAAAAAMIGwBAAAAgAGELQAAAAAwgLAFAAAAAAYQtgAAAADAAMIWAAAAABhA2AIAAAAAAwhbAAAAAGAAYQsAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgAAAAADCFsAAAAAYEC5CluzZs1S/fr1ValSJbVp00YbNmxwd0sAAAAArlPlJmx99NFHSkhI0Lhx47Rlyxa1bNlS0dHRyszMdHdrAAAAAK5D5SZsTZ06VYMHD1b//v3VrFkzzZ07V1WqVNG8efPc3RoAAACA61BFdzdwLeTm5mrz5s0aNWqUc12FChUUGRmp1NTUQvU5OTnKyclxvs7OzpYkORwO881eofyc0+5uAQCMKU1/b8uS06dOuLsFADDG4ajs7hYk/d9nlGVZl60tF2Hr6NGjysvLU0BAgMv6gIAA7dq1q1D9pEmTNGHChELrg4ODjfUIAPg/PtPd3QEAAJd24sQJ+fj4XLKmXIStoho1apQSEhKcr/Pz83X8+HHdcMMNstlsbuwMuPYcDoeCg4P1yy+/yG63u7sdAEApwecDyivLsnTixAnVrl37srXlImzVqlVLHh4eysjIcFmfkZGhwMDAQvXe3t7y9vZ2Wefr62uyRaDUs9vtfJgCAArh8wHl0eXOaBUoFw/I8PLyUnh4uFJSUpzr8vPzlZKSooiICDd2BgAAAOB6VS7ObElSQkKC+vXrp1tvvVW33367pk+frlOnTql///7ubg0AAADAdajchK2//OUvOnLkiMaOHav09HS1atVKy5cvL/TQDACuvL29NW7cuEKX1gIAyjc+H4DLs1lX8sxCAAAAAECRlIt7tgAAAADgWiNsAQAAAIABhC0AAAAAMICwBVynOnbsqKFDh7q7DQBAKcfnBWAOYQvAFVu9erVsNluhJT093aUuPT1dQ4YMUWhoqLy9vRUcHKz77rvP5bvuAABlx/fff6+HHnpIAQEBqlSpkho2bKjBgwfr//2//+fu1oBSjbAFoMh2796tw4cPOxd/f3/n2IEDBxQeHq5Vq1bp9ddf17Zt27R8+XJ16tRJcXFxbuwaAFAcS5cuVdu2bZWTk6MFCxZo586d+ve//y0fHx+NGTPG3e0BpRphC7iO5efna8SIEapZs6YCAwM1fvx455jNZtPbb7+tbt26qUqVKmratKlSU1O1d+9edezYUVWrVtUdd9yhffv2Fdqvv7+/AgMDnUuFCv/3p+SZZ56RzWbThg0bFBsbq0aNGql58+ZKSEjQunXrrsW0AQBFdLHPi9OnT6t///669957tWTJEkVGRiokJERt2rTRG2+8obffflvS/135kJSUpFtuuUWVK1fW3XffrczMTH355Zdq2rSp7Ha7HnnkEZ0+fdqNMwWuLcIWcB17//33VbVqVa1fv16TJ0/WxIkTlZyc7Bx/+eWX1bdvX6WlpalJkyZ65JFH9OSTT2rUqFHatGmTLMtSfHx8of22atVKQUFBuueee/Tdd9851x8/flzLly9XXFycqlatWmg7X19fI/MEAFydi31eJCUl6ejRoxoxYsQFtzv/7/r48eM1c+ZMrV27Vr/88ot69eql6dOnKzExUcuWLdOKFSv01ltvXYMZAaVDRXc3AMCcFi1aaNy4cZKkhg0baubMmUpJSdE999wjSerfv7969eolSRo5cqQiIiI0ZswYRUdHS5Kee+459e/f37m/oKAgzZ07V7feeqtycnL07rvvqmPHjlq/fr1at26tvXv3yrIsNWnS5BrPFABwNS72eVGzZk1JuuK/66+88oratWsnSRo4cKBGjRqlffv2KTQ0VJLUs2dPffXVVxo5cqSBWQClD2ELuI61aNHC5XVQUJAyMzMvOB4QECBJCgsLc1l35swZORwO2e12NW7cWI0bN3aOF1xmOG3aNP3rX/+SZVmmpgIAMOhinxc1atQo9n4CAgJUpUoVZ9AqWLdhw4araxYoQ7iMELiOeXp6ury22WzKz8+/4LjNZrvouj9vc77bb79de/fulfS//xtqs9m0a9euq28eAHDNXOzzolGjRpJ0xX/Xz/8MudznEHC9I2wBuCppaWkKCgqSJNWsWVPR0dGaNWuWTp06Vag2KyvrGncHALgaUVFRqlWrliZPnnzBcf6uA5dG2AJwxaZPn67Fixdr79692r59u4YOHapVq1a5PNJ91qxZysvL0+23365PP/1Ue/bs0c6dOzVjxgxFRES4sXsAQFFVrVpV7777rpYtW6b7779fK1eu1IEDB7Rp0yaNGDFCTz31lLtbBEo17tkCcMVyc3P1/PPP67ffflOVKlXUokULrVy5Up06dXLWhIaGasuWLXr11Vf1/PPP6/Dhw/Lz81N4eLjmzJnjxu4BAMXxwAMPaO3atZo0aZIeeeQRORwOBQcH6+6779Yrr7zi7vaAUs1mcUc7AAAAAJQ4LiMEAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADCAsAUAAAAABhC2AAAAAMAAwhYAAAAAGEDYAgDgT2w2mz7//HN3twEAuA4QtgAA5Up6erqGDBmi0NBQeXt7Kzg4WPfdd59SUlLc3RoA4DpT0d0NAABwrRw4cEDt2rWTr6+vXn/9dYWFhens2bNKSkpSXFycdu3a5e4WAQDXEc5sAQDKjWeeeUY2m00bNmxQbGysGjVqpObNmyshIUHr1q274DYjR45Uo0aNVKVKFYWGhmrMmDE6e/asc/yHH35Qp06dVL16ddntdoWHh2vTpk2SpJ9//ln33XefatSooapVq6p58+b673//e03mCgBwP85sAQDKhePHj2v58uV69dVXVbVq1ULjvr6+F9yuevXqmj9/vmrXrq1t27Zp8ODBql69ukaMGCFJ6tOnj2655RbNmTNHHh4eSktLk6enpyQpLi5Oubm5WrNmjapWraoff/xR1apVMzZHAEDpQtgCAJQLe/fulWVZatKkSZG2Gz16tPPf9evX1wsvvKAPP/zQGbYOHjyo4cOHO/fbsGFDZ/3BgwcVGxursLAwSVJoaOjVTgMAUIZwGSEAoFywLKtY23300Udq166dAgMDVa1aNY0ePVoHDx50jickJGjQoEGKjIzUa6+9pn379jnHnn32Wb3yyitq166dxo0bp61bt171PAAAZQdhCwBQLjRs2FA2m61ID8FITU1Vnz59dO+992rp0qX6/vvv9dJLLyk3N9dZM378eO3YsUMxMTFatWqVmjVrpkWLFkmSBg0apJ9++kmPPfaYtm3bpltvvVVvvfVWic8NAFA62azi/q8+AADKmK5du2rbtm3avXt3ofu2srKy5OvrK5vNpkWLFql79+6aMmWKZs+e7XK2atCgQfrkk0+UlZV1wWM8/PDDOnXqlJYsWVJobNSoUVq2bBlnuACgnODMFgCg3Jg1a5by8vJ0++2369NPP9WePXu0c+dOzZgxQxEREYXqGzZsqIMHD+rDDz/Uvn37NGPGDOdZK0n6448/FB8fr9WrV+vnn3/Wd999p40bN6pp06aSpKFDhyopKUn79+/Xli1b9NVXXznHAADXPx6QAQAoN0JDQ7Vlyxa9+uqrev7553X48GH5+fkpPDxcc+bMKVR///33a9iwYYqPj1dOTo5iYmI0ZswYjR8/XpLk4eGhY8eOqW/fvsrIyFCtWrXUo0cPTZgwQZKUl5enuLg4/frrr7Lb7erSpYumTZt2LacMAHAjLiMEAAAAAAO4jBAAAAAADCBsAQAAAIABhC0AAAAAMICwBQAAAAAGELYAAAAAwADCFgAAAAAYQNgCAAAAAAMIWwAAAABgAGELAAAAAAwgbAEAAACAAYQtAAAAADDg/wMhoFSSINJ/MgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "y_counts = y_data_filtered.value_counts()\n",
    "colors = cm.tab20(range(len(y_counts)))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(y_counts.index, y_counts.values , color = colors)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Value counts of each class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTPaFg0d5BVQ",
    "outputId": "794c6077-0e7c-4358-89ff-7d6c7039f921"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2782      TTTTAACACAATACTTTAATAAGACACATTTAAACTCAACTTCTGA...\n",
       "2783      CCTTTGGGGGGCTAATAGCTCCTATATTCATTCAAAGAAGGAATAG...\n",
       "2784      GGCGCAGGGAAGAGGAAGCGGAGGCACTCGGAAGGTAAGTGGCTAG...\n",
       "2785      AATTATTTTTTTAGGGCCGGGCGCGGTGGCTCACGTCTGTAATCCC...\n",
       "2786      TGTATTTTTCATGTATGGCCTTTATCATGTTGAGTAAGTTTCTTTC...\n",
       "                                ...                        \n",
       "307506    TCTGTTGTCATCCTATCATTGACCTGAGATACCAGAGATCGCCAAA...\n",
       "307507    GGAAAGAGAACACACACCCCAGGTGTCATGCACACCCTCGGAAGAC...\n",
       "307508    TTTGGAAAAAGAGATATCCTAGCTCAGGGCAAGCCGTTTGATGGAA...\n",
       "307509    TTCAAGCGATTCTCCTGCCTCAGCCTCCCGAGTAGCTGGGATTACA...\n",
       "307510    CTGAGCCCAGCACAGCACCAGAGCTTACCCAAGAATTGCAGTTCTT...\n",
       "Name: Sequence, Length: 5085, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_filtered['Sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULG0B0e95BVQ",
    "outputId": "69c76a6c-6b7e-4121-9a88-96d17bf2a5b6"
   },
   "outputs": [],
   "source": [
    "encoded_sequences = [encode_with_k_mer_codon(sequence) for sequence in x_data_filtered['Sequence']]\n",
    "X_encoded = np.array(encoded_sequences)\n",
    "X_encoded_tensor = torch.tensor(X_encoded, dtype=torch.float32)\n",
    "y_encoded = encode_target(y_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne-hmuDd5BVR",
    "outputId": "dbebeca1-6b70-4cfd-b2d2-3c011fdfac48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50., 50., 62.,  ..., 50., 35., 52.],\n",
       "        [ 6., 42., 50.,  ..., 55., 12., 22.],\n",
       "        [17., 44., 30.,  ..., 61., 50., 62.],\n",
       "        ...,\n",
       "        [50., 35., 45.,  ..., 17., 29.,  1.],\n",
       "        [43., 11., 60.,  ..., 34., 50., 43.],\n",
       "        [25., 52., 39.,  ...,  1.,  2., 33.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etAEiUuL5BVR",
    "outputId": "3ce21d47-4199-4911-83b0-a095d1ceda83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Train and Split..\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate Train and Split..\")\n",
    "# Train set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Test and Validation set\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxuA3OdC5BVR",
    "outputId": "0df4344b-8c3a-4fbc-c67b-4973076f8446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Y Count :  Counter({0: 2266, 1: 1293})\n",
      "Test Y Count :  Counter({0: 457, 1: 306})\n"
     ]
    }
   ],
   "source": [
    "X_encoded = None\n",
    "y_encoded = None\n",
    "x_data_filtered , y_data_filtered = None,None\n",
    "x_data , y_data = None , None\n",
    "\n",
    "print(\"Train Y Count : \" ,Counter(y_train))\n",
    "print(\"Test Y Count : \" ,Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zb-kIy35BVR"
   },
   "source": [
    "### Balance Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3tEqKJG25BVR"
   },
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train , dtype=torch.long)\n",
    "y_test = torch.tensor(y_test , dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid , dtype=torch.long)\n",
    "\n",
    "sm = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "y_resampled = torch.tensor(y_resampled , dtype=torch.float32) # Keeping float32\n",
    "X_resampled = torch.tensor(X_resampled , dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpftneeP5BVR",
    "outputId": "45c7f234-7cba-475a-85a2-a23c25c9aa29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3559, 99)\n",
      "torch.Size([3559])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lM0C9uYE5BVS",
    "outputId": "3cb2f8f6-abd9-44f5-81d6-5d71e9a1162b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([54., 61., 43., 22., 42., 62., 32., 12., 13.,  1.,  2., 61., 43., 22.,\n",
       "        25., 28., 29.,  1.,  2., 61., 43., 22., 25., 28., 18.,  2., 12., 13.,\n",
       "         6., 42., 50., 62., 47., 48.,  9., 27., 45., 51., 53., 59., 37.,  2.,\n",
       "        61., 50., 62.,  8., 20., 17., 29.,  1.,  2., 61., 50., 62., 32.,  3.,\n",
       "        32., 61., 43., 11., 60., 59., 37.,  2., 61., 62.,  8.,  9., 46., 32.,\n",
       "        61., 35., 52., 53., 63., 63., 48.,  9., 27., 52., 39., 20., 21., 46.,\n",
       "         4., 58., 14., 22., 42., 43., 22.,  7., 32., 61., 43., 11., 36., 58.,\n",
       "        25.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "pIOzPJWY5BVS"
   },
   "outputs": [],
   "source": [
    "hyperparameter = {}\n",
    "hyperparameter['INPUT_DIMENSION'] = len(kmer_dict) # For One Hot Encoding Input Dimension would be 4 as there only 4 unique nucleocide\n",
    "hyperparameter['HIDDEN_DIMENSION'] = 88\n",
    "hyperparameter['NO_OF_LAYERS'] = 2\n",
    "hyperparameter['BATCH_SIZE'] = 64\n",
    "hyperparameter['OUTPUT_DIMENSION'] = len(eligible_class_list)\n",
    "hyperparameter['EMBEDDING_DIMENSION'] = 16 # if you are using Word2Vec Encoding then this should be same as Word2Vec Embedding Dim\n",
    "hyperparameter['DROP_OUT'] = 0.18612418176703444\n",
    "hyperparameter['LEARNING_RATE'] = 0.00010164966155256074\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "    \n",
    "class RNADataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "train_dataset = RNADataset(X_resampled, y_resampled)\n",
    "test_dataset = RNADataset(X_test, y_test)\n",
    "valid_dataset = RNADataset(X_valid, y_valid)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "sXVdBroi5BVS"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNATransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, output_dim, dropout=0.5):\n",
    "        super(RNATransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "\n",
    "        # If batch size first is true then it should be batch size , sequence lenght , embedding dimension\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=8, dim_feedforward=hidden_dim , batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        #print(\"Shape of Original X  \", x.shape)\n",
    "        x_embedded = self.embedding(x)\n",
    "        #print(\"Shape of X embedded\" , x_embedded.shape)\n",
    "        x_transformed = self.transformer_encoder(x_embedded)\n",
    "        #print(\"Shape of Transformed X\" , x_transformed.shape)\n",
    "        x_transformed = x_transformed[:, -1, :]  # taking the last token's output\n",
    "\n",
    "        output = self.dropout(x_transformed)\n",
    "        out = self.fc(output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sP484k65BVS",
    "outputId": "1bf3a3f4-e539-4b89-8f0c-3918db6732ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 99])\n"
     ]
    }
   ],
   "source": [
    "# Check data is in correct shape - batch size , sequece len , embedding dimension size\n",
    "for inputs, labels in train_dataloader:\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-t8RdUvy5BVS"
   },
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "def validate_model(model, test_dataloader , device ,loss_function):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    class_correct = [0] * hyperparameter['OUTPUT_DIMENSION']\n",
    "    class_total = [0] * hyperparameter['OUTPUT_DIMENSION']\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())  # Capture True Lables for Summary Report\n",
    "            predicted_labels.extend(predicted.cpu().numpy()) # Capture Predicted Labels Lables for Summary Report\n",
    "\n",
    "    validation_loss = running_loss / len(test_dataloader)\n",
    "    validation_accuracy = correct / total\n",
    "\n",
    "    return validation_loss , validation_accuracy , true_labels , predicted_labels\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, test_dataloader, device, epochs, optimizer, loss_function):\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) \n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        val_loss,  validation_accuracy , true_labels , predicted_labels = validate_model(model, test_dataloader, device, loss_function)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Test Accuracy: {validation_accuracy:.4f} ,Learning Rate: {optimizer.param_groups[0]['lr']} , Time Taken : {elapsed_time}\")\n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(validation_accuracy)\n",
    "        \n",
    "        #scheduler.step()\n",
    "\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             no_improvement_count = 0\n",
    "#         else:\n",
    "#             no_improvement_count += 1\n",
    "#             if no_improvement_count == 20:\n",
    "#                 print(\"No improvement in validation loss for 5 epochs. Training stopped.\")\n",
    "#                 break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7wtvOzF5BVS",
    "outputId": "ea97784b-22dc-4b48-f2c6-30f3f397fce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parameters for Model Training : 13754 \n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 88, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.18612418176703444, 'LEARNING_RATE': 0.00010164966155256074}\n",
      "Epoch 1, Train Loss: 0.7921, Val Loss: 0.7487, Test Accuracy: 0.4875 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.139392614364624\n",
      "Epoch 2, Train Loss: 0.7533, Val Loss: 0.7231, Test Accuracy: 0.5033 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1806576251983643\n",
      "Epoch 3, Train Loss: 0.7330, Val Loss: 0.7111, Test Accuracy: 0.5020 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1789140701293945\n",
      "Epoch 4, Train Loss: 0.7264, Val Loss: 0.7071, Test Accuracy: 0.4967 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1842455863952637\n",
      "Epoch 5, Train Loss: 0.7177, Val Loss: 0.7020, Test Accuracy: 0.5125 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0526366233825684\n",
      "Epoch 6, Train Loss: 0.7116, Val Loss: 0.6994, Test Accuracy: 0.5216 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.7058773040771484\n",
      "Epoch 7, Train Loss: 0.7118, Val Loss: 0.6989, Test Accuracy: 0.5138 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.7917370796203613\n",
      "Epoch 8, Train Loss: 0.7069, Val Loss: 0.6979, Test Accuracy: 0.5111 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0052003860473633\n",
      "Epoch 9, Train Loss: 0.7095, Val Loss: 0.6972, Test Accuracy: 0.5151 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.228091239929199\n",
      "Epoch 10, Train Loss: 0.7037, Val Loss: 0.6980, Test Accuracy: 0.5072 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0452003479003906\n",
      "Epoch 11, Train Loss: 0.7005, Val Loss: 0.6945, Test Accuracy: 0.5216 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.167346954345703\n",
      "Epoch 12, Train Loss: 0.6999, Val Loss: 0.6974, Test Accuracy: 0.5177 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2161617279052734\n",
      "Epoch 13, Train Loss: 0.7009, Val Loss: 0.6978, Test Accuracy: 0.5190 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.9629721641540527\n",
      "Epoch 14, Train Loss: 0.6977, Val Loss: 0.6947, Test Accuracy: 0.5164 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.3538708686828613\n",
      "Epoch 15, Train Loss: 0.7005, Val Loss: 0.6923, Test Accuracy: 0.5190 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.4012982845306396\n",
      "Epoch 16, Train Loss: 0.6933, Val Loss: 0.6937, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.375943899154663\n",
      "Epoch 17, Train Loss: 0.6924, Val Loss: 0.6961, Test Accuracy: 0.5177 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.373392105102539\n",
      "Epoch 18, Train Loss: 0.6918, Val Loss: 0.6933, Test Accuracy: 0.5229 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.9567067623138428\n",
      "Epoch 19, Train Loss: 0.6953, Val Loss: 0.6973, Test Accuracy: 0.5125 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.7375268936157227\n",
      "Epoch 20, Train Loss: 0.6976, Val Loss: 0.6950, Test Accuracy: 0.5216 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.878681182861328\n",
      "Epoch 21, Train Loss: 0.6943, Val Loss: 0.6930, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.9328224658966064\n",
      "Epoch 22, Train Loss: 0.6940, Val Loss: 0.6929, Test Accuracy: 0.5295 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2485172748565674\n",
      "Epoch 23, Train Loss: 0.6920, Val Loss: 0.6938, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.259110927581787\n",
      "Epoch 24, Train Loss: 0.6950, Val Loss: 0.6965, Test Accuracy: 0.5164 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2834243774414062\n",
      "Epoch 25, Train Loss: 0.6929, Val Loss: 0.6910, Test Accuracy: 0.5282 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2790162563323975\n",
      "Epoch 26, Train Loss: 0.6936, Val Loss: 0.6909, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2931969165802\n",
      "Epoch 27, Train Loss: 0.6897, Val Loss: 0.6942, Test Accuracy: 0.5177 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.224076509475708\n",
      "Epoch 28, Train Loss: 0.6875, Val Loss: 0.6951, Test Accuracy: 0.5229 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.114353656768799\n",
      "Epoch 29, Train Loss: 0.6884, Val Loss: 0.6935, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.9253146648406982\n",
      "Epoch 30, Train Loss: 0.6881, Val Loss: 0.6928, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.9205126762390137\n",
      "Epoch 31, Train Loss: 0.6877, Val Loss: 0.6966, Test Accuracy: 0.5151 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.923149824142456\n",
      "Epoch 32, Train Loss: 0.6885, Val Loss: 0.6947, Test Accuracy: 0.5203 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.923964500427246\n",
      "Epoch 33, Train Loss: 0.6896, Val Loss: 0.6943, Test Accuracy: 0.5269 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.911911964416504\n",
      "Epoch 34, Train Loss: 0.6888, Val Loss: 0.6951, Test Accuracy: 0.5125 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0863869190216064\n",
      "Epoch 35, Train Loss: 0.6863, Val Loss: 0.6937, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1345889568328857\n",
      "Epoch 36, Train Loss: 0.6852, Val Loss: 0.6930, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1796202659606934\n",
      "Epoch 37, Train Loss: 0.6905, Val Loss: 0.6937, Test Accuracy: 0.5282 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2268855571746826\n",
      "Epoch 38, Train Loss: 0.6894, Val Loss: 0.6941, Test Accuracy: 0.5256 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.173856258392334\n",
      "Epoch 39, Train Loss: 0.6836, Val Loss: 0.6932, Test Accuracy: 0.5269 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.234560251235962\n",
      "Epoch 40, Train Loss: 0.6870, Val Loss: 0.6929, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.213879346847534\n",
      "Epoch 41, Train Loss: 0.6843, Val Loss: 0.6913, Test Accuracy: 0.5413 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.235200881958008\n",
      "Epoch 42, Train Loss: 0.6863, Val Loss: 0.6946, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2400612831115723\n",
      "Epoch 43, Train Loss: 0.6839, Val Loss: 0.6920, Test Accuracy: 0.5426 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2419910430908203\n",
      "Epoch 44, Train Loss: 0.6861, Val Loss: 0.6908, Test Accuracy: 0.5387 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2552475929260254\n",
      "Epoch 45, Train Loss: 0.6856, Val Loss: 0.6944, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.166689395904541\n",
      "Epoch 46, Train Loss: 0.6856, Val Loss: 0.6949, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.7307980060577393\n",
      "Epoch 47, Train Loss: 0.6826, Val Loss: 0.6964, Test Accuracy: 0.5308 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.622063636779785\n",
      "Epoch 48, Train Loss: 0.6864, Val Loss: 0.6965, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.9021661281585693\n",
      "Epoch 49, Train Loss: 0.6831, Val Loss: 0.6913, Test Accuracy: 0.5374 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.172719717025757\n",
      "Epoch 50, Train Loss: 0.6822, Val Loss: 0.6944, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.19921875\n",
      "Epoch 51, Train Loss: 0.6835, Val Loss: 0.6941, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2157974243164062\n",
      "Epoch 52, Train Loss: 0.6830, Val Loss: 0.6955, Test Accuracy: 0.5308 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.214113235473633\n",
      "Epoch 53, Train Loss: 0.6825, Val Loss: 0.6982, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2310075759887695\n",
      "Epoch 54, Train Loss: 0.6812, Val Loss: 0.6899, Test Accuracy: 0.5452 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1026978492736816\n",
      "Epoch 55, Train Loss: 0.6826, Val Loss: 0.6946, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1899545192718506\n",
      "Epoch 56, Train Loss: 0.6806, Val Loss: 0.6927, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.249016284942627\n",
      "Epoch 57, Train Loss: 0.6827, Val Loss: 0.6943, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.3011531829833984\n",
      "Epoch 58, Train Loss: 0.6818, Val Loss: 0.6936, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.019712448120117\n",
      "Epoch 59, Train Loss: 0.6811, Val Loss: 0.6944, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.131859064102173\n",
      "Epoch 60, Train Loss: 0.6812, Val Loss: 0.6933, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0379345417022705\n",
      "Epoch 61, Train Loss: 0.6786, Val Loss: 0.6973, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1614997386932373\n",
      "Epoch 62, Train Loss: 0.6802, Val Loss: 0.6934, Test Accuracy: 0.5374 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1609222888946533\n",
      "Epoch 63, Train Loss: 0.6794, Val Loss: 0.6944, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2011823654174805\n",
      "Epoch 64, Train Loss: 0.6798, Val Loss: 0.6931, Test Accuracy: 0.5374 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.935004949569702\n",
      "Epoch 65, Train Loss: 0.6794, Val Loss: 0.6940, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.7426695823669434\n",
      "Epoch 66, Train Loss: 0.6787, Val Loss: 0.6959, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.7463417053222656\n",
      "Epoch 67, Train Loss: 0.6813, Val Loss: 0.6962, Test Accuracy: 0.5282 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.7365946769714355\n",
      "Epoch 68, Train Loss: 0.6861, Val Loss: 0.6935, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.9946975708007812\n",
      "Epoch 69, Train Loss: 0.6799, Val Loss: 0.6933, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0034024715423584\n",
      "Epoch 70, Train Loss: 0.6780, Val Loss: 0.6952, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.8011481761932373\n",
      "Epoch 71, Train Loss: 0.6791, Val Loss: 0.6930, Test Accuracy: 0.5387 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.80222487449646\n",
      "Epoch 72, Train Loss: 0.6795, Val Loss: 0.6965, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 2.7838432788848877\n",
      "Epoch 73, Train Loss: 0.6769, Val Loss: 0.6938, Test Accuracy: 0.5413 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.240767240524292\n",
      "Epoch 74, Train Loss: 0.6803, Val Loss: 0.6967, Test Accuracy: 0.5256 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2129507064819336\n",
      "Epoch 75, Train Loss: 0.6753, Val Loss: 0.6960, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1981639862060547\n",
      "Epoch 76, Train Loss: 0.6780, Val Loss: 0.6945, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.176668167114258\n",
      "Epoch 77, Train Loss: 0.6748, Val Loss: 0.6958, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.066309928894043\n",
      "Epoch 78, Train Loss: 0.6760, Val Loss: 0.6889, Test Accuracy: 0.5505 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1360061168670654\n",
      "Epoch 79, Train Loss: 0.6767, Val Loss: 0.6939, Test Accuracy: 0.5413 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.198498249053955\n",
      "Epoch 80, Train Loss: 0.6739, Val Loss: 0.6973, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1843743324279785\n",
      "Epoch 81, Train Loss: 0.6776, Val Loss: 0.6952, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.15317440032959\n",
      "Epoch 82, Train Loss: 0.6772, Val Loss: 0.6930, Test Accuracy: 0.5439 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1652274131774902\n",
      "Epoch 83, Train Loss: 0.6742, Val Loss: 0.6969, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.296858787536621\n",
      "Epoch 84, Train Loss: 0.6741, Val Loss: 0.6959, Test Accuracy: 0.5308 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2184886932373047\n",
      "Epoch 85, Train Loss: 0.6753, Val Loss: 0.6979, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0347206592559814\n",
      "Epoch 86, Train Loss: 0.6767, Val Loss: 0.6960, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.3428566455841064\n",
      "Epoch 87, Train Loss: 0.6742, Val Loss: 0.6980, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.3707494735717773\n",
      "Epoch 88, Train Loss: 0.6732, Val Loss: 0.6976, Test Accuracy: 0.5387 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.3751511573791504\n",
      "Epoch 89, Train Loss: 0.6750, Val Loss: 0.6977, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.3602964878082275\n",
      "Epoch 90, Train Loss: 0.6734, Val Loss: 0.6991, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.281094789505005\n",
      "Epoch 91, Train Loss: 0.6744, Val Loss: 0.6970, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0185763835906982\n",
      "Epoch 92, Train Loss: 0.6731, Val Loss: 0.6946, Test Accuracy: 0.5400 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.0544538497924805\n",
      "Epoch 93, Train Loss: 0.6724, Val Loss: 0.6993, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2086589336395264\n",
      "Epoch 94, Train Loss: 0.6728, Val Loss: 0.6946, Test Accuracy: 0.5426 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2325456142425537\n",
      "Epoch 95, Train Loss: 0.6728, Val Loss: 0.7004, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.2257015705108643\n",
      "Epoch 96, Train Loss: 0.6741, Val Loss: 0.6955, Test Accuracy: 0.5452 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.162754774093628\n",
      "Epoch 97, Train Loss: 0.6729, Val Loss: 0.6949, Test Accuracy: 0.5426 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.206035852432251\n",
      "Epoch 98, Train Loss: 0.6713, Val Loss: 0.6941, Test Accuracy: 0.5465 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.1795947551727295\n",
      "Epoch 99, Train Loss: 0.6717, Val Loss: 0.6976, Test Accuracy: 0.5505 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.179945945739746\n",
      "Epoch 100, Train Loss: 0.6711, Val Loss: 0.6965, Test Accuracy: 0.5413 ,Learning Rate: 0.00010164966155256074 , Time Taken : 3.125802993774414\n"
     ]
    }
   ],
   "source": [
    "model = RNATransformerModel(input_dim=hyperparameter['INPUT_DIMENSION'],\n",
    "                            embedding_dim=hyperparameter['EMBEDDING_DIMENSION'],\n",
    "                            hidden_dim=hyperparameter['HIDDEN_DIMENSION'] ,\n",
    "                            num_layers = hyperparameter['NO_OF_LAYERS'],\n",
    "                            output_dim=hyperparameter['OUTPUT_DIMENSION'],\n",
    "                            dropout=hyperparameter['DROP_OUT'] )\n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()  ## MSELoss of Regression problem  # BCELoss for binary classification\n",
    "optimizer = optim.Adam(model.parameters() ,  lr=hyperparameter['LEARNING_RATE'] , weight_decay=0.000001 )\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Number of Parameters for Model\n",
    "total_parameters = []\n",
    "for p in model.parameters():\n",
    "    total_parameters.append(p.numel())\n",
    "\n",
    "print(f\"Total Number of Parameters for Model Training : { sum(total_parameters)} \" )\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model Parameters  : \" , hyperparameter)\n",
    "\n",
    "# Train Model with configured Parameter\n",
    "train_model(model, train_dataloader ,test_dataloader, device ,num_epochs,optimizer,loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAHWCAYAAACbsXOkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACuJUlEQVR4nOzdd3gUVdvH8e/uplcIJQk1gHRp0hEpShNEEKXYKCpYwIaVx66P8lhf7FhARUWKgg2kCgjSe+8l1ISWTuru+8dJFkIKSUiyCfw+17VXdmdnZ85uJpu559znPhaHw+FARERERERELovV1Q0QERERERG5Eii4EhERERERKQQKrkRERERERAqBgisREREREZFCoOBKRERERESkECi4EhERERERKQQKrkRERERERAqBgisREREREZFCoOBKRERERESkECi4EhERuYINHToUPz8/VzdDROSqoOBKREQK5Ntvv8VisbB27VpXN8Wlhg4disViyfbm5eXl6uaJiEgxcnN1A0REREo7T09Pvv766yzLbTabC1ojIiKuouBKRETkMrm5uXHPPfe4uhkiIuJiSgsUEZEitWHDBm6++WYCAgLw8/PjpptuYuXKlZnWSUlJ4bXXXqN27dp4eXlRrlw52rdvz/z5853rnDhxgmHDhlGlShU8PT0JDQ2lT58+HDx4MMd9v/fee1gsFg4dOpTluTFjxuDh4cHZs2cB2LNnD7fffjshISF4eXlRpUoVBg0aRHR0dKF8DhlplP/88w8PPvgg5cqVIyAggMGDBzvbcKHPPvuMhg0b4unpSaVKlRg5ciRRUVFZ1lu1ahU9e/akbNmy+Pr60rhxYz788MMs6x09epS+ffvi5+dHhQoVePrpp0lLSyuU9yYiIoZ6rkREpMhs27aNG264gYCAAJ599lnc3d354osv6NSpE0uWLKF169YAvPrqq4wdO5YHHniAVq1aERMTw9q1a1m/fj1du3YF4Pbbb2fbtm08+uijhIWFERkZyfz58wkPDycsLCzb/Q8YMIBnn32WadOm8cwzz2R6btq0aXTr1o2yZcuSnJxM9+7dSUpK4tFHHyUkJISjR4/y559/EhUVRWBg4CXf66lTp7Is8/DwICAgINOyUaNGUaZMGV599VV27drF559/zqFDh1i8eDEWi8X5ebz22mt06dKFhx9+2LnemjVr+Pfff3F3dwdg/vz53HLLLYSGhvL4448TEhLCjh07+PPPP3n88ced+0xLS6N79+60bt2a9957jwULFvD+++9Tq1YtHn744Uu+NxERySOHiIhIAXzzzTcOwLFmzZoc1+nbt6/Dw8PDsW/fPueyY8eOOfz9/R0dOnRwLmvSpImjV69eOW7n7NmzDsDx7rvv5rudbdu2dTRv3jzTstWrVzsAx6RJkxwOh8OxYcMGB+CYPn16vrc/ZMgQB5DtrXv37s71Mj6v5s2bO5KTk53L33nnHQfg+O233xwOh8MRGRnp8PDwcHTr1s2RlpbmXO+TTz5xAI6JEyc6HA6HIzU11VGjRg1H9erVHWfPns3UJrvdnqV9r7/+eqZ1mjVrluVzERGRy6O0QBERKRJpaWnMmzePvn37UrNmTefy0NBQ7rrrLpYtW0ZMTAwAZcqUYdu2bezZsyfbbXl7e+Ph4cHixYuzTaHLzcCBA1m3bh379u1zLps6dSqenp706dMHwNkzNXfuXBISEvK1fQAvLy/mz5+f5fa///0vy7ojRoxw9jwBPPzww7i5uTF79mwAFixYQHJyMk888QRW6/l/08OHDycgIIBZs2YBJt3ywIEDPPHEE5QpUybTPjJ6wC700EMPZXp8ww03sH///ny/VxERyZmCKxERKRInT54kISGBunXrZnmufv362O12Dh8+DMDrr79OVFQUderUoVGjRjzzzDNs3rzZub6npydvv/02f/31F8HBwXTo0IF33nmHEydOXLId/fv3x2q1MnXqVAAcDgfTp093jgMDqFGjBqNHj+brr7+mfPnydO/enU8//TTP461sNhtdunTJcmvatGmWdWvXrp3psZ+fH6Ghoc6xYxnjwy7+3Dw8PKhZs6bz+Yxg8dprr71k+7y8vKhQoUKmZWXLls13oCoiIrlTcCUiIi7XoUMH9u3bx8SJE7n22mv5+uuvue666zKVN3/iiSfYvXs3Y8eOxcvLi5deeon69euzYcOGXLddqVIlbrjhBqZNmwbAypUrCQ8PZ+DAgZnWe//999m8eTP/+c9/OHfuHI899hgNGzbkyJEjhf+Gi5lKwouIFA8FVyIiUiQqVKiAj48Pu3btyvLczp07sVqtVK1a1bksKCiIYcOG8dNPP3H48GEaN27Mq6++mul1tWrV4qmnnmLevHls3bqV5ORk3n///Uu2ZeDAgWzatIldu3YxdepUfHx86N27d5b1GjVqxIsvvsg///zD0qVLOXr0KOPHj8//m8/FxamPcXFxHD9+3FmUo3r16gBZPrfk5GQOHDjgfL5WrVoAbN26tVDbJyIiBafgSkREioTNZqNbt2789ttvmcqlR0REMHnyZNq3b+9Myzt9+nSm1/r5+XHNNdeQlJQEQEJCAomJiZnWqVWrFv7+/s51cnP77bdjs9n46aefmD59Orfccgu+vr7O52NiYkhNTc30mkaNGmG1WvO0/fz48ssvSUlJcT7+/PPPSU1N5eabbwagS5cueHh48NFHH+FwOJzrTZgwgejoaHr16gXAddddR40aNRg3blyWEu0Xvk5ERIqPSrGLiMhlmThxInPmzMmy/PHHH+e///0v8+fPp3379jzyyCO4ubnxxRdfkJSUxDvvvONct0GDBnTq1InmzZsTFBTE2rVr+fnnnxk1ahQAu3fv5qabbmLAgAE0aNAANzc3Zs6cSUREBIMGDbpkGytWrEjnzp354IMPiI2NzZIS+PfffzNq1Cj69+9PnTp1SE1N5fvvv8dms3H77bdfcvupqan88MMP2T532223ZQrkkpOTne9l165dfPbZZ7Rv355bb70VMD1+Y8aM4bXXXqNHjx7ceuutzvVatmzpnKzYarXy+eef07t3b5o2bcqwYcMIDQ1l586dbNu2jblz516y3SIiUshcXK1QRERKqYzS4jndDh8+7HA4HI7169c7unfv7vDz83P4+Pg4Onfu7Fi+fHmmbf33v/91tGrVylGmTBmHt7e3o169eo4333zTWbL81KlTjpEjRzrq1avn8PX1dQQGBjpat27tmDZtWp7b+9VXXzkAh7+/v+PcuXOZntu/f7/jvvvuc9SqVcvh5eXlCAoKcnTu3NmxYMGCS243t1LsgOPAgQOZPq8lS5Y4RowY4ShbtqzDz8/PcffddztOnz6dZbuffPKJo169eg53d3dHcHCw4+GHH85Sct3hcDiWLVvm6Nq1q8Pf39/h6+vraNy4sePjjz/O1D5fX98sr3vllVccOg0QESlcFodDuQMiIiJF7dtvv2XYsGGsWbOGFi1auLo5IiJSBDTmSkREREREpBAouBIRERERESkECq5EREREREQKgcZciYiIiIiIFAL1XImIiIiIiBQCBVciIiIiIiKFQJMIZ8Nut3Ps2DH8/f2xWCyubo6IiIiIiLiIw+EgNjaWSpUqYbXm3jel4Cobx44do2rVqq5uhoiIiIiIlBCHDx+mSpUqua6j4Cob/v7+gPkAAwICinx/KSkpzJs3j27duuHu7l7k+5Mrh44dKQgdN1IQOm6koHTsSEGUpOMmJiaGqlWrOmOE3Ci4ykZGKmBAQECxBVc+Pj4EBAS4/OCR0kXHjhSEjhspCB03UlA6dqQgSuJxk5fhQipoISIiIiIiUggUXImIiIiIiBQCBVciIiIiIiKFQGOuRERERKRUSEtLIyUlxdXNkGKQkpKCm5sbiYmJpKWlFem+bDYbbm5uhTIFk4IrERERESnx4uLiOHLkCA6Hw9VNkWLgcDgICQnh8OHDxTLvrI+PD6GhoXh4eFzWdhRciYiIiEiJlpaWxpEjR/Dx8aFChQrFcrItrmW324mLi8PPz++SE/deDofDQXJyMidPnuTAgQPUrl37svan4EpERERESrSUlBQcDgcVKlTA29vb1c2RYmC320lOTsbLy6tIgysAb29v3N3dOXTokHOfBaWCFiIiIiJSKqjHSopKYQVwCq5EREREREQKgYIrERERERGRQqDgSkRERESklAgLC2PcuHGubobkQMGViIiIiEghs1gsud5effXVAm13zZo1jBgx4rLa1qlTJ5544onL2oZkT9UCRUREREQK2fHjx533p06dyssvv8yuXbucy/z8/Jz3HQ4HaWlpuLld+tS8QoUKhdtQKVTquSrh3py1na4fLOHPzcdc3RQRERGREsHhcJCQnOqSW14nMQ4JCXHeAgMDsVgszsc7d+7E39+fv/76i+bNm+Pp6cmyZcvYt28fffr0ITg4GD8/P1q2bMmCBQsybffitECLxcLXX3/Nbbfdho+PD7Vr1+b333+/rM/3l19+oWHDhnh6ehIWFsb777+f6fnPPvuM2rVr4+XlRXBwMHfccYfzuZ9//plGjRrh7e1NuXLl6NKlC/Hx8ZfVntJEPVclXERMEnsi4zgRnejqpoiIiIiUCOdS0mjw8lyX7Hv7693x8SicU+jnn3+e9957j5o1a1K2bFkOHz5Mz549efPNN/H09GTSpEn07t2bXbt2Ua1atRy389prr/HOO+/w7rvv8vHHH3P33Xdz6NAhgoKC8t2mdevWMWDAAF599VUGDhzI8uXLeeSRRyhXrhxDhw5l7dq1PPbYY3z//fe0a9eOM2fOsHTpUsD01t15552888473HbbbcTGxrJ06dI8B6RXAgVXJVyAt/kVxSSmurglIiIiIlKYXn/9dbp27ep8HBQURJMmTZyP33jjDWbOnMnvv//OqFGjctzO0KFDufPOOwF46623+Oijj1i9ejU9evTId5s++OADbrrpJl566SUA6tSpw/bt23n33XcZOnQo4eHh+Pr6csstt+Dv70/16tVp1qwZYIKr1NRU+vXrR/Xq1QFo1KhRvttQmim4KuECvNwBiDmX4uKWiIiIiJQM3u42tr/e3WX7LiwtWrTI9DguLo5XX32VWbNmOQOVc+fOER4enut2Gjdu7Lzv6+tLQEAAkZGRBWrTjh076NOnT6Zl119/PePGjSMtLY2uXbtSvXp1atasSY8ePejRo4czJbFJkybcdNNNNGrUiO7du9OtWzfuuOMOypYtW6C2lEYac1XCBXgruBIRERG5kMViwcfDzSU3i8VSaO/D19c30+Onn36amTNn8tZbb7F06VI2btxIo0aNSE5OznU77u7uWT4fu91eaO28kL+/P+vXr+enn34iNDSUl19+mSZNmhAVFYXNZmP+/Pn89ddfNGjQgI8//pi6dety4MCBImlLSaTgqoQLzAiuEhVciYiIiFzJ/v33X4YOHcptt91Go0aNCAkJ4eDBg8Xahvr16/Pvv/9maVedOnWw2UyvnZubG126dOGdd95h8+bNHDx4kL///hswgd3111/Pa6+9xoYNG/Dw8GDmzJnF+h5cSWmBJdz5tECNuRIRERG5ktWuXZsZM2bQu3dvLBYLL730UpH1QJ08eZKNGzdmWhYaGspTTz1Fy5YteeONNxg4cCArVqzgk08+4bPPPgPgzz//ZP/+/XTo0IGyZcsye/Zs7HY7devWZdWqVSxcuJBu3bpRsWJFVq1axcmTJ6lfv36RvIeSSMFVCXe+oIV6rkRERESuZB988AH33Xcf7dq1o3z58jz33HPExMQUyb4mT57M5MmTMy174403ePHFF5k2bRovv/wyb7zxBqGhobz++usMHToUgDJlyjBjxgxeffVVEhMTqV27Nj/99BMNGzZkx44d/PPPP4wbN46YmBiqV6/O+++/z80331wk76EkUnBVwmX0XEVrzJWIiIhIqTR06FBncALQqVOnbMuTh4WFOdPrMowcOTLT44vTBLPbTlRUVK7tWbx4ca7P33777dx+++3ZPte+ffscX1+/fn3mzJmT67avdBpzVcIFqqCFiIiIiEipoOCqhMuoFhifnEZqWtHk3IqIiIiIyOVTcFXC+Xudz9yM1UTCIiIiIiIlloKrEs7dZsXHw5S91LgrEREREZGSS8FVKeAsx66KgSIiIiIiJZaCq1LgfFELpQWKiIiIiJRUCq5KAc11JSIiIiJS8im4KgU015WIiIiISMmn4KoUCNBcVyIiIiIiJZ6Cq1LAOeZKaYEiIiIiV5VOnTrxxBNPOB+HhYUxbty4XF9jsVj49ddfL3vfhbWdq4mCq1IgIH2uKxW0EBERESkdevfuTY8ePbJ9bunSpVgsFjZv3pzv7a5Zs4YRI0ZcbvMyefXVV2natGmW5cePH+fmm28u1H1d7Ntvv6VMmTJFuo/ipOCqFAhQz5WIiIhIqXL//fczf/58jhw5kuW5b775hhYtWtC4ceN8b7dChQr4+PgURhMvKSQkBE9Pz2LZ15VCwVUpoIIWIiIiIhdwOCA53jU3hyNPTbzllluoUKEC3377bablcXFxTJ8+nfvvv5/Tp09z5513UrlyZXx8fGjUqBE//fRTrtu9OC1wz549dOjQAS8vLxo0aMD8+fOzvOa5556jTp06+Pj4ULNmTV566SVSUsx55bfffstrr73Gpk2bsFgsWCwWZ5svTgvcsmULN954I97e3pQrV44RI0YQFxfnfH7o0KH07duX9957j9DQUMqVK8fIkSOd+yqI8PBw+vTpg5+fHwEBAQwYMICIiAjn85s2baJz5874+/sTEBBA8+bNWbt2LQCHDh2id+/elC1bFl9fXxo2bMjs2bML3Ja8cCvSrUuhUEELERERkQukJMBblVyz7/8cAw/fS67m5ubG4MGD+fbbb3nhhRewWCwATJ8+nbS0NO68807i4uJo3rw5zz33HAEBAcyaNYt7772XWrVq0apVq0vuw263069fP4KDg1m1ahXR0dGZxmdl8Pf359tvv6VSpUps2bKF4cOH4+/vz7PPPsvAgQPZunUrc+bMYcGCBQAEBgZm2UZ8fDzdu3enbdu2rFmzhsjISB544AFGjRqVKYBctGgRoaGhLFq0iL179zJw4ECaNm3K8OHDL/l+snt/t912G35+fixZsoTU1FRGjhzJwIEDWbx4MQB33303zZo14/PPP8dms7Fx40bc3c2588iRI0lOTuaff/7B19eX7du34+fnl+925IeCq1Lg/DxXGnMlIiIiUlrcd999vPvuuyxZsoROnToBJiXw9ttvJzAwkMDAQJ5++mnn+o8++ihz585l2rRpeQquFixYwM6dO5k7dy6VKplg86233soyTurFF1903g8LC+Ppp59mypQpPPvss3h7e+Pn54ebmxshISE57mvy5MkkJiYyadIkfH1NcPnJJ5/Qu3dv3n77bYKDgwEoW7Ysn3zyCTabjXr16tGrVy8WLlxYoOBqyZIlbNmyhQMHDlC1alUAJk2aRMOGDVmzZg0tW7YkPDycZ555hnr16gFQu3Zt5+vDw8O5/fbbadSoEQA1a9bMdxvyS8FVKZCRFqieKxERERHA3cf0ILlq33lUr1492rVrx8SJE+nUqRN79+5l6dKlvP766wCkpaXx1ltvMW3aNI4ePUpycjJJSUl5HlO1Y8cOqlat6gysANq2bZtlvalTp/LRRx+xb98+4uLiSE1NJSAgIM/vI2NfTZo0cQZWANdffz12u51du3Y5g6uGDRtis9mc64SGhrJly5Z87SvD7t27qVq1qjOwAmjQoAFlypRhx44dtGzZktGjR/PAAw/w/fff06VLF/r370+tWrUAeOyxx3j44YeZN28eXbp04fbbby/QOLf80JirUiCjFLvGXImIiIgAFotJzXPFLT29L6/uv/9+fvnlF2JjY/nmm2+oVasWHTt2BODdd9/lww8/5LnnnmPRokVs3LiR7t27k5ycXGgf1YoVK7j77rvp2bMnf/75Jxs2bOCFF14o1H1cKCMlL4PFYsFutxfJvsBUOty2bRu9evXi77//pkGDBsycOROABx54gP3793PvvfeyZcsWWrRowccff1xkbQEFV6VCRs9VUqqdxJQ0F7dGRERERPJqwIABWK1WJk+ezKRJk7jvvvuc46/+/fdf+vTpwz333EOTJk2oWbMmu3fvzvO269evz+HDhzl+/Lhz2cqVKzOts3z5cqpXr84LL7xAixYtqF27NocOHcq0joeHB2lpuZ9j1q9fn02bNhEfH+9c9u+//2K1Wqlbt26e25wfderU4fDhwxw+fNi5bPv27URFRdGgQYNM6z355JPMmzePfv368c033zifq1q1Kg899BAzZszgqaee4quvviqStmZQcFUK+Hu5OS+SxGrclYiIiEip4efnx8CBAxkzZgzHjx9n6NChzudq167N/PnzWb58OTt27ODBBx/MVAnvUrp06UKdOnUYMmQImzZtYunSpbzwwguZ1qlduzbh4eFMmTKFffv28dFHHzl7djKEhYVx4MABNm7cyKlTp0hKSsqyr7vvvhsvLy+GDBnC1q1bWbRoEY8++ij33nuvMyWwoNLS0ti4cWOm244dO+jUqRONGjXi7rvvZv369axevZrBgwfTsWNHWrRowblz5xg1ahSLFy/m0KFD/Pvvv6xZs4b69esD8MQTTzB37lwOHDjA+vXrWbRokfO5oqLgqhSwWi34eWYUtVBqoIiIiEhpcv/993P27Fm6d++eaXzUiy++yHXXXUf37t3p1KkTISEh9O3bN8/btVqtzJw5k3PnztGqVSseeOAB3nzzzUzr3HrrrTz55JOMGjWKpk2bsnz5cl566aVM69x+++306NGDzp07U6FChWzLwfv4+DB37lzOnDlDy5YtueOOO7jpppv45JNP8vdhZCMuLo5mzZpluvXp0weLxcLMmTMpW7YsHTp0oEuXLtSsWZOpU6cCYLPZOH36NIMHD6ZOnToMGDCAm2++mddeew0wQdvIkSOpX78+PXr0oE6dOnz22WeX3d7cWByOPBbrv4rExMQQGBhIdHR0vgf7FURKSgqzZ8+mZ8+eWfJUM1z/v785GnWOmY+0o1m1skXeJikd8nLsiFxMx40UhI4bKajCOHYSExM5cOAANWrUwMvLq5BbKCWR3W4nJiaGgIAArNai7w/K7RjLT2ygnqtSIkBFLURERERESjQFV6VEoOa6EhEREREp0UpEcPXpp58SFhaGl5cXrVu3ZvXq1Tmu26lTJywWS5Zbr169nOvExcUxatQoqlSpgre3Nw0aNGD8+PHF8VaKjOa6EhEREREp2VweXE2dOpXRo0fzyiuvsH79epo0aUL37t2JjIzMdv0ZM2Zw/Phx523r1q3YbDb69+/vXGf06NHMmTOHH374gR07dvDEE08watQofv/99+J6W4UuIy1QBS1EREREREomlwdXH3zwAcOHD2fYsGHOHiYfHx8mTpyY7fpBQUGEhIQ4b/Pnz8fHxydTcLV8+XKGDBlCp06dCAsLY8SIETRp0iTXHrGSLqPnSmOuRERE5GqlOmxSVArr2HIrlK0UUHJyMuvWrWPMmDHOZVarlS5durBixYo8bWPChAkMGjQIX19f57J27drx+++/c99991GpUiUWL17M7t27+b//+79st5GUlJSpnn9MTAxgqtukpBR9MJOxj9z25edh4uCo+ORiaZOUDnk5dkQupuNGCkLHjRRUYRw7DocDh8NBUlISnp6ehdU0KcEygh2Hw4Hdbi/y/cXFxTn3efGxmp9j16XB1alTp0hLS8sy8VhwcDA7d+685OtXr17N1q1bmTBhQqblH3/8MSNGjKBKlSq4ublhtVr56quv6NChQ7bbGTt2rLMe/oXmzZuHj49PPt7R5Zk/f36Ozx05bgFs7D4QzuzZB4utTVI65HbsiOREx40UhI4bKajLPXaCgoKw2+1UqFABi8VSSK2Sku706dNFun2Hw0FycjKnTp3i7Nmz7NmzJ8s6CQkJed6eS4OryzVhwgQaNWpEq1atMi3/+OOPWblyJb///jvVq1fnn3/+YeTIkVSqVIkuXbpk2c6YMWMYPXq083FMTAxVq1alW7duxTbP1fz58+natWuO8z8kbTjGjINb8S1bgZ49mxd5m6R0yMuxI3IxHTdSEDpupKAK69hJSUkhPDy8yE+2pWRwOBwkJibi5eVVLMF0hQoVaNiwYbb7yshqywuXBlfly5fHZrMRERGRaXlERAQhISG5vjY+Pp4pU6bw+uuvZ1p+7tw5/vOf/zBz5kxnBcHGjRuzceNG3nvvvWyDK09Pz2y7mN3d3Yv1H0hu+yvrZyYzi01M1T81yaK4j1W5Mui4kYLQcSMFdbnHjru7O3Xq1CE5ObkQWyUlVUpKCv/88w8dOnQo8u8cd3d3bDZbrs/nlUuDKw8PD5o3b87ChQvp27cvYGZjXrhwIaNGjcr1tdOnTycpKYl77rkn0/KMcVIXz+Rss9mKJV+zqAR4aZ4rERERubpZrVa8vLxc3QwpBjabjdTUVLy8vErVBR2XpwWOHj2aIUOG0KJFC1q1asW4ceOIj49n2LBhAAwePJjKlSszduzYTK+bMGECffv2pVy5cpmWBwQE0LFjR5555hm8vb2pXr06S5YsYdKkSXzwwQfF9r4KW6CP5rkSERERESnJXB5cDRw4kJMnT/Lyyy9z4sQJmjZtypw5c5xFLsLDw7P0Qu3atYtly5Yxb968bLc5ZcoUxowZw913382ZM2eoXr06b775Jg899FCRv5+i4pxEODEFh8OhgZwiIiIiIiWMy4MrgFGjRuWYBrh48eIsy+rWrZtrLfqQkBC++eabwmpeiZAxiXBKmoPEFDveHjnnhYqIiIiISPFz+STCkje+HjZsVtNbpYmERURERERKHgVXpYTFYrmgqIWCKxERERGRkkbBVSmSkRqoohYiIiIiIiWPgqtS5MKiFiIiIiIiUrIouCpFArxNWqDGXImIiIiIlDwKrkoRZ8/VOU0kLCIiIiJS0ii4KkUCNeZKRERERKTEUnBVijgLWmjMlYiIiIhIiaPgqhTJKMWuMVciIiIiIiWPgqtS5Hwpdo25EhEREREpaRRclSKBSgsUERERESmxFFyVIprnSkRERESk5FJwVYpkzHOltEARERERkZJHwVUpktFzpYIWIiIiIiIlj4KrUiRjzFVsYgp2u8PFrRERERERkQspuCpFMqoF2h0Qn6zUQBERERGRkkTBVSni6WbFw2Z+ZTGJCq5EREREREoSBVeliMVicRa1iE7QuCsRERERkZJEwVUpo3LsIiIiIiIlk4KrUiZj3FWMKgaKiIiIiJQoCq5KGWdwpTFXIiIiIiIlioKrUibAK33MlXquRERERERKFAVXpYzSAkVERERESiYFV6VMoLcKWoiIiIiIlEQKrkoZZ7XAcxpzJSIiIiJSkii4KmUy5rlSz5WIiIiISMmi4KqUyei5UkELEREREZGSRcFVKROoghYiIiIiIiWSgqtSJqNaYKzmuRIRERERKVEUXJUyGfNcqedKRERERKRkUXBVyjh7rpJSSbM7XNwaERERERHJoOCqlMkoaAEQq4qBIiIiIiIlhoKrUsbDzYq3uw3QXFciIiIiIiWJgqtSSHNdiYiIiIiUPAquSiHNdSUiIiIiUvIouCqFAjTXlYiIiIhIiaPgqhRyTiSstEARERERkRJDwVUpdH6uKxW0EBEREREpKRRclUIB6rkSERERESlxFFyVQipoISIiIiJS8ii4KoUCVdBCRERERKTEUXBVCp2f50pjrkRERERESgoFV6VQRlqgeq5EREREREoOBVelUEZBC425EhEREREpORRclULOnitVCxQRERERKTEUXJVC5wtaaMyViIiIiEhJoeCqFMooaHEuJY3kVLuLWyMiIiIiIlBCgqtPP/2UsLAwvLy8aN26NatXr85x3U6dOmGxWLLcevXqlWm9HTt2cOuttxIYGIivry8tW7YkPDy8qN9KsfDzdHPej1VqoIiIiIhIieDy4Grq1KmMHj2aV155hfXr19OkSRO6d+9OZGRktuvPmDGD48ePO29bt27FZrPRv39/5zr79u2jffv21KtXj8WLF7N582ZeeuklvLy8iuttFSk3m9UZYKmohYiIiIhIyeB26VWK1gcffMDw4cMZNmwYAOPHj2fWrFlMnDiR559/Psv6QUFBmR5PmTIFHx+fTMHVCy+8QM+ePXnnnXecy2rVqlVE78A1Ar3diUtK1VxXIiIiIiIlhEuDq+TkZNatW8eYMWOcy6xWK126dGHFihV52saECRMYNGgQvr6+ANjtdmbNmsWzzz5L9+7d2bBhAzVq1GDMmDH07ds3220kJSWRlJTkfBwTEwNASkoKKSlF3zOUsY/87Mvf0wbAmbhzpKT4Fkm7pOQryLEjouNGCkLHjRSUjh0piJJ03OSnDRaHw+Eowrbk6tixY1SuXJnly5fTtm1b5/Jnn32WJUuWsGrVqlxfv3r1alq3bs2qVato1aoVACdOnCA0NBQfHx/++9//0rlzZ+bMmcN//vMfFi1aRMeOHbNs59VXX+W1117Lsnzy5Mn4+Phc5rssGh9ttbEv1sLQ2mk0K++yX6GIiIiIyBUtISGBu+66i+joaAICAnJd1+VpgZdjwoQJNGrUyBlYgem5AujTpw9PPvkkAE2bNmX58uWMHz8+2+BqzJgxjB492vk4JiaGqlWr0q1bt0t+gIUhJSWF+fPn07VrV9zd3fP0mt/PbmDfzpPUrH8tPVtWLeIWSklVkGNHRMeNFISOGykoHTtSECXpuMnIassLlwZX5cuXx2azERERkWl5REQEISEhub42Pj6eKVOm8Prrr2fZppubGw0aNMi0vH79+ixbtizbbXl6euLp6Zllubu7e7H+MvOzvzI+pr3xyQ6XH3DiesV9rMqVQceNFISOGykoHTtSECXhuMnP/l1aLdDDw4PmzZuzcOFC5zK73c7ChQszpQlmZ/r06SQlJXHPPfdk2WbLli3ZtWtXpuW7d++mevXqhdd4F8uY6ypGpdhFREREREoEl6cFjh49miFDhtCiRQtatWrFuHHjiI+Pd1YPHDx4MJUrV2bs2LGZXjdhwgT69u1LuXLlsmzzmWeeYeDAgXTo0ME55uqPP/5g8eLFxfGWikWAl4mgY1SKXURERESkRHB5cDVw4EBOnjzJyy+/zIkTJ2jatClz5swhODgYgPDwcKzWzB1su3btYtmyZcybNy/bbd52222MHz+esWPH8thjj1G3bl1++eUX2rdvX+Tvp7gEeJvgSvNciYiIiIiUDC4PrgBGjRrFqFGjsn0uu96munXrcqkih/fddx/33XdfYTSvRArwykgL1DxXIiIiIiIlgUvHXEnBBXorLVBEREREpCRRcFVKZaQFqqCFiIiIiEjJoOCqlDpf0EJpgSIiIiIiJYGCq1LKWYr9XMolx5+JiIiIiEjRU3BVSmWMuUpOs5OUandxa0RERERERMFVKeXr4YbVYu6rqIWIiIiIiOspuCqlrFYL/l4qaiEiIiIiUlIouCrFMsZdaSJhERERERHXU3BVip2f60oVA0VEREREXE3BVSkWoLRAEREREZESQ8FVKXZ+risFVyIiIiIirqbgqhTTmCsRERERkZJDwVUpVsbHA4CzCQquRERERERcTcFVKRYS4AXAsahzLm6JiIiIiIgouCrFKpf1BuCogisREREREZdTcFWKVS6THlydVXAlIiIiIuJqCq5KsSrpPVen45M5l5zm4taIiIiIiFzdFFyVYoHe7vh62AClBoqIiIiIuJqCq1LMYrFo3JWIiIiISAmh4KqU07grEREREZGSQcFVKXe+5yrBxS0REREREbm6Kbgq5SqX8QHUcyUiIiIi4moKrko5jbkSERERESkZFFyVchpzJSIiIiJSMii4KulijsHh1RAbke3TGXNdnYhJJCXNXpwtExERERGRCyi4Kun+eAImdIXdc7J9uoKfJx42K3YHnIhOLN62iYiIiIiIk4Krks4/2PyMy77nymq1UKmMF6BxVyIiIiIirqTgqqTzSw+uYk/kuIqzqIXGXYmIiIiIuIyCq5LOL/eeK7igqIV6rkREREREXEbBVUmXp+BKc12JiIiIiLiagquSzj/E/MwtuNJcVyIiIiIiLqfgqqRzjrmKAIcj21WUFigiIiIi4noKrkq6jOAqLQkSo7JdpcoFPVd2e/YBmIiIiIiIFC0FVyWduxd4BZr7cZHZrhIS6IXVAsmpdk7FJxVj40REREREJIOCq9LgEuXY3W1WggPS57pSUQsREREREZdQcFUaOCsGZt9zBRp3JSIiIiLiagquSgNnxcBLTyR8RD1XIiIiIiIuoeCqNLhEWiBc0HOl4EpERERExCUUXJUGeUkL1FxXIiIiIiIupeCqNHAGV+q5EhEREREpqRRclQb+l+65unCuK0cOkw2LiIiIiEjRUXBVGvilF7TIZcxVpfSeq7ikVGLOpRZHq0RERERE5AIKrkoDv4rmZ2IUpGY/SbCPhxtBvh4AHIlKKKaGiYiIiIhIBgVXpYF3WbCZwIm4iBxX07grERERERHXUXBVGlgsF5Rjz0NwpYqBIiIiIiLFTsFVaeGsGJhLcFVWPVciIiIiIq6i4Kq08E8vapGXcuzquRIRERERKXYlIrj69NNPCQsLw8vLi9atW7N69eoc1+3UqRMWiyXLrVevXtmu/9BDD2GxWBg3blwRtb6YZBS10ETCIiIiIiIlksuDq6lTpzJ69GheeeUV1q9fT5MmTejevTuRkdkHETNmzOD48ePO29atW7HZbPTv3z/LujNnzmTlypVUqlSpqN9G0ctDOXYVtBARERERcR2XB1cffPABw4cPZ9iwYTRo0IDx48fj4+PDxIkTs10/KCiIkJAQ523+/Pn4+PhkCa6OHj3Ko48+yo8//oi7u3txvJWi5ey5ynnMVcZEwqfjkzmXnFYcrRIRERERkXRurtx5cnIy69atY8yYMc5lVquVLl26sGLFijxtY8KECQwaNAhfX1/nMrvdzr333sszzzxDw4YNL7mNpKQkkpLOzx8VExMDQEpKCikpKXl9OwWWsY/c9mXxLo8bYI89QVoO6/m4ga+HjfjkNA6diqVWBd9s15MrR16OHZGL6biRgtBxIwWlY0cKoiQdN/lpg0uDq1OnTpGWlkZwcHCm5cHBwezcufOSr1+9ejVbt25lwoQJmZa//fbbuLm58dhjj+WpHWPHjuW1117LsnzevHn4+PjkaRuFYf78+Tk+VyZhPx2BpFOHmDd7do7r+dtsxGPh1/n/UL+MowhaKSVRbseOSE503EhB6LiRgtKxIwVREo6bhISEPK/r0uDqck2YMIFGjRrRqlUr57J169bx4Ycfsn79eiwWS562M2bMGEaPHu18HBMTQ9WqVenWrRsBAQGF3u6LpaSkMH/+fLp27ZpzCmPMMdj1Kl5psfS8uQdYss/onHF6PSd2n6Jy7Ub0bFmlCFstJUGejh2Ri+i4kYLQcSMFpWNHCqIkHTcZWW154dLgqnz58thsNiIiMo8jioiIICQkJNfXxsfHM2XKFF5//fVMy5cuXUpkZCTVqlVzLktLS+Opp55i3LhxHDx4MMu2PD098fT0zLLc3d29WH+Zue6vjCnKYbGn4p4SC77ls12tapDpaTsRm+TyA1GKT3Efq3Jl0HEjBaHjRgpKx44UREk4bvKzf5cWtPDw8KB58+YsXLjQucxut7Nw4ULatm2b62unT59OUlIS99xzT6bl9957L5s3b2bjxo3OW6VKlXjmmWeYO3dukbyPYmFzB59y5n6uFQNNcKWKgSIiIiIixcvlaYGjR49myJAhtGjRglatWjFu3Dji4+MZNmwYAIMHD6Zy5cqMHTs20+smTJhA3759KVeuXKbl5cqVy7LM3d2dkJAQ6tatW7Rvpqj5hUDC6fSKgddmu4rmuhIRERERcQ2XB1cDBw7k5MmTvPzyy5w4cYKmTZsyZ84cZ5GL8PBwrNbMHWy7du1i2bJlzJs3zxVNdh3/YIjclms5ds11JSIiIiLiGi4PrgBGjRrFqFGjsn1u8eLFWZbVrVsXhyPvlfCyG2dVKvmlV1XMw1xXJ2ISSUmz425z+VRmIiIiIiJXBZ15lyYZwVVszsFVBT9PPGxW7A44EZ1YTA0TEREREREFV6WJs+cq54IWVquF0DJegMZdiYiIiIgUJwVXpYl/RnAVmetqGnclIiIiIlL8FFyVJn7pc3/lUoodLgiu1HMlIiIiIlJsFFyVJn557Lkqq54rEREREZHipuCqNMlIC0yOheT4HFdTz5WIiIiISPErUHB1+PBhjhw54ny8evVqnnjiCb788stCa5hkw8MP3H3M/VxSAzWRsIiIiIhI8StQcHXXXXexaNEiAE6cOEHXrl1ZvXo1L7zwAq+//nqhNlAuYLHkKTWwShkTgB2NOofdnvf5wEREREREpOAKFFxt3bqVVq1aATBt2jSuvfZali9fzo8//si3335bmO2Ti/mnF7XIpRx7SKAXFgskp9o5FZ9UTA0TEREREbm6FSi4SklJwdPTE4AFCxZw6623AlCvXj2OHz9eeK2TrPwqmp+59Fx5uFkJ9k+f60pFLUREREREikWBgquGDRsyfvx4li5dyvz58+nRowcAx44do1y5coXaQLlIHsuxV9G4KxERERGRYlWg4Ortt9/miy++oFOnTtx55500adIEgN9//92ZLihFxNlzFZHrairHLiIiIiJSvNwK8qJOnTpx6tQpYmJiKFu2rHP5iBEj8PHxKbTGSTacY64uEVypHLuIiIiISLEqUM/VuXPnSEpKcgZWhw4dYty4cezatYuKFSsWagPlIs60wNyDq2sq+gGwfN9pHA5VDBQRERERKWoFCq769OnDpEmTAIiKiqJ169a8//779O3bl88//7xQGygXyWNaYJcGwXi6WdkbGcfmI9HF0DARERERkatbgYKr9evXc8MNNwDw888/ExwczKFDh5g0aRIfffRRoTZQLpKRFhh/EtJSc1wtwMud7g3NujPWH8lxPRERERERKRwFCq4SEhLw9/cHYN68efTr1w+r1UqbNm04dOhQoTZQLuJTDixWwGECrFzc3rwKAL9vOkZyqr0YGiciIiIicvUqUHB1zTXX8Ouvv3L48GHmzp1Lt27dAIiMjCQgIKBQGygXsdrAN2+pge2vKU9Ff0/OJqTw986c58USEREREZHLV6Dg6uWXX+bpp58mLCyMVq1a0bZtW8D0YjVr1qxQGyjZ8A82Py8RXNmsFm5rVhlQaqCIiIiISFErUHB1xx13EB4eztq1a5k7d65z+U033cT//d//FVrjJAd+eQuu4Hxq4KJdkZyJTy7KVomIiIiIXNUKFFwBhISE0KxZM44dO8aRI6ZXpFWrVtSrV6/QGic5yAiuLlGOHaBOsD+NKgeSkubg941Hi7hhIiIiIiJXrwIFV3a7nddff53AwECqV69O9erVKVOmDG+88QZ2uwonFLl89FwB9LvOpAb+sl7BlYiIiIhIUSlQcPXCCy/wySef8L///Y8NGzawYcMG3nrrLT7++GNeeumlwm6jXCyjHHvciTytfmuTSrhZLWw5Gs3uiNgibJiIiIiIyNWrQMHVd999x9dff83DDz9M48aNady4MY888ghfffUV3377bSE3UbLIR1ogQDk/TzrXMxUGf1FhCxERERGRIlGg4OrMmTPZjq2qV68eZ86cuexGySXkMy0Q4Pb01MBfNxwlze4oilaJiIiIiFzVChRcNWnShE8++STL8k8++YTGjRtfdqPkEi4sxe7IW6DUuV5Fyvi4ExGTxL97TxVh40RERERErk5uBXnRO++8Q69evViwYIFzjqsVK1Zw+PBhZs+eXagNlGxk9FylJkJSDHgFXvIlnm42bm1SiUkrDvHL+iN0qFOhiBspIiIiInJ1KVDPVceOHdm9eze33XYbUVFRREVF0a9fP7Zt28b3339f2G2Ui7l7g2d6QJXHcVcAt19n5ryau+0EsYkpRdEyEREREZGrVoF6rgAqVarEm2++mWnZpk2bmDBhAl9++eVlN0wuwT8YkqJNxcAKdfL0ksZVAqlVwZd9J+P5a8sJBrSsWsSNFBERERG5ehR4EmFxMWdRi8g8v8RisXB7c9N79bOqBoqIiIiIFCoFV6WVsxx73ua6ynBbs8pYLLD6wBkOn0kogoaJiIiIiFydFFyVVgUoxw4QGujN9bXKA5rzSkRERESkMOVrzFW/fv1yfT4qKupy2iL54V+w4Aqg33WVWbb3FLM2H+eJLnkbryUiIiIiIrnLV3AVGJh7ye/AwEAGDx58WQ2SPPILMT/zmRYIcFO9YKwW2BMZx9Goc1Qu413IjRMRERERufrkK7j65ptviqodkl9+Fc3PfBS0yBDo48511cqy9tBZFu+K5O7W1Qu5cSIiIiIiVx+NuSqt/NN7ruLy33MF0KmumUR48a6ThdUiEREREZGrmoKr0iqjoMW5s5CalO+Xd6prer6W7z1Fcqq9MFsmIiIiInJVUnBVWnmXBZuHuV+A1MAGoQGU9/MkPjmNtQfPFHLjRERERESuPgquSiuLpcDl2AGsVgsd66SnBu5WaqCIiIiIyOVScFWaOYta5D+4gvPjrhbtzH/Pl4iIiIiIZKbgqjS7jHLsADfULp+pJLuIiIiIiBScgqvSLKPnqoDBVRkfD5pVKwvA4l3qvRIRERERuRwKrkqzcrXMz8jtBd5EpzoqyS4iIiIiUhgUXJVmlZqZn8c2FHgTKskuIiIiIlI4FFyVZqFNAAvEHIXYghW1aFhJJdlFRERERAqDgqvSzNMfKtQ19wvYe6WS7CIiIiIihUPBVWlX6Trz89j6Am8ioyS7ilqIiIiIiBRciQiuPv30U8LCwvDy8qJ169asXr06x3U7deqExWLJcuvVqxcAKSkpPPfcczRq1AhfX18qVarE4MGDOXbsWHG9neJVOT24Olrw4CqjJPvuiDiOqSS7iIiIiEiBuDy4mjp1KqNHj+aVV15h/fr1NGnShO7duxMZmX0vyowZMzh+/LjztnXrVmw2G/379wcgISGB9evX89JLL7F+/XpmzJjBrl27uPXWW4vzbRUfZ1GL9eBwFGgTmUuyKzVQRERERKQgXB5cffDBBwwfPpxhw4bRoEEDxo8fj4+PDxMnTsx2/aCgIEJCQpy3+fPn4+Pj4wyuAgMDmT9/PgMGDKBu3bq0adOGTz75hHXr1hEeHl6cb614BF8LVjdIOA3Rhwu8mYyS7IuUGigiIiIiUiBurtx5cnIy69atY8yYMc5lVquVLl26sGLFijxtY8KECQwaNAhfX98c14mOjsZisVCmTJlsn09KSiIpKcn5OCYmBjAphikpKXlqx+XI2EfB9mXDrWIDLCc2kxq+BodvaIHa0L5WEO/PNyXZ488l4eHm8rhb8uDyjh25Wum4kYLQcSMFpWNHCqIkHTf5aYNLg6tTp06RlpZGcHBwpuXBwcHs3Lnzkq9fvXo1W7duZcKECTmuk5iYyHPPPcedd95JQEBAtuuMHTuW1157LcvyefPm4ePjc8l2FJb58+cX6HWNU8pRAziw7Be2HyjYr9TuAD93G3HJaXw2fS51AguWYiiuUdBjR65uOm6kIHTcSEHp2JGCKAnHTUJCQp7XdWlwdbkmTJhAo0aNaNWqVbbPp6SkMGDAABwOB59//nmO2xkzZgyjR492Po6JiaFq1ap069Ytx4CsMKWkpDB//ny6du2Ku7t7vl9v2XgGZi2ilnc0YT17Frgd/yRuYebG4ySWrUnPHnULvB0pPpd77MjVSceNFISOGykoHTtSECXpuMnIassLlwZX5cuXx2azERGReQLciIgIQkJCcn1tfHw8U6ZM4fXXX8/2+YzA6tChQ/z999+5Bkmenp54enpmWe7u7l6sv8wC769qCwCsJzZjtdnAWrCUvs71Q5i58ThL957mJX35lSrFfazKlUHHjRSEjhspKB07UhAl4bjJz/5dOrDGw8OD5s2bs3DhQucyu93OwoULadu2ba6vnT59OklJSdxzzz1ZnssIrPbs2cOCBQsoV65cobe9RKlQH9y8ISkGzuwr8GY6qCS7iIiIiEiBubxqwejRo/nqq6/47rvv2LFjBw8//DDx8fEMGzYMgMGDB2cqeJFhwoQJ9O3bN0vglJKSwh133MHatWv58ccfSUtL48SJE5w4cYLk5ORieU/FzuYGoY3N/cuY70ol2UVERERECs7lY64GDhzIyZMnefnllzlx4gRNmzZlzpw5ziIX4eHhWC9Kc9u1axfLli1j3rx5WbZ39OhRfv/9dwCaNm2a6blFixbRqVOnInkfLlfpOji8ysx31WRggTfTqU4F1h06y+JdkdzVulohNlBERERE5Mrm8uAKYNSoUYwaNSrb5xYvXpxlWd26dXHkMGFuWFhYjs9d0SpfZ35eRs8VQOd6FXl//m6W7D5JdEIKgT7KjRYRERERyQuXpwVKIanUzPw8sRnSCj4fQMNKAdQL8Scp1c6MDUcKqXEiIiIiIlc+BVdXiqBa4BkAqYlw8tJzhOXEYrE40wF/Wh1+dfYCioiIiIgUgIKrK4XVCpWamvuXmRrYt1llvNyt7I6IY92hs5ffNhERERGRq4CCqytJpfRxV8cuL7gK8HKnd+NKAExeFX65rRIRERERuSoouLqSZIy7usyeK8CZGvjnluNEJVyhJexFRERERAqRgqsrSUbFwMjtkJJ4WZtqWrUM9UMDSE6188v6o4XQOBERERGRK5uCqytJYFXwKQ/2VIjYelmbUmELEREREZH8UXB1JbFYCm2+K4C+TSvh7W5jb2Qcaw6qsIWIiIiISG4UXF1pCqmoBYC/lzu3NskobHHosrcnIiIiInIlU3B1pSnEohZwvrDF7K0nOBuvwhYiIiIiIjlRcHWlyUgLPLUbkmIve3ONqwTSsFJGYYsjl709EREREZErlYKrK41fRQioAjjg+KbL3tyFhS0mq7CFiIiIiEiOFFxdiSoXbmpgn6aV8fGwsf9kPKsOnCmUbYqIiIiIXGkUXF2JCrGoBYCfpxt9mmYUtggvlG2KiIiIiFxpFFxdiQq5qAXAXa2qAzBn6wnOqLCFiIiIiEgWbq5ugBSBjOAq6hAknAGfoMveZKMqgTSqHMiWo9FMWRPOHc2rcDY+hTPxyZxNSOZMvLlVL+dDn6aVL3t/IiIiIiKljYKrK5F3GQiqBWf2mdTAa7oUymbval2NMTO28M6cXbwzZ1eO64UGetOqxuUHdCIiIiIipYnSAq9UGSXZj24otE3e2qQSlct4A2CxQFkfd2pW8KVlWFm6NQimSZVAAP5v/u5C26eIiIiISGmhnqsrVZWWsGU6bPoJrn8M3Dwve5O+nm4seroTsYkplPHxwGa1ZHr+aNQ5Or27iBX7T7Ni32na1ip32fsUERERESkt1HN1pWoyCPyCTWrg8o8KbbMeblbK+XlmCawAKpfxZlBLMyfW/y3YrTmxREREROSqouDqSuUVCN3+a+7/8z6cPVQsu32kcy08bFZWHzjDin2ni2WfIiIiIiIlgYKrK1mj/hB2A6SegznPF8suQwO9ubNVVUC9VyIiIiJydVFwdSWzWKDne2B1g12zYddfxbLbRzpfg4eblTUHz7Js76lc13U4HLwzZyed3l3EvpNxxdI+EREREZGioODqSlexHrQdae7/9SwkJxT5LoMDvLi7dfrYq/m59169P283ny3ex8HTCYxfvK/I2yYiIiIiUlQUXF0NOjwLAVUgKhyWvl8su3y4Yy083aysD4/inz3Z9159vngfnyza63z8+6ZjnI1PLpb2iYiIiIgUNgVXVwNPP+gx1txf/hGc2pv7+oWgYoAX97SpDsAH2fRefb/iIG/P2QnA8zfX49rKASSl2pm29nCRt01EREREpCgouLpa1O8N13SFtGSY/RQUQ6GJhzrWwsvdyqbDUSzeddK5/Jd1R3jpt20AjOp8DQ91rMXgNmEAfL/yEGl2FcEQERERkdJHwdXVwmKBnu+AzRP2L4ZtM4t8lxX8PRncNgw4XzlwztbjPPPzJgCGtgvjqW51ALi1aSXK+Lhz5Ow5Fu2MLPK2iYiIiIgUNgVXV5OgmtD+SXN/7n8gKbbIdzmiQ0283W1sPhLNm7N28OhPG7A7oH/zKrx8SwMsFjMZsZe7jYEtTAn371YcLPJ2iYiIiIgUNgVXV5v2T0DZGhB7HJa8XeS7K+/nyZB2YQB8vewAKWkOejUK5X+3N8ZqtWRa95421bFYYOmeUyrLLiIiIiKljoKrq427N9ycHlSt/griij4Fb0SHmvh62ADoXLcC/zewKbaLAiuAqkE+3FSvIgDfrzhU5O0SERERESlMCq6uRrW7QeUWkJoIKz4p8t0F+Xrw8V3NGNm5Fp/f0xwPt5wPu4wxWr+sO0J8UmqRt01EREREpLAouLoaWSzQ4Rlzf80ESDhT5Lu8sV4wz3Svh5e7Ldf12l9TnhrlfYlNSmXmhqNF3i4RERERkcKi4OpqVac7BDeC5DhYNd7VrXGyWi3cmz4/1qQVB7PMjyUiIiIiUlIpuLpaWSzQ4Wlzf9V4SIx2bXsucHvzKvh42NgdEcfK/UXfqyYiIiIiUhgUXF3N6t8K5euawGrN165ujVOgtzu3NasMmN4rEREREZHSQMHV1cxqhRueMvdXfArJ8a5tzwUyClvM2x7Bsahzrm2MiIiIiEgeKLi62l17O5QNg4TTsO5bV7fGqW6IP21qBpFmdzB5VbirmyMiIiIickkKrq52NjdoP9rc//cjSEl0bXsukNF79dPqcJJS01zbGBERERGRS1BwJdDkTgioDHEnYOMPrm6NU9cGwYQEeHE6Pplpaw67ujkiIiIiIrlScCXg5gHXP2HuLxsHaSmubI2Tu83K8A41AfjvrB1sPVpyKhqKiIiIiFxMwZUY190LvhUh+jBsnurq1jgNaxfGjfUqkpRq55Ef1xOdUDICPxERERGRiym4EsPdG9o9au4vfR/sJWOMk9Vq4f8GNKVKWW/CzyTw1PSN2O2aWFhERERESh4FV3Jei/vAuyyc2Q/bZrq6NU6BPu6Mv6c5Hm5WFuyI5PMl+1zdJBERERGRLBRcyXmeftBmpLm/8DWIjXBtey5wbeVA3ujTEID35+1i2Z5TLm6RiIiIiEhmCq4ks9YjoEw1iAqH7/tCwhlXt8hpYMtqDGxRFbsDHpuygePRmlxYREREREoOBVeSmVcgDP4N/EIgcjv80A8SY1zdKqfX+jSkYaUAzsQn88iP60lOtRdoO8mpdo3dEhEREZFCVSKCq08//ZSwsDC8vLxo3bo1q1evznHdTp06YbFYstx69erlXMfhcPDyyy8TGhqKt7c3Xbp0Yc+ePcXxVq4MQTVNgOUdBMc2wOSBkJzg6lYB4OVuY/w9zQnwcmNDeBRvztqe59c6HA5W7T/NqMnrafjKHIZPWkuaAiwRERERKSQuD66mTp3K6NGjeeWVV1i/fj1NmjShe/fuREZGZrv+jBkzOH78uPO2detWbDYb/fv3d67zzjvv8NFHHzF+/HhWrVqFr68v3bt3JzExsbjeVulXsR7cOxM8AyB8OUy9G1KTXN0qAKoG+TBuUFMAvltxiAe+W8PXS/ez5Ug0qWlZe7JiE1OYtOIg3cf9w8AvV/Ln5uOkpDlYuDOSjxbmPehOszsYO3sH78zZicOhoExERESuIGcPwqovITXZ1S0p1dxc3YAPPviA4cOHM2zYMADGjx/PrFmzmDhxIs8//3yW9YOCgjI9njJlCj4+Ps7gyuFwMG7cOF588UX69OkDwKRJkwgODubXX39l0KBBRfyOriCVmsLdP5uxV/v+hp/vg/7fgc3lhw031gvmiS61GbdgDwt2RLJghwnG/TzdaF69LK1qBNEgNID5OyL4dcNREpJNaXlvdxt9m1WiSlkf3p27i4/+3kOLsLLcULtCrvtzOBy89sc2Jq04BEDPRqFcWzmwaN+kiIiISHH5+T44ug4STkPnMa5uTanl0rPk5ORk1q1bx5gx53+BVquVLl26sGLFijxtY8KECQwaNAhfX18ADhw4wIkTJ+jSpYtzncDAQFq3bs2KFSuyDa6SkpJISjrfKxMTY8YYpaSkkJJS9JPWZuyjOPaVb6HXYen/A7apd2LZ+Sf2mQ+RduunYHF5pycjO9agwzVBrNh/hjUHz7IuPIrYxFSW7D7Jkt0nM61bs7wvd7euSt8moQR4uwMQfjqeqWuP8PiUDfz+SFuCA7xy3NdXyw44AyuA3zYcoW5Fn6J5Y/lQoo8dKbF03EhB6LiRgtKxU/JZjq7D7eg6ABwrPyO1xXAzDt+FStJxk582uDS4OnXqFGlpaQQHB2daHhwczM6dOy/5+tWrV7N161YmTJjgXHbixAnnNi7eZsZzFxs7diyvvfZaluXz5s3Dx6f4TqDnz59fbPvKr+Dqj9Bq/0dYt07nZPguIv0bE+1TjWjvaqTaXBtkVAGqlIM+QXAsAfbFWNgXY+FIvIWqfg7aBzu4JiAay5loli3a6nxdCyss87FxND6FIeOXMLJhGjZL1u2vO2Vh0h4bAPXL2NkRZeWXNQdomLoXSzbru0JJPnak5NJxIwWh40YKSsdO8fBJOol7WjzRPmF5fs11Bz+navp9S1IM+358il2h/YqkfflVEo6bhIS81x5wfX7XZZgwYQKNGjWiVatWl7WdMWPGMHr0aOfjmJgYqlatSrdu3QgICLjcZl5SSkoK8+fPp2vXrri7uxf5/gqmJ/Zt9bH8+iDBMZsJjtnsfMZRpjqO4GvNrUprHGHtS0TPVl40bRdP389Xsi82jV3utXm6W+1Mz686cIafvlsHOBjathqju9Sm7duLOZOURqXG7WhWtYxL2p2hdBw7UtLouJGC0HEjBaVjJwdnD2Bd8zWOam1x1LulcLaZFIvb560g4Qypw+ZCaNNLvyb2BG6b1gCQ1u4JbMvHUffsQmrd9R54lymcdhVASTpuMrLa8sKlwVX58uWx2WxERGSerDYiIoKQkJBcXxsfH8+UKVN4/fXXMy3PeF1ERAShoaGZttm0adNst+Xp6Ymnp2eW5e7u7sX6yyzu/eVb04FQvhbsmQcntphb9GEsUYewRB2CXbPMemVrQIv7oNk94BOU+zZdrHZIGd65vQkjJ6/ni6UHaF2rHDfWM72euyNieXjyRlLSHNx8bQgv974Wq9VClwbB/LbxGH9ti6RVzdzHahWXEn/sSImk40YKQseNFJSOnXQJZ+Cf92D1l2BPgTVfwPWPw02vgNV2edteNh7izdAI9yVvmeJkl7LpB7CnQtU22Lq8AnvnY4nchvu6r6Dzfy6vPYWgJBw3+dm/S7sXPDw8aN68OQsXLnQus9vtLFy4kLZt2+b62unTp5OUlMQ999yTaXmNGjUICQnJtM2YmBhWrVp1yW1KHlRpYf7Q7vwJntwKzx6AIX9A97eg8UBTXfDsAZj/ErxfD2Y+BIfXQAmurtercShD2lYH4MmpmzhyNoGImESGTlxNbGIqLaqX5f8GNsVqNTmAvRtXAmDW5uMq5S4il5aWAodXgz3N1S0REVdKTYLlH8NHTWHlpyawCmlknvv3Q/hpECRGF3z78adgxafnH+/7Gw78c+k2rZ1o7rceAVYrdHrOPF75OZw7W/D2XKVcnrs1evRovvrqK7777jt27NjBww8/THx8vLN64ODBgzMVvMgwYcIE+vbtS7ly5TItt1gsPPHEE/z3v//l999/Z8uWLQwePJhKlSrRt2/f4nhLVxefIKjRAdqOhH5fwlM7ofdHENIY0pJg008woQt8cQOsmQCx2Y97y1ZcpHnNrKch5ljhtvuiYO8/verTuEog0edSGDl5A0O/WcOx6ERqVvDlq8Et8HI/fyXphjrlCfByIzI2iTUHzxRuu0TkypKaBD/eARO6mu8zEXGt1CQThORX9BFTpnzzdHPROO5k3i8cOxyw9Rf4pCXMe9EEUBUbwj2/wEPL4PYJ4OZlMoO+uglO7c1/+wCWfgDJcRDaBFrcb5YteC33dm77FeIjwT8U6t9qltXrbdqXFAMrPitYW65iLh9zNXDgQE6ePMnLL7/MiRMnaNq0KXPmzHEWpAgPD8dqzRwD7tq1i2XLljFv3rxst/nss88SHx/PiBEjiIqKon379syZMwcvr5yrwUkh8fCF5kPgusGmnOeaCbBthkkhnDXa3EKbQp0eUKe7uX/h7zfmOOz4A7b/Bof+BdK/EE5sgWGz899dnhwPp/bAqd1wchec2mUen9lvvkT6fQVWK55uNj696zp6fbSUTYejACjv58F3w1pR1tcj0yY93Wx0bxjC9HVH+HPzMdrULJfNjoveqbgkpqw6hI+mbxMpmex203u/f7F5vG2muTIsIq5xYgtMuRtijpoUvHaPkqfKVBnT0Vzci+PuA2XDoEx1CKxitpWWbHqr05LTb6kQdQgi0gtq+YXAjS9C07vOn9M0ugPK1TJtO70HvroR+k+Ea7qQZ9FHYM3X5v5NL0NwI3OB++ha2DUb6vXK/nWrxpufLe8HW3rqW0bv1bTB5vk2DxfNMA+7HbZMA++ycE3XzOeDpZjFodlQs4iJiSEwMJDo6OhiK2gxe/Zsevbs6fKc0iKRcAY2TjYnFkdNcQgnv2Co3Q2CasLuOXB4VebXVrrOBEPJsebL4oan8rbP45tgxoNwckfu63UaA53Oz6c2f3sEwyetxdvdxtQH29C4SplsX/bP7pMMnriaIF8PVv/nJtxsRfSFcHqf+bK8boiZ2DndiehE7vp6JftPxlPO08H8p28iyN+7aNogV5wr/junJHA44K9nzZgKq5sZz2CxwTN7S/xY1Jzketyc3gc7foeWw8HTzzUNlJIp+ihp/7zPiphgWg8Y7brvnK2/wK8jIfXc+WV1e0Lfz8zJfXYcDlj+ESx4FRx2qFAffMqZyXZjjpLpfOZS3H2h/RMm08fDN/t1YiNg2r3mXMhiha5vmPXzEgD+Ngo2fA/V28PQP81rFr4OS9+HCvXg4eVZL1AfWQtf3wQ2D3hyO/hdMI7cbjdZRxFbocOzcOMLeX+vebXiM5ibnp1Wtga0fhCa3g1e5ty7JP2vyk9s4PKeK7kK+ARBu1HmFhcJe+abQGrf3xAXYb4MLlS1NTToA/V7Q5lqJjD79WFY9BbUuslMbpybmGMweSDEHk/ff3moUBfK14bydaFCHXMi8NezsHisSWGs1xOArg2C+X3U9ZT18aBqUM4l5tvVKkeQrwdn4pNZvu80HeoUQWGLtFRz1Shiq/kM7pkBVZpz5GwCd321ivAzpizo6SQLL/++nY/vug5LSakNL3K1yxisjgVu+8I8PrnDfO81usPVrStcqcnw053pmQF7oe+nl36NXB3SUmDaYGxH19IOG/bNlaD5vYWz7YhtZvuhTXIPPuxpJjha/pF5XOtG00uy4BXTozO+A/T/Fqo0z/y65HgTsGybYR43vQd6vQ/u6VlQqUmmt+jswfRg65gJiGweYHNL/+lheoPcvKBmZ/DPPE1QFv7BZhz7rNGw4QeY94L53uj9Ue6ZO6f2mPMEMBeiMz6Pdo+ZDKKTO2HzNGh6Z+bXZfRaXXtH5sAKTC9Sx+dMsFcUvVeRO8zvBcDN24zXn/M8/P0mNLsbWo2AgGqFt79ipOBKipdfRfNH0+xu88V0aDnsnmu6zGt2hvq3QEClzK9pcqf5AtzxB8wYAQ8uAfccemmS482A0Njj5krN4N/AP5vKk9d0MV9Ga76CmQ/C8L9N8AU59lZdyM1m5eZrQ/hxVTh/bj5WNMHVqvHn0wgSo2DSrZzo+S0D59g4GnWOakE+PHlTLZ6avpk/t5ygw7ojDGhRNddNXrYzByA1ESrWL9r9FLWD/5ryssENXd0SuRwOh/keSUkwt+QESIk3P1PPmQsnfhWLv11rv4FF/zX3b37bBFMnNpuTpN1zr7zgauWnJrAC2PgDNB4ANTu6tk2lSeQOCKoFbh6XXjdD/CmYeq8piFC7O9TtAcHX5q2HozgteQeOrsWBBStpWP8YBbHHoOOzl9fW45tM6pw91aS/tRhmjjtP/8zrJZwx6Xz7F5nH1z9hgg+rDaq3g+lDTGA0sTt0+6/pObFYzP+6KXdD5DbT89zjf9DygcxtdvM0qXzlahX8fWTHzRNu/cS8r7n/MUFWahL0HW+CtuwsehMcaWbIRbXW55d7l4H2T5pActFbcG0/s30wwzC2pVcSzCldud4t5riK2AorPzPpjIUhNdmcz6UlmUC3/7eweao57zm12/xc9QW22t0o72gKjpsLZ7/F5MpIbpTSyc0TanWGm/9nqg+2HpE1sALzZXbLhyaF8NQuMzgzO3a7CZSObzLd9ndOyT6wytBjLFRrZwZsTrkLEvM+hwFA7yamrXO2niApNQ9VwNLyMcN41GHzRQjmS71GB0iOo8yvd1E7Zjk1K/gy7cG23NI4lJ7V7AC88ts29kbG5es95MvRdfD59fBFR/PPqLTa9Rd82xPGt4cl76qCW2mUlmqqWL1bC94MhndqwP81hE9bwpedzO/3h9thQrf8/d0Vhu2/m6vOADc8bU7WwJz0AOydf2Udc1Hh5gQazAB4gD+fgJRzOb7EJRJj4MRW8/e/6gszrrckWPk5fNbGFH7K6/+glETzPyt8ORxZYwL58e3N38CfT5oAviR8/oeWw9L3AEjr+wW7g9PncVr8Fvw+quB/m/Y0+ONxE1gBRKSP6X6vrll+bGP68m3wVWcTWLn7wB0Toetr53uAKjWFB/8xWTL2FJiTPsZo++/meyRyG/hWhCF/QqvhxRu4WizQ5iETdFjdYMt0mPFA9p/ZsY3pQZIFbnwp6/OtRphxXtHhsO7b88vXfeMsv06lZtm3I6P3CmDleBOsFoYl/zMXnLyDoM8nJpW45f3wyCpT5OOaroAD6565tNv7DsQcKZz9FhMFV1I6+JaDPumpJqs+N6k1F1v0X9O7ZfOAgT9CUI3ct2lzhwHfgX8lc6Vk5kMmQMujlmFBBAd4EpOYytLduVQeSoozJ3rv1IJ9i/K28TnPmyvw1dpCqwfZeeME/qE5XiTztccHzOx4kpBAk5pwUyUH7WoGcS4ljVGT15OYUgQnbmf2w48DTJvSksyXbGl07iz88YS577CbY+b720yeu5QOB5aacQBznoeE0+eX2zzAq4z5ey53jRnfcPaAOSkpLgeXwS8PmGPruiGZr/JWaWXad+6sOSG+Uvz1vOk1rNbOFB3yDzXfFxkBlyvY00zQMuVuGH8D/K86/K8qjL/eZDb89aw5iV75uevaCKbHav4r5v7xTSa18lJBkd1u0uQPrwKvQOg+1owbcvM2Y4DWToTJA+DtGuZYPHsof206cwDCVxbs/VzoXJTpmXDYocldOBr2Y0elAaT1eNekzm34wbQznxc1AZNue2wDeAaak/HuY6FcbfP/ad238GVH+KIDfN3FXAgsUw3unwfX3p51W16BMOB76PE2WN3NuMFp95pskcotTKZMdRdO49PgVhgwybRt20z4eZjp9bnQ32+Yn43ugJBrs27Dw+d8afUl75hzktQk08MOly6yU+8W04uWHGt6ry5X+CpY9n/mfu8PM18Et1pNZtE9P8OotaQ1v58jZdtBYBFn5RQyBVdSetTuarrlAX59JPMVlI0/mUGbALd+nPcvQ7+KMPAHsHmaSZDTr7Llhc1qoWcjM1H1n5tzKBWfGGMCq70LICkapt5j/onmZuds2PmnuVrV6wO2HItl0DcbuS/xcZZ4dMCNNAJnjYD1Zqya1QLv3tGIcr4e7DwRy9jZlyjikV9xJ+H7fpBwypy4ghkndy6qcPdTHOb8B+JOmH/EvT80VzMPLDEnXXkNfMU1oo/C9GHw3S0Qud0MQL/l/+D5cHjpFLx0Ep4/BE/tgEfXnT+ZWPpB8fQUHVlrTo7TkszJSK8PMl/ptrmdr/y1e07Rt6c47PrLfG9a3eCWD0wKUs93zXPLPzI9RcUt/hT80M8E3zv/NFfHE6PMc95BpkJt2A3m8ZznYcvPxd9GSE+LGm6Ol6qtzRyRh5aZFLa01Jxft+hNMwbI6mb+d7V9xGR+PHcA7ppuym8HVDFpsVumw6etYNFYkyqbm+ij8Ptj8HFzkyJ3Od+HDgfMegqiD5tKej3PB9r25sNg0E/mu3ff3/BNT5OellfRR+Dv9JTbrq+aQk9tH4FRa2DoLBNAWd3N/9mUBKjZCUYsOT+XVHYyeonumwuB6WN8rhtsLhZkl01T3Or1Sj9P8TAXkKcPNcERmBT3vQvM8dAp67RFTs3uNYXDEk6ZiwrZlV/PSaZ5r8ZfXuZKUhzMzAi67zTBY07K18be423Whz1Y8P25iIIrKV26vm6uSsceN1/eDgccWgG/P2qev+EpaDIof9us0tycGIBJxduV9xOfjNTA+dsjsvYYnYsyvSKHV5orbJVbmPknfrgj5y+n5HhzVRWg7Sg2p1Tirq9WEpWQwrVVy9P08enmS99hh99HYV39BQAV/T15f0ATAL5bcYi52/Ixn1hukuLM1cWzB6BMdRzD/8ZRsYF5H+u/K5x95CYtxZTOze1kI692z4VNkwGLqQ7VfCiMWAwVG5jZ7L+/DRa+UfB92e356vmUPEpNMhdOPmlhTiotVnOR5dH10OI+c+U5o3zwhTKeO73HnGQXlYQz8OdoM49VUgxUv97MWZPd2Ig63c3P3dlPI1KqJCdc8F018vw4zPq9TXBpT01P3SrGFMij60za8v7F5uT9plfgzqnw8AoYc8QEIA8uMQUDWqWfsF1YKv9yHFkHc1/Ie0/R4rHmu807yPSc3PmTKXqwa7b5f5bdd8mGH89fAOz9kUkXz+DuDXW6mf9lT24144jDbjBjZJf8zwRZ23/LOt9Rwhkz79LH15nvdEf672vDD/n/DDJsngZbfzbVMft9nXUcVN0eJhDyrWBS+r7uAhHbL71dhwNmP2P+/1RtA9cNPf+cxQJh7U3q31M7odub0P0tuPuXvBdhqNIcHllhqurd+vH5sUklQd0eJijNuBA89V6THrrwdfN8s3tzH/tlc4fO6dX+ln9kJiyGzOXXc91/r/O9Vx82MUH4H4+bixP5mb907n/M+U9gVTMe9Qql4EpKFw9fuO1L86W9bYY56Zp6t8mXrn8rdC7gYMtm96T3ijnM1cQ8TuDXrGoZKpfxJj45jUU7I88/kXAGJt1q5pfwLgtDfod7Z5iBofGRpicou0kMF//PXO0LrEZs6ycZOXk9sUmptAoL4ocHWhPo62X+qbYdBYBt/gvUPzYd7Gl0qluRER1qAvDsz5s5FnWZOfdpKeYK2bH14B1EwoBpDJh8gHejbzLPr/qi6MazRO4wJyof1DdjCb6+EY5vLvj2zp01/wjAnAhWbWXuV6hrTkKaDwMc5sTlu1tMakxeJCfAzlnw20h4rza8FQrzXiqdvXolRVqqOdHa8KOZQPyTluYEIiXBnFCNWGIqdl3qhMnTH1o/ZO4vfT/vk33mlT3NTJPw8XWwdoK54NGwnzlJzqgmdrFrupjgMHKbGVdZmi19z4y3CqhiyjRfqOe7pifm6Nrz8+4UtXXfwcQeZmxGUC3zd33D6PRCDw0yn+BbLGbMbYO+5n/HlDxkFOTE4TCpeBO7w4pPzDi/yEtkD4Svgn/Hmfu9PzQV4sLawx3fmP9tmyabgOfCY/bA0vPfYTc8ZYpC5cRigcrNTRDZ/1vzO4o+bFIhJ91q/r6S4kyK2IdNYPnHJgir1g5uTu953DXbrJNfZw6YC59gpjmp2jL79SpfBw8sMFkEMUfM7+7gv7lve8cfpl1Wd+g9Luc5kXzLm+rEbUfmXAAiJ55+JbfQUe0ucNeU9MmG55rxZIdXmscdn7306xv2Mz14STHmO8jmkTlAzY3VCrd9bqbHsVjh9F6TgvnL/fB+XfM9nTHeL6NX7WK7/kq/KGuB28abi19XKAVXUvpUaX5+gOXfb5hxF6FNTbnjy5mArvtYM8YpKcb01sTkkOp3AYvFwi1NTGrgHxmpgXEn4bve6YU1ypvBsJWami+Su382aQdn9sGP/U1PVYaIbbAifVxZz3d5dc4hDp85R+Uy3nw9tAV+nm4ZOzVVjdJTAOpE/IFt2t1wLoqnu9WlSZVAos+l8PiUDaSmFbAnxeEwg9L3zgc3bxx3TeWpv+NZc/AsX0e34JQj0OT3Z1QaKgznzpoTsS87mwHeKz4xPUpgPssvO6WfZBdg1uS5L5jeznLXZK125O5t/lHfMRE8/CF8BXzUFN6tDd/dCnPGmBTMI+vM7ysuEtZPgsmDTCGFKXeZq7wJp8wJyvKP4KNmRRt8uoLDYT7Hb28xqTmFxZ5m5p/563mY0N2Mjfm8Lfz2iKnmGXXIDMbu9xXcNwdCG+d9260fMmOvjm+CfQvz3p6k2NzXOfiv6SGZ9ZQ5bis2NFfi+3+T+wmDT5AZewXm5OhSog6b74l/PyxYr2hBAsr4UyZFLDendsO/6WWtb34767xWAZWgS/pYooWvX/p4uZye6ZRE09Pzx2Nmwta6vWDEoktXNLXaoN+XpncnOdZkFOT1okqmfY8yJ5X2FBNQxp2Ab242aaLZyS0tql7P82OLV356PtX95O7zFxEb9sv7RUSLBRreZlLmOj5nej0O/GMuWI1rZFIMk2JMj8TdP5s0uFbDzXxDKekXjvIjLdWMs0qONf9LLzUvZdkwMxaqahuTNv/9bSaAyk5izPme0usfL/0Vawuq1o1w1zTTMxuZ3tvXKodiYBezWk1vbobsyq/nJqSR+dt69oApGNZmpKnIisV8J2SM93unlklv3TbzfIAef+p8hlG7UeZiwhVMkwhnQ5MIlwJpqeZK4dG1ZhzQ8L8hIPTytxsbYVIUosPNF/+QP8xg2FxsPRrNLR8vw9PNyvonG+E75XYzp4RfMAz+PdPkv4ApAT+hqzkpq90NBk02Vyu/6WEGKdfvzaz67zJy8nqsFpgyoi2tamR/lT51/Y9Y/ngcmyPF5FMPmswhWzV6fbSMuKRU6gT7US3Ihwr+XlT096RigCcV/b0IDvCkXkgAHm45BKN/vwn/vGOuUA2azKfHavPu3F242yxcWzmQ649+w9Pu0zntX49yo1deXhWlswfNCdiOP834AzD543V6mMkEQ5uYSQYzqnuVq52/cXW758Hk/oDFnJxXa5Pzumf2m3lNDi0n+8khM97nBc8FVjMnRXVvNidb818+X5Y6qJapTlXvlsKtNJVwxvxjPbPffD6hTfL18gJ956z+CmY/be6Xr2PGJxTGnCcZE19eyMPPXDCp1NRUsarTPWtqUV7NfcEE6tWvNyePuUmMMWNAIraYQDugUvqtMgRWNvcPLDUpT2ACqc4vmhTEvF4hX/oBLHzNlM++e1ru604fdn6OndrdzdXevHzm2341PagpCaa3rHZXuOamnCdKPXPApE7unJVezMBh9tf+CXOSnH7spqSkMHvWLHqf/QrroWXmb/TOKdkf23b7+e+0OjebHr0L10tOMH/T6yeZqndVWpoTvxo3XPr9ZYg6bIoPHNuAqZT2IrQfnb+LbInR8E0v8zsPqgn3zcvbCWf0EZOadWy9+Z686WVTxGTyAFOwxN0XBv1oKuJe6PfHzNX7wKrw8L/ZB+MXTqx60ytm/bMHzWc05I+cpyK5lLMHzd9DRpps2RrmM2vYL/NntugtWPJ2emGBX/K+/UVjTQqiZ4B5bxf878z1OyflnDkZ3zXbfJY93zPpahea/YwpZBFU06TtFfQzuFIc/Nccax5+JpUxr9/FDod53YGlMHxh4fTSJZwxFyX3LTLfIbEXXJi2eZrvnsQYM6awYgMYvijn3v2LlKTz4/zEBgqusqHgqpSIOW56OpoMcs5RVSiiwk3PU0Ze8JDfzRd6DhwOBze9v4T4U4dZWP49/OIOmoBvyB9Q/prsX3R4tekVST1nAoiqrUzKh4cfEYP/oduEfUSfS2Fk51o8071e9tvAHDv//vwZHY9/iSXmiPmi7fs5f6S04PEpG7Dn8tdds7wvXw9pQc0KF1x1tqeZk+g56T2DvT9kkW9P7vtuDQ4HvHVbI/q3qMKb05fx3I7b8bYkM6nOJ9w96B5s1gIED4kxpkfqzD7zOPha83k06p/1BGfHH6anIC69sl/LB8yJh1cuf6PnouCztubLvu0o6P5m3tqVHG8C5IjtJoiJ2GZ+ZvSkhTY1g4zr9jT/nC48aUxLhQ2TzAlKxvrV2kG3N6BKi7zt/8JtHd9k5hiJ3GHmSYrccf4zyBDaxIzFa9Q/T6kW+f7OObbRXBBISzYnjSnxZgzh4N+y9lrkx6458NNAwGJ+n1VammCq3DWX1wt9oZhjMK6xueo/bE7OQbndDlPuzGOxCYsZs3fjS6aSaX5EbIPP25lUnmcPmEpe2TmxxfQwgDlBSUsyJ6sDJuVcNjnuJMx+Kvsy4xarKZxQu5u54TAXNHb+eX4+vQvfX8YFhKqtzdxAdXqQkpbG5h9epPmh8aY63ciV5iJUTiJ3mGp99hTo/52ZHP74RhNQbfnZ9JpcrNaNJlDJ6T06HGZs1cYfz2/Du6wZ53bNTTm3JTexJ+DrruaiWqVmJtsgt+P6wFKTMp1wyuz7jomm3WC+O6bcbcp/2zxMuzJ6py483of8kXsg+fd/4Z93zz8uUx0eWJi/noacHFxm3nODPtmPtzm1Fz5pbi76PbUrb/s8vNpc8HTYzXu+aC63S37npKWacuoZY3k7PmeyMywW0wv4dRfAYb5zanbK91u+IiXGmLGN+b3IlZZiLrwURVqe3W4uOOz43ZS0P3tBb7DV3fR85VZc5CIl6fxYwdVlUnAlRB81uemn96YHSr/nHMClpbLgx7dpum885S0xeQrIAJN/POUu88/IYgNHGvZub3LPthYs33eaxlUC+eXhdrjbcj7JdB47HVvh/tsIk/IBcMPThDd+gt0nE4iMTSIiJpHI2CROxpqfB07FE5uYSqC3O5/fcx3t/E/Cpp/MQOTY9MpNHZ/nQKPHuPWTZcQmpnJnq2qM7We+FB0OB1u/eoBGx35mQVozptZ+jw8HNcXH4/zVe4fDwcHTCSzdc5J/dp/ibEIy4wY2pWqQT8YK6akDM0zPwKAfTdCSWw/PubPminxGT0dAZTNrfM3OWYMcgF9HmklNg2rBQ8tyPpHNq7j0YCkvJxtJsSada/knJogGc0xc08XM4RHWPvv2xJ821Z/2zIW9C89XOrtYmWqm1+zIahP0gDnhbXgbNB9iTopz+Czz9Z2TGGPKGp89YFKubnrZ9EicOwu1bjI9F/mZ/DRDwhmT/hkXYdJLeryV/23kVUZvQe1ucHcOpdkXvmHGEdk8YfCvZrB9zFETnMUcNd8JMcfMIPcbnjK9agXhcJiUrOjDJr0no8jFxSYPNIFew35mEtBp95oLPjYPuPkdE9xl/H4dDpNaOfsZOHfGfJ/cMNoUPNgzH/bMMxcLcmJJn1C1fm9z0SA1yaS3bpx8/tiqUI/UliNInfcaXqnRJrDs8PSl329GL7hvBVNy+cSW88+VqW4G4tfpZgKudd+en7uoQR/TK1ihjnkccww2TTHfU6d2n99GpWYmcCtb/dJtyc2pPWa81Lkz5m+n1k1m7I5veZPe7VvB3N842fROO9JMStTAH7LuOzXJjN3d/psJant/ZHq2P2tjLrjk5UJPRsW9tRNMQaQH5psxosXly06mR/Dmd87P1ZYTh8N8dkdWQ+OBJt3yInn6znE4TKGPJemFDpoPNSXSv77JXABocqfpvZXSweEwFyV3/GHOTZrdA03vytcmStL5sYKry6TgSgCTIjjpVnNS4lvRBEwX5nk7HGbw5vyXnP/s99gr80ejj+jY6jquq1YWy6VSwdZ9Z8YKAAQ34qv6E3hzzl683W3Meqx95l6lbGQ6dqwW809/ZXrOfu1uZkCxd5C5uuoZ4OwNOBmbxDPfzafm8Tn0sy3jWusFV5e8ykCbh4lr8xS3fbacPZFxXFetDD+NaIOnm+38eqf34fi4ORYc3JT0Lj6VGvB/A5uwJyKOf/acYumekxw5m7moxvXXlOOH+1ubzyUjzczqBsP+Ol9kIi/2LzY9fRdWXfStaK5o1upsgq2IrfDjHYDFbN9Vc5VEHzVjGzZPPX/iCOYkPux6E2yFNjVpFbvnmlRXxwXja7zLmucrNjDHX8UG5oQzI00u/rTZ9vrvMp9Al69rTq79Q87f/MzPFHd/Zv8159LfORcGwIFVzYSbPkFweI3520hJMHn7/b7Kf0/TLw+YUtHlasNDS4s2zef0PlNt0GGHB5dmHbe1dYaZPwZMwZwmA4uuLWCqC66dYNIJb/m/rM8fXmMmlbXYYORq0wN+LsrMb7QrPbWxyV2msEdSjNnervTxMcGNoO+nWVNFzx4yYyh3z0u/COMwAUT9W0x6X3ZXv2NPmLLNaydm6mVylLsGy8PL81ZNLSXR9MCd3mMe2zxNEHfdvRDWIfNxc+aAObnePM20z2KFRgNMQLJ/0fm/CzdvE3w1vTPrNi7HkbUmayHlEmXLARoPMmM1czpu7Wlm3Or6SeZxudrmM8hPWpQ9zQRoIY1zzoIoKhmpiZVbmPSx3Oz724yXcvOCxzebAh0Xydd5zpoJ6UUxHKZn9OxB839s1Nr89xRLqVaSzo8VXF0mBVfiFH8KJvUxJ+o+5UxKQkgjk6o178XzPUU+5fjB6y5ePdaSVEzvTeUy3tzSJJRbm1SiQWhAzoHWyvGweQr72rxFj6lRpKQ5eOu2RtzVOvexXpDDsbN5mhk4mnpR4QeL1QRO3mXBwxdHxDYs6WV3Uxw2DpS9nlpdH8BWtwcOmwcP/7CeOdtOUNHfkz8fbU/FgGxOBn66C3bN4hdLV546NyzL0+42Cy2qB9G6ZhCfL95HUqqd9/s34faQCFO8wJ5iyuW2HXnJ95pFcoI5cdm7AA79m/WEyOZhrrq3ecRUBnO1xBhzvOxdYG7RuVSLC25krubX7m5SCa22nNfN4HCYsR7rvjPBUC4niA6rOyd961L27q9wD2mQ8zbXTDCpOlY3k1J3YeWvPQtMipM91ZS1vvntvI8r2/6bqVxmscL98/OfLlkQP99vxko1vM1UUMtwfLO56p56Dto9aorFFLWMcYABVUzZ7Is/t+96n7/Sm1HgAEzKzfIPzRhFh90E0HEnzLghq7upGNb+yUuXVk5NBhx5LzWdGA1rv8Gx4lPsCWdw3P0zbtd0vvTrMpzYYlLcql9vUlcvlcYUsc30eGUEjBmqtTNXvhv0yT0d+HKc2Gr+fuJPmVvCBT8To01g1/U1U0TgUse7wwELXjlf9trqbsYH56coi6vERsAH9cxx9uj6nMt8Oxym0t/hldD6Ybj5f9mulu/znO2/mwswGeNw+36e714PKf1K0vmxgqvLpOBKMkk4Y67KHd9ogpNrupgUHBzmKmybh+GG0aS4+7Nszyl+33SMedtOEJ98fn6XWhV8uaVxJTrUqUCTKoG4XZTql5iSRu+Pl7EnMo6uDYL58t7ml+71Ipdj5/gmU+Xu7EGTvpXDibajcnMWed7IU9trcZYAujYIZtzApnzz7wHem7cbD5uVKQ+24bpqOQyEP/gvfNsTu82LO7y+ZP1pN66p6McNtcvToXYFWtcMcqYKfr54H2/P2Uk17yQWBbyCLTrcFHoY+MPlF3tITTI5//sXmUG1xzYAjsJLByxsDofp7dy7wKRtRW43JW7rpI+HCaxyedtPjDFjaU7vNSdJscdN+l3scVNdM6MZNk8sHZ+Bdo9nTe07vtmMc0hLgq5vwPWPZd3Plp9NKV4wKVwdn7l02+JOwmetTTtueMqkGRaHE1vNZNFYzBXw8teYk+YvO5lAt9aNpmJaXgLZy5VyDt6uYQK6h/6FkGvPP7d/sbmgY3WHx9ZnX1DnwFLToxifPv1DaFMzd1sRl5BOSYxn/qyZdL11YPH8rzq8xvTI+oeasbW5zeNTHPIblGb490P453246SVTja+0mNTXfKd2fiHnUt/7l5hebJsnPL4px8JSBTrPOfivqT5YrQ3c/nXhFgWSUqEknR8ruLpMCq4ki3NRJsXsyJrzyxr1N+MOssn1P5ecxt87I/lj0zH+3hVJcur5NC8/Tzfa1AyiXa3ytK9dntoV/Xjtj+18u/wgFfw9mfP4DZTzy9s/7zwfOymJZuzOubPptygzhix9HNlvG4/yzM+bSU61U6O8LwdPx+NwwP/6NWJQq1x60BwOM9fGsQ2kdniOsy2fooJ/9m1PSbPT+6OlPHXmNbra1pl0jxFLwLtMnt5rviScMSk+oU2yTVG5qqUmkxK5izM/PUJwbPrcYRUbmgqMVZqbx0mxptT4mX2m9+zOKTmnXq0cf74Ayi3/Z1LdcuJwwNR7TOBXsaEZ3FycE3VOHgS7/zI9QreMM0HMoX/T50VamHM1vSJpS/qYqptePl+y2uEwAe3RtaY3sOc7Ob8+5jgs+i9UqG9Kzud3Pp8C0P+qy2C3F176YnHZONmkoparbcq5ZxfcfNPT/A21GmHmN8tBgY+djFNUBVZXpZL0nZOf2KDov41FrgTeZeDemfDrI+aqc6cx509Es1vdw0avxqH0ahxKTGIK87ZF8PfOCJbvO01UQgoLdkSyYIe56lzez5NTcSb14d07Guc5sMoXdy9wTx93k40+TStTpawPD36/lgOnzNxbd7eulntgBeYfXttR8Mv9uK2dQIUbnsy5CTYrE+qsovKadSQ53Nje5kOaFUVgBSbtqE63otl2aefmARXqsbLWU/Sqfg63+S+YCSW/vsn0wnZ+wczbc2afKRhy2/jcTwrbPGRSpv5514z92bfIVJfL7u9jy3QTWFndzHaLM7ACE8Ts/ssURkiONyeFHv6mTHhxBlZgeih3zzHj7DKCq11/mcDKzfvScwQFhGZOGZSSrbQFVmAyC9yeNGPFjm/MWsHxwFLzN2TzMH/zRUFBlZRCpfCvXcRFPP1h4Pdwz8+5BlYXC/By547mVfjs7uase7Erf4xqz/M31+OG2uXxdLM6A6uh7cLoVLdiUbX+kppXL8vMR66nXa1y9Gocyiu985hi1KCvKXaQcCp9IHoOwldSea3Jx389dTCPL3Fw7oLUSSlmFguOa++AkWvM4HwcsPIzU8luy3RTTOGOiXkr89v5BTO2DYcpwfv1jWay4T0Lzl95jjl2fp6sjs+5ZtxJ1ZZm0lh7avoE2BaTblScVdgyZFQJPLLGFCWx203hEzDV2dTjKq7mFWCqHAJszqbKZkZVv+sGm3ngRARQz5VIsbJZLTSqEkijKoE81LEWiSlprA8/y4noRHo3ycMM60WsapAPk4fnMsludmxu5mRw3ovw77j0uZB8zDgnDz9z3+pmJkR1pJHS4Hb+3tuL42cS+OjvPTzXI+d5vKQY+JaDfl9A4/7wx5Nmrh8wk4vmNuHyhSwWUzSk2b2w/GPYMg0OLjW34Gvh+sdN4J0YbcYHtc+5h7PI3fCUaReYMTB1e7imHYFVzGcTsdWMvbPazH3PAPN5iZQEjQaYCxFbfzFz9WWMSTz4r/k7srq79u9ZpARScCXiQl7uNtrVKu/qZly+6wbD4rfhzP7zvRPZKVcb9z4f8treeEZ8v44v/9nPrU0qUT+06Mc2yiVc08VMCrv8Y9PbVJA0n+AGcNvncOMLppTzum9NwDAjfRC/zdOkA16qml1RqtnJ9JxZrNB+tOvaAab3KmKrqYp3In0i33aP5n9SUJGick0XkzIbd8JUsKyVXiXS2Wt17+UX4BG5wigtUEQun1cg9P/GTPJY/1bzD7laO1NQotw1ZiLmcrVhwCTw9KdbwxB6NAwhze5gzIwtpNlVVyc7+07GMXjiat6bu4ujUecu/YLL5eFr5kbrPObyxogEVjGTAj+51fSA+aRfQOjySua54lzBYoHO/zHv09XjOWqnpwZu/82McfMpZ8a9iZQUbh4m9RtMujBA+Eo4sCS918rFFyhESiD1XIlI4ajd1dzy6NVbG/Lv3lNsPBzFDysPMaRdWNG1rZR6a9YO/tl9kn92n+SzxXu5qX4w97apTvtrymO1loKB3j5B0OEZU/QkKtw1Y5tKsiotzOSo586Yx+1Hn58cWqSkaDwA1n1j5p7q9T4sTp/LquldUKaqa9smUgKp50pEXCIk0Itnbzbjrd6Zs5PDZ3Ke9LakCD+dwMbDUcXS07bzRAwLd0ZitUCrGkHYHTB/ewSDJ66m8/uL+eqf/ZyNTy7ydhQKd28FVtmx2s5fkPAPhZb3u7Y9Itmp2sYULUqOhYVvmLmvrG6XrmgpcpVScCUiLnN3q2pcV60M8clpDPxiBXsjY13dpGytDz/LiElr6fjeIvp++i9txy7ktT+2sT78LEU1VeD4xfsAuLlRKNMebMuC0R0Y2i4Mf083Dp1O4M3ZO2gzdiHT1h4ukv1LMWk7EoIbmXm33L1d3RqRrKxWaHSHub8yvfx/kzuzneNRRBRciYgLWa0WPr7rOmpW8OVYdCJ3jF/BhvCzrm4WAA6Hg0U7IxnwxQr6fbacedsjcDjMJNCRsUl88+9B+n22nPZvL+J/f+1k27HoQgu0Dp9J4I/NxwF4uGMtAK6p6M+rtzZk1Qs38b9+jWgQGkBSqp03Z+1QSfvSLLQJPLzMdVULRfKi0YDz9y029VqJ5ELBlYi4VOUy3vz8UDuaVC1DVEIKd321ikW7Il3WnpQ0OzM3HOHmD5cy7Ns1rD5wBnebhf7Nq7BgdAfWv9SVCUNa0LdpJXw8bByNOsf4Jfvo9dEybv5wKftPxl12G778Zz9pdgcd6lTg2sqBmZ7z8XBjUKtq/PFoe6qU9Sb6XAq/bzp62fsUEclRcAMzdQCYXqugGq5tj0gJpoIWIuJyQb4e/DS8NQ//sJ4lu08y/Lu1vHNHY/pdl32J350nYpiy+jDzt0fg6W6lchlvKpfxppLz5uV87G679DWkmMQUlu4+xd87I1myO5JTcWYsk6+HjbtaV+O+9jUIDTyfsnVT/WBuqh/MueQ0Fu2K5I9Nx1i4M5KdJ2IZ9OVKJg9vwzUV/Qr0WZyMTXKm+mX0WmXHZrUwuG113pq9k++WH2JAi6pYXF39TkSuXD3fhQ0/mKqfIpIjBVciUiL4eLjx9ZAWPPvzZmZuOMroaZs4FZfEiA4mwIhLSuWPTceYsuYwmw5HZXrt/pPx2W7T3WahRnlfalf0p1ZFP2pX9KN2sB81yvsSfjqBv3dG8vfOSNYdOkvqBUUqyvt5MOz6GtzTujqBPjnPyeTtYaNno1B6NgrlZGwS905Y5QywfhremtrB+a/89s2/B0hKtdO0ahna1Mx9vqMBLary/rzdbD8ew7pDZ2kRpvmRRKSIVG9nbiKSKwVXIlJiuNusvN+/CeV8Pfh62QHemr2T8DMJJKfa+XPzcRLSxxa5WS10bRDMHc2r4O1h4+jZcxyLSuRY1DmORp1z/kxKtbM7Io7dEZdO1atZwZcb61bkxnoVaREWhIdb/rKmK/h7Mnl4G+7+ehU7jsc4e7DqhuQ9wIpJTOH7FYcAeKRTrUv2RJXx8aBv08pMXXuY71YcUnAlIiLiYgquRKREsVotvHhLAyr4ezL2r538sDLc+VzNCr4MalmVftdVobyfZ67bsdsdHI06x96TceyNiGNvZBx7ImPZExlHbGIqHm5W2tQsx411K9C5XkWql/O97LZnpDfeM2EVW4/GcOdXK/nh/tY0qBSQp9f/uDKc2KRUalf0o0v94Dy95t621Zm69jB/bTlOZK/6VAzwupy3ICIiIpdBwZWIlEgPdqxFBX9Pxi3YQ8uwIAa1qkqL6mXzPK7IarVQNciHqkE+dK5b0bnc4XBwKi4ZP083vD1shd7uMj4e/Hh/G+6duIrNR6K562sTYF1cmOJiiSlpTFh2AICHOtbK8yTB11YOpEX1sqw9dJbJq8N5okudXNdPszv4eNE+jp2wcHMRlZEXERG5WqlaoIiUWP2uq8I/z3bm/QFNaBkWVCgFGywWCxX8PYsksMoQ6OPO9/e3pqmzAuJKNh+JyvU1P687wqm4JCoFenFr00r52t/gdmEA/LgqnORUe67rfrZoLx/9vY+fD9j4bMmBfO1HREREcqfgSkSkCAR6u/P9/a1oXr0sMYmp3P31Kr5Yso/ocylZ1k1Ns/PFP2bS4OEdauapwuGFejQMoYK/Jydjk5i77USO660+cIb/W7Db+Xjcwr1MXhWe4/oXstsdjF+yj2d/3kR0Qtb3cCnxSalFNuHyxU7HJXHrJ8sYPXUjdrt65yTvUtPsJKZo3jgRKTgFVyIiRcTfy53v7mtFq7AgYhNTGfvXTtqNXcjrf2zn8JkE53qzthzn8JlzBPl6MKhltXzvx8PNyl2tzOsmrTiY7TpRCck8PmUDdgf0bRJKt8qmh+vFX7cwZ+vxXLcfl5TKiO/X8b+/djJt7RHunrCSqITkPLUtMSWNR3/aQMNX5tL09fnc+eVK3vhzO7+sO8KO4zGkpOXe01YQr/2xnc1Hopmx4Sjj04NWkUtxOBwMn7SWlv9dwKHT2VcgFRG5FI25EhEpQn6ebvzwQGt+3XiUCUsPsCsilon/HuDb5Qe4+dpQ7mtfg88XmwBgaLuwAqcr3tW6Gp8u2suag2fZdiyahpXOj/FyOBw88/NmjkcnUqO8L6/0rs+SBYcpG1qVqWuP8tiUjUy6z4M2Nctl2e7hMwk88N1adkXE4uFmxdfDxtajMdz11Sp+eKA1Qb4eObYpOiGF4ZPWsvrgGfP4XAor9p9mxf7TznU8bFZqVvDFz9MNN5sFd5sVN6sFN5sVd5sFHw83hrYLu+SYtQwLtkfw+6Zjzsfvz9tNy7AgWqqSolzC4t0nWbTrJAA/rDzEC70auLhFIlIaKbgSESliHm5WBrSoSv/mVfhnzym+XrqfpXtOMWvLcWZtMb1Gvh42hrQNK/A+ggO86HFtCH9uPs73Kw7xv9sbO5+btOIQ87dH4GGz8vGdzfDzdMNigVdvqc/ZhFTmbY9g+HdrmfJgm0xB2cr9p3n4h3WcTUihor8nXw5uga+HjTu/WsX24zHc9dVKfnygNeWyqdx4LOocQ79Zze6IOPw93fjsnusI8vVg+7EYth+PYduxGHYciyE2KZWdJ2JzfW8LdkTw28jrL1nRMSYxhRd+3QLAgx1qEhGTyK8bj/Ho5A3MfvyGXANBubo5HA4+mHc+ZfaX9Ud5untdPN2KbmymiFyZFFyJiBQTi8VCxzoV6FinAjtPxDBh6QF+23iM5DQ797TNfcLivBjSLow/Nx/n141Hef7mepTx8WDbsWjenLUDgDE963Ft5UBSUsyYKTeblY/ubMbgiatZfeAMQyauYcbD7ahWzofJq8J5+betpNodNK4SyJf3tiAk0JR5nzKiDXd9tZKdJ2K586uV/PhAGyr4nw+wdp2IZcjE1ZyISSQ4wJNvh7WifqgpR39xj9qRs+fYGxlHUmoaKWkOUu128zP9/s/rjrD5SDT3f7eWmY+0w98r589o7OwdRMQkEVbOhye71iHN7mDz0Wj2n4znqWkbmTCkZZ6rMMrVZd72CLYcjcbHw4avpxsnY5OYty2C3k3yV1xGRERjrkREXKBeSADv9m/Csuc78+W9zXm6W93L3maL6mWpHxpAYoqd6WuPEJ+UyqOTN5CcZqdL/YoMTa8qeCEvdxtfDW5BvRB/TsUlce/EVfxn5hb+M3MLqXYHvZtUYtqDbZ2BFcA1Ff2YMqINwQGe7I6IY9CXK4iMSQRg1f7T9B+/nBMxiVxT0Y8Zj1zvDKwuZrGYcvmd61Wkx7Wh9G5SiduaVWFAi6rc1boag9uG8fXgFgQHeLI3Mo7Hp2wkLYcCFcv3nuKn1YcBePv2xni5m5PkT++6Dk83K4t2neTLpfsv8xOWK5Hd7uD/5pteq/uur8Gd6eMXf1qdt2IvIiIXUnAlIuJCFf296NYwJN8VArNjsVgY0rY6AJNWHuSl37ay/1Q8IQFevHtHkxxL2Qd6uzPpvlZUKevNodMJzgqCT3erw0eDmuLlnjU1qmYFP6aOaEtooBf7TsYz6MuV/LDyEPdOXE1MYiotqpfl54faUrmM92W9p4oBXnw1uAWeblb+3hnJu3N3ZVnnXHIaz88w6YD3tKlG6wvGjtUPDeDVWxsC8O7cXaw7dOay2iNXnllbjrPzRCz+Xm4Mv6EmA1tWxWKB5ftOc/CUCluISP4ouBIRuYL0aVqZAC83Dp85x4z1R7Fa4MNBTSl7ifFGFQO8+P7+1lTw98THw8b4e5oz6sbauc4tFlbel6kjTAC1/1Q8L/66leRUO90aBPPDA60p41M4Y5waVynDO3eYMWTjl+xj5oYjmZ5/f94uws8kUCnQi+d61Mvy+kEtq3Jrk0qk2R2MmryBs/F5q3QoV77UNLtzeoLhN9Qk0MedymW86VinAgBT1hx2ZfNEpBRScCUicgXx9rAxsGVV5+PHb6qTqScnNzXK+7L46U6s+s9N9Lg2JE+vqVbOhykj2lClrOmhuqdNNT6/p3m2vV2Xo0/TyjzSqRYAz/2yhQ3hZwHYEH6Wif+ayZDfvK1RtmOyLBYLb/VrRI3yvhyPTuSp6ZvyPf9VapqdXzccZexfO5ix/gh7I2NzTFGU0uO3jcfYfzKesj7uDLs+zLk8IzXw53WHLzkxt4jIhVTQQkTkCjOkXRg/rztCs2plGXXjNfl6ra9n/v8tVA3yYfbjN7D/ZDxNqgTm2tt1OZ7uVpfdEXEs2BHBg9+v45eH2/HcL5uxO+C2ZpXpXK9ijq/1Sx9/1fezf/l7ZyTjFuzmkc7XXDIITE2z89vGY3z89x4Onk7I9Jyvh42GlQNpVDmQxlUCubZyIDXK+apoRimRkmZn3ELTa/Vgx1qZAvMb61Wkor8nkbFJLNgRQc9Goa5qpoiUMgquRESuMFXK+rDuxa4AxXaiH+DlTtOqZYp0H1arhXGDmnL7Z8vZFRHLzR8uJS4plXK+Hrx8y6XnJGpQKYBXejfghZlb+ejvvXy97ABd6gdzS+NQOtSpkCnQyi6oCvL1oGv9YPadjGPbsRjik9NYfeAMqw+cH8fl62GjQaUAGlYywda1lQO4poIfbgUcU5eYkpbvXkCHw8Gfm49jsUCX+sGF3ot4pZi+9giHz5yjvJ8ng9PHKmZwt5npEz5ZtJefVocruBKRPFNwJSJyBbpSe0/8PN34ekgLbv1kGWcTTEn51/o0vOSYsgx3tapGXGIqk1Yc4mjUOX7fdIzfNx3Dz9ONrg1MoBWVkJIlqBrRoSb3tqnu7NlLszvYdzKOzUei2XIkii1Ho50B15qDZ1lz8Kxznx5uVhpWCuDeNtXp07Qytjz8bk7FJTFuwW5+Wn2YTnUq8H+DmhKQSxn6DKlpdl76bZuz0p2/pxu3NKnEHc2rcF21MkXWq1jaJKak8fHfewAY2bkWPh5ZT4cGtjTB1dI9pzh8JoGqQT7F3UwRKYUUXImISKlSNciHz+9pzv3frqFrg2B65aNXwWKx8GDHWozoUJONh6OYtdlM5Hw8OpGZG44yc8NR57rZBVUZbFYLdYL9qRPszx3NqwAmsNl/Kp6tR6PZejSGbcei2Z4+UfKG8Cg2hEfx2eJ9jO5ahx4NQ7INgBNT0vh2+UE+/XsvsUmpACzcGcltn/7L10NaUqN8zhMpJySnMmryBv7eGYnFAiEBXhyPTuSn1eH8tDqcGuV9uaN5FW5rVplKl1nFsbSbsjqc49GJhAZ6OcdXXaxqkA831C7P0j2nmLImnGe6Zy2WIiJyMQVXIiJS6rSpWY6Nr3TDzWopUG+MxWKhWbWyNKtWlv/0rM+Gw2f5c/Nx/tpyArvDwX3ta2QbVOXGzWZ1Blz9rjPL7HYH4WcSmL31OF8s2c/eyDge+XE9DSsF8HS3unSqWwGLxYLD4WDWluP876+dHDl7DoBrKwcwpG0YH8zfzb6T8fT99F8+u/s6rr+mfJZ9n4pL4r5v17D5SDSebmZy6K71g1l54DS/rDvK7C3HOXAqnnfn7uK9ebtoXSOIznUr0qluReoE+11VPVrnktP4ZNE+AEbdmPu4u7taVWPpnlNMW3uEJ7rUKZQpE0TkyqbgSkRESqXCOtG1Wi00rx5E8+pBvNK7YaFs88Jth5X35ZFO13BPm+p8vfQAE5buZ9uxGIZ9u4YW1ctyV+tq/LgqnHWHTCphcIAnz3avx23NKmO1WuhYpwIjvl/HxsNRDJ64mld7N+DetmHOfRw4Fc+QiasJP5NAWR93vh7SkubVywLQrlZ52tUqz2t9GvLXluP8vO4Iqw6cYeV+cxv7104qBXrRsW4FOtapyPXXlMtScTHN7iAhOZXo+EQS0wr143GJ71ce5FRcElWDvOnfvGqu63ZpEEx5P09Oxibx985IujfMWxVNEbl6KbgSEREpBgFe7ozuWoeh7cIYv2Qf3y0/yNpDZ1mbHlR5u9t4sGNNRnSomWkMUMUAL6aMaMOYGVuYueEoL/22jZ0nYnn11oZsORrN/d+u4WxCClWDvPluWCtqVvDLsm8/Tzf6t6hK/xZVOXwmgYU7Ili8+yQr9p3mWHQiP60+zE+rD+NmtVCjvC+JqWkkJKURn5xKYsr5UuTuVhu+NSO4pWmVov/AisC2Y9F8vHAvAI/dWBsPt9wDdHeblf4tqvD54n38tDpcwZWIXJLL+7c//fRTwsLC8PLyonXr1qxevTrX9aOiohg5ciShoaF4enpSp04dZs+e7Xw+LS2Nl156iRo1auDt7U2tWrV44403cDg0H4mIiLhekK8H/+lZn3+e7cy9barj7+VGv+sqs+jpTjzRpU62xRW83G18MKAJz/Woh8UCP64K547Pl3Pnlys5m5BC4yqBzHj4+mwDq4tVDfJh6PU1+HZYKza90o1vhrVkaLswwsr5kGp3sCcyjsNnznE6PjlTYGWxQIrdwpPTN7Nsz6lC/UyKw/6TcQyesJrYpFRa1QjitmaV8/S6Qenzxi3ZfZIjZxMusbaIXO1c2nM1depURo8ezfjx42ndujXjxo2je/fu7Nq1i4oVs85XkpycTNeuXalYsSI///wzlStX5tChQ5QpU8a5zttvv83nn3/Od999R8OGDVm7di3Dhg0jMDCQxx57rBjfnYiISM6CA7x4o++1vNH32jytb7FYeLhTLa6p6McTUzaw6Ug0YOZk+uSuZtkGZZfi5W6jc92KdK5bEWjIwVPxHDl7Dh9PG74ebvh42PD1ND+xpzHow7lsPGNlxPdr+fGB1jSrVjZP+3E4HC4d13U06hz3fL2K0/HJXFs5gK+HtMhzefzq5Xy5/ppy/Lv3NNPWHGZ0t7pF3NpLyyi3HxLoRcuwIFc3R0Qu4NLg6oMPPmD48OEMGzYMgPHjxzNr1iwmTpzI888/n2X9iRMncubMGZYvX467u8kJDwsLy7TO8uXL6dOnD7169XI+/9NPP+XaI5aU9P/t3Xl8VNX5x/HPZGYy2XeyQkhYw76FYIQqCBXRWjY3jBpEiwhYwGpBW0RrEZeW+hMRSlXUCqJYF0RckM2yh30n7MSQjUB2ss79/RGdGgkQ4sgE+L5fr3ll5t5z7z0XHkKenHueU0ZZWZnjc0FBAQAVFRVUVFT8rHusix+ucSmuJVcWxY7Uh+Lm8ta7ZRDv/y6BZz7fR8coPx77dUssJsMpf59R/u5E+ddW1t5ORVUl97a045UTzNrDpxk+dyPzH+hOqzDfc54vr6SCaV/u57MdGTQP8aZ360b0bhVC5yYBdSpJ7wy5RWXc83oKJ/JLaRbizev3dsXTfHHxf0fXKNYczOX9TWk8fF1Mvdctc5YPt6TzxMe78bS6seLRXxHsY3Npfy5E33OkPhpS3FxMH0yGi56XKy8vx8vLiw8//JBBgwY5ticnJ5OXl8enn3561jE333wzQUFBeHl58emnn9KoUSPuvvtuJk6ciNlcXe3nueeeY86cOXz99de0atWK7du3c+ONNzJ9+nSSkpJq7cvTTz/NM888c9b2+fPn4+WldS1ERER+UFYFr+0xc7TIhJ/VYHz7KoI9arYxDNiWa+LDo24UVZydRHlZDNoEGLQLNIjzNyi3w8lSEzmlNb+eKgNvC4R5GoR5QriX4XjvVYdfD5dUwqu7zaSXmAh0NxjXvorAeuQhlXaYstlMUaWJnmF2hsTYucB0rTorqwJ3t+rHLusi6wz8bYeZcnv1Af2i7Nwabb/AUSLyc5SUlHD33XeTn5+Pn5/fedu6bOTq5MmTVFVVERYWVmN7WFgY+/btq/WYw4cPs3z5cpKSkliyZAkHDx5k9OjRVFRUMGXKFAAmTZpEQUEBcXFxmM1mqqqqmDp16jkTK4AnnniCRx991PG5oKCAJk2acOONN17wD9AZKioqWLp0Kb/+9a8dI3IidaHYkfpQ3Eh9/BA3v7np1/TpC0lvpJCaXcRbx3xZ8GACjXyrs5aM/FKe/mwvyw/kANCikTd/viWOk0XlrNifw38PnKSgtJLNJ01srsPUrdIqyC0zsSev5vZGPu50bhJAn9aN6NM6hJCfjN6UlFcy4u0tpJfkEeLjznsPdicm+NzrhF1IcVgaTy3ay5osN4rdA3nlzk5E+Htc+ECqH+PLLCjjYE4Rh3KKf/Qq4lRxBb/tGMELQ9pdcESsrKKK2+ZspNxeSFSAB+l5paw7aWXafdcR4NVw/y3re47UR0OKmx+eaquLy6paoN1uJzQ0lDlz5mA2m+nWrRvp6em89NJLjuTqgw8+YN68ecyfP5927dqxbds2xo8fT2RkJMnJybWe12azYbOd/assq9V6Sf8yL/X15Mqh2JH6UNxIfVitVhp5WXn3wR7cNnsdx0+VMOKdLSwYeU31Wl1L9lFYVonVbGJ07xaM7tMcm6X66ZLb4qOprLKz5Xgey/dls3xfFqlZRVjcTDQJ8qJpsBcxwd6Or40DPcktLudgdlGNV2ZBKTlF5Szdm83SvdkAdGoSQL+4UPq2CaN5qDdjF+xg8/E8/DwsvDOiBy3Df94vS++7thmNg7wZv2Ab29LyGTxrPTOGdeHaWtYd+8Hx3BJeX32Yj7emU1haec52i3ZkYDG78bfbO9W6uPQPpn6Ryr7MQoK83fnPwz0ZPncj+zILmZdSvQ5XQ6fvOVIfDSFuLub6LkuuQkJCMJvNZGVl1dielZVFeHjtpU4jIiKwWq2ORwAB2rRpQ2ZmJuXl5bi7u/P4448zadIk7rrrLgA6dOjAsWPHmDZt2jmTKxEREbk4oX4evPtAD4bOXsu+zEJ6vbCCorLqBKJLdAAvDO1Y63wsi9mNhNggEmKDmDQgjvySCrxt5nOO2rSketHoHyssrSA1q4j/Hshh2d5sdqbnsz0tj+1pefx9aSo+NgtFZZV4Ws3Mvb87bSOd8xTKDXFhLH7kV4x6dzN7Mgq4540NPNa/NaOua14jKdqelsecbw/zxa4M7N9PvrC4mWga7EWLUB/Hq2WoL0dOFjP+/W18tDUdd4sbzw3uUGuC9c2eLN5aexSAv93ekXB/D8be0IKx87cyd81RHugVe9YaZSJy6bksuXJ3d6dbt24sW7bMMefKbrezbNkyxo4dW+sxPXv2ZP78+djtdtzcqr8Jp6amEhERgbt79QTckpISx74fmM1m7HY9jywiIuJM0cFe/PuBBO6YvY6C0kq83M083r819yXG1LlghX89Hmfz9bDSrWkg3ZoGMr5fK7IKSlm+L5tle7NYffAkRd+PnM25rxvdmjq3ml50sBcfjb6WyZ/sYuHm73jxy/1sOZbH32/vxObjp/jnqsNsOHLK0f66Vo343a9i6REbXOu6Wu2j/AEYt2ArC1LScLe48cxv29WorpiZX8rjH24HYETPWG6Iq55SMaB9BM0apXI4p5h/rz/G6N4tnHqvInLxXPpY4KOPPkpycjLx8fEkJCTw8ssvU1xc7KgeeN999xEVFcW0adMAePjhh3n11VcZN24cjzzyCAcOHOC5556rUWL91ltvZerUqURHR9OuXTu2bt3K9OnTGTFihEvuUURE5EoWF+7H+w8l8vmODO7s3oQmQZe+EFSYnwfDEqIZlhDNmfIqNhzJJdTXw2kjVj/lYTXz0u2d6NY0kKcW7eabvVl0f+4byiurf5FrcTPx286R/O5XzWgTceE+3NopkooqO39YuJ131h3D3ezGn25pg8lkospuMOH9bZwuqaBdpB8TB/yvFLzZzcSY3i34w8LtvP7fIwy/Nua8JfntdoPpS1M5dqqE5wa310iXyC/ApcnVnXfeSU5ODk899RSZmZl07tyZL7/80lHk4vjx4zVGoZo0acJXX33FhAkT6NixI1FRUYwbN46JEyc62syYMYPJkyczevRosrOziYyM5KGHHuKpp5665PcnIiJyNWgT4VenJOJS8HQ307v12Wtl/hLuSoimbaQfD7+7hfS8M/jYLNzdI5r7e8YQ4e95Ueca0rUxZZV2nvhoJ6+vPoLN6sZjN7Zm1sqDrDuci5e7mRnDujjmr/1gYOdIXl6WStqpM7y3MY0HesWe8xovfLWPf646DECV3c7Mu7u6dP2x4rJKZq44iNXsRsswH1qF+RIT7F3rCJ/I5cLlBS3Gjh17zscAV65ceda2xMRE1q9ff87z+fr68vLLL/Pyyy87qYciIiIitevYOIAlv/8Vaw+dpGfLEPx+xmjQsIRoyivtTFm0m5krDpGRX8qn204A8JeB7WnWyOesYyxmN0b3bsETH+1kzreHSOoRjYfVfFa7uWuOOBIrs5uJJTszefP7uVqu8tfP9/LexuM1tlncTMSGeNMyrHpO2sDOkbXet0hDpV8NiIiIiPwM/l5WBnSI+FmJ1Q+Sr43hTze3AeCjLelU2Q0GdY5kaNeocx4zpGsUEf4eZBWUsXDzd2ft/3xHBn9ZvAeAx/u3ZvIt1eeftmQvm4+dOqv9xTIMg/wzF7fQ67epOY7E6redIuncJAAfm4VKu8GB7CKW7Mzk/5YdYODMNRzMLvrZfRS5VFw+ciUiIiIi//O765pRVlnF375OJSbYi2cHtT/v43s2i5lR1zdnyqLdzF55iLu6N8H6ffXF9YdzmfD+NgwD7r2mKaN7Nwcg5dhpPt+RwZh5W1n8+15nrRN2IaUVVaw/nPt9IZFs0vPO8NiNrRh7Q8sLHltQWsGk/+wAIDmxKc8MbA9UJ2kZ+aWkZhVyIKuIT7als/tEAQ++ncInY3oS4OV+UX28GMdzS3jhy33sOpHPS7d1IiHWuYVQ5Oqh5EpERESkgRl7Q0t6tw4lOtirToUn7uzehBnLD5Ked4aPt6ZzR3wT9mcW8rt3NlFeZad/uzCe/lEVwheGdmRfRgGHcooZt2Ar74zoccEKj9mFpaz4PplaffAkJeVVNfb/7etUwv09ua1b4/Oe57nP93Iiv5ToIC8mDohzbDeZTEQGeBIZ4Env1qEM7hrFwFfXcDS3hIff3cI7DyQ4kkZnKSytYOaKQ7y5+gjlVdUFSYbP3cjc4d3p8ZMlAETqQo8FioiIiDRA7aP86/yooYfVzMjrqudPvbbiIGmnShg+dyOFpZXENw3k/+7qUiN58rFZmHVPNzytZtYczOXlb1LPee7Nx07zwFspJExdxsT/7OTrPVmUlFcR7ufB3T2ieSM5noeuawbApP/sYPWBk+c816rUHBakpAHw0m0dz1vdMMTHxhvD4/F2N7PucC5TFu3GMIw6/XlcSJXd4P2U4/T52ypmrzpEeZWdXi1C6NkimJLyKobPTWH94VynXEuuLhq5EhEREbkCJPVoyqyVhziaW8JvZqwm/0wFzRt583pyfK1FLlqF+fL80A6MW7CNGcsP0rVpIH2+r7RoGAZrD+Xy6vLqaoU/6NTYnxviwujbJpR2kX6OkbA+rUPJyC9l0fYTjHp3MwtHJZ5VQbLwR48D3t8zpk4jQ3HhfrwyrAsPvrOJ+RuO0yrUh+E9f14RjvWHc/nLZ3vYk1EAQGyIN3+6uQ1924RSVmln5L83821qDvfPTeHN4d1JbK4RLKk7jVyJiIiIXAG8bRZH9b/8MxWE+dl4e0TCeecqDewcxT3XRAMw4f1tpJ0qYdneLAa/tpak1zew7nAuFjcTd8Q3ZvkfrufTsb0Y168l7aP8a8wDc3Mz8dLtHekRG0RRWSX3z00hI/9MjWs990UqGfmlxAR78cf+cdRV3zZhPDmgugjHXxbvYeX+7Dof+2M7v8vnwbc3cdec9ezJKMDXw8Kfb2nDV+Ovo1/bMEwmEx5WM3Pu7cb1rRpxpqKKEW+lsPbQuUfi6qKwtMJpI27S8Cm5EhEREblC3HdtDCE+Nnw9LMwdnkDjwAsv6jz5N23p1NifvJIK+k1fxQNvb2JbWh42ixvJiU1Z9cc+vHhbpwuWRLdZzMy5N54WoT5kFpRy/9wUCkurqwjuOW3iwy3pmEzw0u2d8HQ/eyTtfB78VSx3xDfGbsAj87dyMLuwzsduPX6aEW+lcOurq/lmbxZuJrjnmmhWPtabB3/V7Kx1tTysZv55bzd6t/5RgnXw4hOsssoqnl28h47PfM3ts9ep6uFVQsmViIiIyBXCz8PK0gnXserxPrSNrNvCzjaLmZlJXQnwslJWacfb3cxD1zdj9cQbeGZge6IC6r4gsr+XlbnDuxPiY2NfZiGj520ht7icBYeqf+Qc0TOW7jEXX4nPZDLx10EdSIgNorCskhFvbeJ0cfl5j9l09BT3vbmRwa+tZfm+bNxMMLhLFF9PuJ6/DupA8HkqJHpYzcy+pxt9WjeitMLOiLdTWHMRCdahnCKGvLaWN1YfwTBg07HT3PzKf5m54iAV3xfOOJ+8knLeTznOiv3ZGvW6zGjOlYiIiMgVJND74kuWNw70YsHIa0g5eppbO0b8rLLnTYK8eHN4PHf+cz3/PXCSW2asJb/CREywF4/d2Lre53W3uDH7nm4MnLma46dK6Dt9FZEBHgR4uuPvZSXQy1r93tPKiv3ZrD1UPVfM7GZicJcoxvRpQWyId52v52E1M/veboz692ZW7M9hxFspPNArlmEJ0TQJqn1E0DAMPtiUxtOL9nCmoopALytP3tyGxTsyWJWaw0tf7WfJzgxevK0j7SL9zzp+b0YBb689yifb0imtqE7CEmKDmHxLWzo0Prv9pXIi7wyrUnPoGxdKqJ+Hy/pxOVByJSIiIiLEhfsRF1630a4L6dg4gFfv7sLv3tlEbnE5JgxeGNL+oh8H/Kkgb3feTO7OnXPWc6q4nFPnGb2yuJm4rVtjRvduQXTwhR+PrI3NUp1gjX53C8v2ZfPaykPMWnWI61s1IqlHU26IC3VUYcw/U8GTH+3k850ZAFzbPJjpd3Qm3N+D27o15qMt6fxl8R52nyhg4KtrGHV9cx7p2wKzycTXe7J4a+1RNh7536LOLUJ9+O50CRuPnOK3M1czpEtjHu/fmnD/S5fcnC4u57WVB3l73THKK+24W9wY1r0Jo3o3J8K/7iOaVxMlVyIiIiLidH3bhDF1cAeeXbyH3mHldI0OcMp5W4b58u0f+3Agq5C8MxXklZSTV1LB6ZIK8kvKOV1SQaivjeE9Y+o05+xCbBYzc+6L5+vdmczfeJz/HjjJyv05rNyfQ6S/B3clRNM2wo8pi3aTnncGi5uJP9zYmoeua4bb94mXyWRiaLfGXNeqEVMW7WLJzkxeXXGQJTszKK2o4kR+KVA9ynZTu3DuS2xKQmwQGfmlvPTVfj7ems5/tnzHkp0ZPHR9M0Ze1+y8Zex/rjPlVby55gizVx2isLQSgAh/DzLyS3l73THe25jGbfGNefj65uccxbtaKbkSERERkV/EsIRoBnYMY+lXXzr1vD42C12iA516zvMxu5kY0CGCAR0iOHqymPc2HueDTWmcyC9l+tL/rREWHeTFK8O60LlJQK3naeRr47Wkbny5K4M/f7KbwyeLAQj2dmdYQjRJ10TXGBGKDPDkH3d2JvnaGJ5dvIfNx07z8jcHWLAxjYd7N6fP9wtNO0tllZ0PNn3Hy9+kkl1YBkBcuC+TBsRxfatGrDuUyyvLD7D+8CnmbzjOBylpDOkaxejeLYi5iEcur2RKrkRERETkF2M1X1n102JCvHni5jZM+HUrvtyVybwNx0g5epohXaJ4ZmA7fOuw8PNN7SO4plkwb609SnSQFzd3iKh1LbIfdG4SwIejEvl8ZwbPf7GP706fYcqi3UxhN02CPOnVIoReLRqR2DyYoB/NuSspryQ1q4jUzEL2ZRaSmlVIVkEpVrMbNqsb7mY3bFbz91/d2HuiwJHwNQ705A83tmJgpyjHCNy1LUK4tkUIGw7nMmP5QVYfPMkHm77jw83fcV9iDI/3b4237epOL67uuxcRERERqQcPq5lBXaIY1CWKkvLKi35ML8DLnfH9WtW5vclk4jcdI+nXJox5G47z1a5Mthw/TdqpM7y3MY33NqZhMkG7SD/C/TxJzSok7XQJF1tsMMjbnUduaMHdPaKxWWpP+Ho0C6ZHs2A2HzvNq8sPsGJ/Dm+tPcrSPVlMHdye3t8vRn01UnIlIiIiIvIz/JLzn37Kw2rmgV6xPNArlqKySjYeyWX1gVzWHDzJ/qxCdqUXsCu9wNE+xMdG63AfWof50Trch8aBXlRU2SmvtFNW+b+vZZVVeFjN/KZjRJ1G3wC6NQ1k7v0JfJuaw5Mf7+S702cYPjeFIV2imPybtvWqXHm5U3IlIiIiInIZ8rFZuCEujBviwgDILihl7aFc8krKaRXmS+tw3/Ou5+Us17VqxFfjr+PvX6cyd+0RPtqazqrUHJ4Z2I5bOkRgMpkcbavsBumnz3Aop4jDJ4sJ8XEnPibootZTa8iUXImIiIiIXAFC/TwY1CXKJdf2tll46ta2/KZTBBM/3MGB7CLGzt/KJ21O0DbCl0M5xY6Eqrzy7IWUI/09iI8JontMIPExQcQGXZ7raSm5EhERERERp+gaHcji3/fitRWHeG3lQb7Zm8U3e7NqtHG3uNEsxJuYYG8y8s+w60QBJ/JLWbT9BIu2nwCqR+WaeLrRs08FIda6PabYECi5EhERERERp7FZzEz4dStu7hDBnG8PYzWbaBHqQ/NG1a+oQE/H4stQXdVw2/E8Uo6eZtOxU2w5dpqiskqOVZnwvcyqD15evRURERERkctC63Bf/n5Hpwu283K3OMq8Q/V6W7u+O83ny9c4ysBfLpRciYiIiIhIg2Exu9Eu0o9jQRdZR74BuLJWdRMREREREXERJVciIiIiIiJOoORKRERERETECZRciYiIiIiIOIGSKxERERERESdQciUiIiIiIuIESq5EREREREScQMmViIiIiIiIEyi5EhERERERcQIlVyIiIiIiIk6g5EpERERERMQJlFyJiIiIiIg4gZIrERERERERJ1ByJSIiIiIi4gQWV3egITIMA4CCgoJLcr2KigpKSkooKCjAarVekmvKlUGxI/WhuJH6UNxIfSl2pD4aUtz8kBP8kCOcj5KrWhQWFgLQpEkTF/dEREREREQagsLCQvz9/c/bxmTUJQW7ytjtdk6cOIGvry8mk+kXv15BQQFNmjQhLS0NPz+/X/x6cuVQ7Eh9KG6kPhQ3Ul+KHamPhhQ3hmFQWFhIZGQkbm7nn1WlkatauLm50bhx40t+XT8/P5cHj1yeFDtSH4obqQ/FjdSXYkfqo6HEzYVGrH6gghYiIiIiIiJOoORKRERERETECZRcNQA2m40pU6Zgs9lc3RW5zCh2pD4UN1IfihupL8WO1MflGjcqaCEiIiIiIuIEGrkSERERERFxAiVXIiIiIiIiTqDkSkRERERExAmUXImIiIiIiDiBkqsGYObMmcTExODh4UGPHj3YuHGjq7skDci0adPo3r07vr6+hIaGMmjQIPbv31+jTWlpKWPGjCE4OBgfHx+GDh1KVlaWi3osDdHzzz+PyWRi/Pjxjm2KG6lNeno699xzD8HBwXh6etKhQwc2bdrk2G8YBk899RQRERF4enrSr18/Dhw44MIeS0NQVVXF5MmTiY2NxdPTk+bNm/Pss8/y47ppih359ttvufXWW4mMjMRkMvHJJ5/U2F+XGDl16hRJSUn4+fkREBDAAw88QFFR0SW8i/NTcuVi77//Po8++ihTpkxhy5YtdOrUif79+5Odne3qrkkDsWrVKsaMGcP69etZunQpFRUV3HjjjRQXFzvaTJgwgc8++4yFCxeyatUqTpw4wZAhQ1zYa2lIUlJS+Oc//0nHjh1rbFfcyE+dPn2anj17YrVa+eKLL9izZw9///vfCQwMdLR58cUXeeWVV5g9ezYbNmzA29ub/v37U1pa6sKei6u98MILzJo1i1dffZW9e/fywgsv8OKLLzJjxgxHG8WOFBcX06lTJ2bOnFnr/rrESFJSErt372bp0qUsXryYb7/9lpEjR16qW7gwQ1wqISHBGDNmjONzVVWVERkZaUybNs2FvZKGLDs72wCMVatWGYZhGHl5eYbVajUWLlzoaLN3714DMNatW+eqbkoDUVhYaLRs2dJYunSpcf311xvjxo0zDENxI7WbOHGi0atXr3Put9vtRnh4uPHSSy85tuXl5Rk2m8147733LkUXpYG65ZZbjBEjRtTYNmTIECMpKckwDMWOnA0wPv74Y8fnusTInj17DMBISUlxtPniiy8Mk8lkpKenX7K+n49GrlyovLyczZs3069fP8c2Nzc3+vXrx7p161zYM2nI8vPzAQgKCgJg8+bNVFRU1IijuLg4oqOjFUfCmDFjuOWWW2rEByhupHaLFi0iPj6e22+/ndDQULp06cK//vUvx/4jR46QmZlZI278/f3p0aOH4uYqd+2117Js2TJSU1MB2L59O6tXr2bAgAGAYkcurC4xsm7dOgICAoiPj3e06devH25ubmzYsOGS97k2Fld34Gp28uRJqqqqCAsLq7E9LCyMffv2uahX0pDZ7XbGjx9Pz549ad++PQCZmZm4u7sTEBBQo21YWBiZmZku6KU0FAsWLGDLli2kpKSctU9xI7U5fPgws2bN4tFHH+XJJ58kJSWF3//+97i7u5OcnOyIjdr+31LcXN0mTZpEQUEBcXFxmM1mqqqqmDp1KklJSQCKHbmgusRIZmYmoaGhNfZbLBaCgoIaTBwpuRK5jIwZM4Zdu3axevVqV3dFGri0tDTGjRvH0qVL8fDwcHV35DJht9uJj4/nueeeA6BLly7s2rWL2bNnk5yc7OLeSUP2wQcfMG/ePObPn0+7du3Ytm0b48ePJzIyUrEjVxU9FuhCISEhmM3ms6pzZWVlER4e7qJeSUM1duxYFi9ezIoVK2jcuLFje3h4OOXl5eTl5dVorzi6um3evJns7Gy6du2KxWLBYrGwatUqXnnlFSwWC2FhYYobOUtERARt27atsa1NmzYcP34cwBEb+n9Lfurxxx9n0qRJ3HXXXXTo0IF7772XCRMmMG3aNECxIxdWlxgJDw8/q+hbZWUlp06dajBxpOTKhdzd3enWrRvLli1zbLPb7SxbtozExEQX9kwaEsMwGDt2LB9//DHLly8nNja2xv5u3bphtVprxNH+/fs5fvy44ugq1rdvX3bu3Mm2bdscr/j4eJKSkhzvFTfyUz179jxrqYfU1FSaNm0KQGxsLOHh4TXipqCggA0bNihurnIlJSW4udX8sdJsNmO32wHFjlxYXWIkMTGRvLw8Nm/e7GizfPly7HY7PXr0uOR9rpWrK2pc7RYsWGDYbDbjrbfeMvbs2WOMHDnSCAgIMDIzM13dNWkgHn74YcPf399YuXKlkZGR4XiVlJQ42owaNcqIjo42li9fbmzatMlITEw0EhMTXdhraYh+XC3QMBQ3craNGzcaFovFmDp1qnHgwAFj3rx5hpeXl/Huu+862jz//PNGQECA8emnnxo7duwwBg4caMTGxhpnzpxxYc/F1ZKTk42oqChj8eLFxpEjR4yPPvrICAkJMf74xz862ih2pLCw0Ni6dauxdetWAzCmT59ubN261Th27JhhGHWLkZtuusno0qWLsWHDBmP16tVGy5YtjWHDhrnqls6i5KoBmDFjhhEdHW24u7sbCQkJxvr1613dJWlAgFpfc+fOdbQ5c+aMMXr0aCMwMNDw8vIyBg8ebGRkZLiu09Ig/TS5UtxIbT777DOjffv2hs1mM+Li4ow5c+bU2G+3243JkycbYWFhhs1mM/r27Wvs37/fRb2VhqKgoMAYN26cER0dbXh4eBjNmjUz/vSnPxllZWWONoodWbFiRa0/0yQnJxuGUbcYyc3NNYYNG2b4+PgYfn5+xv33328UFha64G5qZzKMHy2dLSIiIiIiIvWiOVciIiIiIiJOoORKRERERETECZRciYiIiIiIOIGSKxERERERESdQciUiIiIiIuIESq5EREREREScQMmViIiIiIiIEyi5EhERERERcQIlVyIiIk5mMpn45JNPXN0NERG5xJRciYjIFWX48OGYTKazXjfddJOruyYiIlc4i6s7ICIi4mw33XQTc+fOrbHNZrO5qDciInK10MiViIhccWw2G+Hh4TVegYGBQPUje7NmzWLAgAF4enrSrFkzPvzwwxrH79y5kxtuuAFPT0+Cg4MZOXIkRUVFNdq8+eabtGvXDpvNRkREBGPHjq2x/+TJkwwePBgvLy9atmzJokWLftmbFhERl1NyJSIiV53JkyczdOhQtm/fTlJSEnfddRd79+4FoLi4mP79+xMYGEhKSgoLFy7km2++qZE8zZo1izFjxjBy5Eh27tzJokWLaNGiRY1rPPPMM9xxxx3s2LGDm2++maSkJE6dOnVJ71NERC4tk2EYhqs7ISIi4izDhw/n3XffxcPDo8b2J598kieffBKTycSoUaOYNWuWY98111xD165dee211/jXv/7FxIkTSUtLw9vbG4AlS5Zw6623cuLECcLCwoiKiuL+++/nr3/9a619MJlM/PnPf+bZZ58FqhM2Hx8fvvjiC839EhG5gmnOlYiIXHH69OlTI3kCCAoKcrxPTEyssS8xMZFt27YBsHfvXjp16uRIrAB69uyJ3W5n//79mEwmTpw4Qd++fc/bh44dOzree3t74+fnR3Z2dn1vSURELgNKrkRE5Irj7e191mN6zuLp6VmndlartcZnk8mE3W7/JbokIiINhOZciYjIVWf9+vVnfW7Tpg0Abdq0Yfv27RQXFzv2r1mzBjc3N1q3bo2vry8xMTEsW7bskvZZREQaPo1ciYjIFaesrIzMzMwa2ywWCyEhIQAsXLiQ+Ph4evXqxbx589i4cSNvvPEGAElJSUyZMoXk5GSefvppcnJyeOSRR7j33nsJCwsD4Omnn2bUqFGEhoYyYMAACgsLWbNmDY888silvVEREWlQlFyJiMgV58svvyQiIqLGttatW7Nv3z6gupLfggULGD16NBEREbz33nu0bdsWAC8vL7766ivGjRtH9+7d8fLyYujQoUyfPt1xruTkZEpLS/nHP/7BY489RkhICLfddtulu0EREWmQVC1QRESuKiaTiY8//phBgwa5uisiInKF0ZwrERERERERJ1ByJSIiIiIi4gSacyUiIlcVPQ0vIiK/FI1ciYiIiIiIOIGSKxERERERESdQciUiIiIiIuIESq5EREREREScQMmViIiIiIiIEyi5EhERERERcQIlVyIiIiIiIk6g5EpERERERMQJ/h9E5c7+yFvFxQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:42:35,983] A new study created in memory with name: no-name-4719fd28-6866-4833-9587-b59e0664d408\n",
      "/tmp/ipykernel_682/3044487090.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  hyperparameter['LEARNING_RATE'] = trial.suggest_loguniform('LEARNING_RATE', 1e-5, 1e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 127, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.3218775692645613, 'LEARNING_RATE': 2.617623336579906e-05}\n",
      "Epoch 1, Train Loss: 0.7677, Val Loss: 0.7541, Test Accuracy: 0.4718 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.584235429763794\n",
      "Epoch 2, Train Loss: 0.7679, Val Loss: 0.7498, Test Accuracy: 0.4744 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5493006706237793\n",
      "Epoch 3, Train Loss: 0.7685, Val Loss: 0.7457, Test Accuracy: 0.4731 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5541126728057861\n",
      "Epoch 4, Train Loss: 0.7560, Val Loss: 0.7420, Test Accuracy: 0.4771 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5458157062530518\n",
      "Epoch 5, Train Loss: 0.7530, Val Loss: 0.7387, Test Accuracy: 0.4784 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5549993515014648\n",
      "Epoch 6, Train Loss: 0.7593, Val Loss: 0.7358, Test Accuracy: 0.4823 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5529665946960449\n",
      "Epoch 7, Train Loss: 0.7540, Val Loss: 0.7333, Test Accuracy: 0.4823 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5534365177154541\n",
      "Epoch 8, Train Loss: 0.7502, Val Loss: 0.7307, Test Accuracy: 0.4836 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5539252758026123\n",
      "Epoch 9, Train Loss: 0.7534, Val Loss: 0.7288, Test Accuracy: 0.4849 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5544757843017578\n",
      "Epoch 10, Train Loss: 0.7530, Val Loss: 0.7272, Test Accuracy: 0.4875 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5552918910980225\n",
      "Epoch 11, Train Loss: 0.7504, Val Loss: 0.7255, Test Accuracy: 0.4849 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.554192066192627\n",
      "Epoch 12, Train Loss: 0.7511, Val Loss: 0.7239, Test Accuracy: 0.4823 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5536329746246338\n",
      "Epoch 13, Train Loss: 0.7447, Val Loss: 0.7225, Test Accuracy: 0.4849 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5584704875946045\n",
      "Epoch 14, Train Loss: 0.7436, Val Loss: 0.7212, Test Accuracy: 0.4875 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5519731044769287\n",
      "Epoch 15, Train Loss: 0.7470, Val Loss: 0.7201, Test Accuracy: 0.4849 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.549297571182251\n",
      "Epoch 16, Train Loss: 0.7379, Val Loss: 0.7190, Test Accuracy: 0.4862 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.7528178691864014\n",
      "Epoch 17, Train Loss: 0.7433, Val Loss: 0.7182, Test Accuracy: 0.4875 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5525407791137695\n",
      "Epoch 18, Train Loss: 0.7411, Val Loss: 0.7172, Test Accuracy: 0.4889 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5537152290344238\n",
      "Epoch 19, Train Loss: 0.7396, Val Loss: 0.7161, Test Accuracy: 0.4941 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5477983951568604\n",
      "Epoch 20, Train Loss: 0.7376, Val Loss: 0.7153, Test Accuracy: 0.4954 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.546257495880127\n",
      "Epoch 21, Train Loss: 0.7403, Val Loss: 0.7146, Test Accuracy: 0.4967 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5469326972961426\n",
      "Epoch 22, Train Loss: 0.7386, Val Loss: 0.7137, Test Accuracy: 0.4980 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5548474788665771\n",
      "Epoch 23, Train Loss: 0.7415, Val Loss: 0.7132, Test Accuracy: 0.4980 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5592191219329834\n",
      "Epoch 24, Train Loss: 0.7317, Val Loss: 0.7128, Test Accuracy: 0.4967 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5602941513061523\n",
      "Epoch 25, Train Loss: 0.7352, Val Loss: 0.7122, Test Accuracy: 0.4928 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5630302429199219\n",
      "Epoch 26, Train Loss: 0.7341, Val Loss: 0.7117, Test Accuracy: 0.4954 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5602247714996338\n",
      "Epoch 27, Train Loss: 0.7375, Val Loss: 0.7112, Test Accuracy: 0.4915 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5610918998718262\n",
      "Epoch 28, Train Loss: 0.7365, Val Loss: 0.7106, Test Accuracy: 0.4875 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5569429397583008\n",
      "Epoch 29, Train Loss: 0.7418, Val Loss: 0.7101, Test Accuracy: 0.4875 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5591974258422852\n",
      "Epoch 30, Train Loss: 0.7284, Val Loss: 0.7096, Test Accuracy: 0.4889 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5601439476013184\n",
      "Epoch 31, Train Loss: 0.7334, Val Loss: 0.7091, Test Accuracy: 0.4928 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5556514263153076\n",
      "Epoch 32, Train Loss: 0.7318, Val Loss: 0.7091, Test Accuracy: 0.4889 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5611932277679443\n",
      "Epoch 33, Train Loss: 0.7307, Val Loss: 0.7086, Test Accuracy: 0.4889 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5616724491119385\n",
      "Epoch 34, Train Loss: 0.7264, Val Loss: 0.7084, Test Accuracy: 0.4823 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5607645511627197\n",
      "Epoch 35, Train Loss: 0.7255, Val Loss: 0.7081, Test Accuracy: 0.4810 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5567989349365234\n",
      "Epoch 36, Train Loss: 0.7258, Val Loss: 0.7079, Test Accuracy: 0.4784 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.558208703994751\n",
      "Epoch 37, Train Loss: 0.7208, Val Loss: 0.7076, Test Accuracy: 0.4810 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5627832412719727\n",
      "Epoch 38, Train Loss: 0.7231, Val Loss: 0.7073, Test Accuracy: 0.4784 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5597097873687744\n",
      "Epoch 39, Train Loss: 0.7234, Val Loss: 0.7071, Test Accuracy: 0.4823 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5613629817962646\n",
      "Epoch 40, Train Loss: 0.7221, Val Loss: 0.7069, Test Accuracy: 0.4823 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5576658248901367\n",
      "Epoch 41, Train Loss: 0.7237, Val Loss: 0.7066, Test Accuracy: 0.4823 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5614821910858154\n",
      "Epoch 42, Train Loss: 0.7185, Val Loss: 0.7062, Test Accuracy: 0.4823 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5578162670135498\n",
      "Epoch 43, Train Loss: 0.7267, Val Loss: 0.7060, Test Accuracy: 0.4849 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5607850551605225\n",
      "Epoch 44, Train Loss: 0.7232, Val Loss: 0.7057, Test Accuracy: 0.4862 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5504312515258789\n",
      "Epoch 45, Train Loss: 0.7192, Val Loss: 0.7054, Test Accuracy: 0.4862 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5492956638336182\n",
      "Epoch 46, Train Loss: 0.7198, Val Loss: 0.7051, Test Accuracy: 0.4875 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5516645908355713\n",
      "Epoch 47, Train Loss: 0.7188, Val Loss: 0.7047, Test Accuracy: 0.4862 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5473308563232422\n",
      "Epoch 48, Train Loss: 0.7147, Val Loss: 0.7043, Test Accuracy: 0.4875 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5494022369384766\n",
      "Epoch 49, Train Loss: 0.7240, Val Loss: 0.7042, Test Accuracy: 0.4875 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.5486304759979248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:43:04,027] Trial 0 finished with value: 0.44692005242463956 and parameters: {'HIDDEN_DIMENSION': 127, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 512, 'DROP_OUT': 0.3218775692645613, 'LEARNING_RATE': 2.617623336579906e-05}. Best is trial 0 with value: 0.44692005242463956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7268, Val Loss: 0.7040, Test Accuracy: 0.4849 ,Learning Rate: 2.617623336579906e-05 , Time Taken : 0.548882007598877\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 103, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 1024, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.12366135111140807, 'LEARNING_RATE': 4.444213029341879e-05}\n",
      "Epoch 1, Train Loss: 0.8183, Val Loss: 0.8066, Test Accuracy: 0.4889 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2939455509185791\n",
      "Epoch 2, Train Loss: 0.8095, Val Loss: 0.8050, Test Accuracy: 0.4889 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2932891845703125\n",
      "Epoch 3, Train Loss: 0.8131, Val Loss: 0.8035, Test Accuracy: 0.4889 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2927114963531494\n",
      "Epoch 4, Train Loss: 0.8091, Val Loss: 0.8020, Test Accuracy: 0.4875 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2929387092590332\n",
      "Epoch 5, Train Loss: 0.8097, Val Loss: 0.8004, Test Accuracy: 0.4849 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.294588565826416\n",
      "Epoch 6, Train Loss: 0.8017, Val Loss: 0.7988, Test Accuracy: 0.4849 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2911360263824463\n",
      "Epoch 7, Train Loss: 0.8062, Val Loss: 0.7974, Test Accuracy: 0.4836 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2923581600189209\n",
      "Epoch 8, Train Loss: 0.8029, Val Loss: 0.7959, Test Accuracy: 0.4836 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29138970375061035\n",
      "Epoch 9, Train Loss: 0.7949, Val Loss: 0.7944, Test Accuracy: 0.4836 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29793524742126465\n",
      "Epoch 10, Train Loss: 0.7941, Val Loss: 0.7929, Test Accuracy: 0.4810 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2932119369506836\n",
      "Epoch 11, Train Loss: 0.7947, Val Loss: 0.7913, Test Accuracy: 0.4823 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2920534610748291\n",
      "Epoch 12, Train Loss: 0.7934, Val Loss: 0.7898, Test Accuracy: 0.4810 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2916746139526367\n",
      "Epoch 13, Train Loss: 0.7910, Val Loss: 0.7883, Test Accuracy: 0.4784 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29413700103759766\n",
      "Epoch 14, Train Loss: 0.7923, Val Loss: 0.7868, Test Accuracy: 0.4784 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29275035858154297\n",
      "Epoch 15, Train Loss: 0.7922, Val Loss: 0.7855, Test Accuracy: 0.4758 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2932274341583252\n",
      "Epoch 16, Train Loss: 0.7897, Val Loss: 0.7841, Test Accuracy: 0.4744 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2954862117767334\n",
      "Epoch 17, Train Loss: 0.7897, Val Loss: 0.7827, Test Accuracy: 0.4744 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.293520450592041\n",
      "Epoch 18, Train Loss: 0.7838, Val Loss: 0.7813, Test Accuracy: 0.4771 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2940254211425781\n",
      "Epoch 19, Train Loss: 0.7911, Val Loss: 0.7799, Test Accuracy: 0.4797 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2925882339477539\n",
      "Epoch 20, Train Loss: 0.7828, Val Loss: 0.7785, Test Accuracy: 0.4784 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2936441898345947\n",
      "Epoch 21, Train Loss: 0.7820, Val Loss: 0.7773, Test Accuracy: 0.4758 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2927711009979248\n",
      "Epoch 22, Train Loss: 0.7782, Val Loss: 0.7759, Test Accuracy: 0.4758 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2993037700653076\n",
      "Epoch 23, Train Loss: 0.7816, Val Loss: 0.7745, Test Accuracy: 0.4810 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.4931473731994629\n",
      "Epoch 24, Train Loss: 0.7796, Val Loss: 0.7731, Test Accuracy: 0.4823 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2942330837249756\n",
      "Epoch 25, Train Loss: 0.7754, Val Loss: 0.7717, Test Accuracy: 0.4836 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2921884059906006\n",
      "Epoch 26, Train Loss: 0.7735, Val Loss: 0.7704, Test Accuracy: 0.4862 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2949223518371582\n",
      "Epoch 27, Train Loss: 0.7735, Val Loss: 0.7690, Test Accuracy: 0.4823 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2935502529144287\n",
      "Epoch 28, Train Loss: 0.7762, Val Loss: 0.7678, Test Accuracy: 0.4836 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29351115226745605\n",
      "Epoch 29, Train Loss: 0.7716, Val Loss: 0.7665, Test Accuracy: 0.4810 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2925858497619629\n",
      "Epoch 30, Train Loss: 0.7694, Val Loss: 0.7652, Test Accuracy: 0.4810 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29547572135925293\n",
      "Epoch 31, Train Loss: 0.7673, Val Loss: 0.7639, Test Accuracy: 0.4810 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29268455505371094\n",
      "Epoch 32, Train Loss: 0.7676, Val Loss: 0.7627, Test Accuracy: 0.4797 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2946004867553711\n",
      "Epoch 33, Train Loss: 0.7635, Val Loss: 0.7616, Test Accuracy: 0.4784 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29231953620910645\n",
      "Epoch 34, Train Loss: 0.7654, Val Loss: 0.7604, Test Accuracy: 0.4797 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29619288444519043\n",
      "Epoch 35, Train Loss: 0.7644, Val Loss: 0.7592, Test Accuracy: 0.4797 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29289865493774414\n",
      "Epoch 36, Train Loss: 0.7614, Val Loss: 0.7579, Test Accuracy: 0.4810 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29451966285705566\n",
      "Epoch 37, Train Loss: 0.7635, Val Loss: 0.7567, Test Accuracy: 0.4797 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2935795783996582\n",
      "Epoch 38, Train Loss: 0.7587, Val Loss: 0.7556, Test Accuracy: 0.4784 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29284095764160156\n",
      "Epoch 39, Train Loss: 0.7593, Val Loss: 0.7544, Test Accuracy: 0.4758 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29137277603149414\n",
      "Epoch 40, Train Loss: 0.7560, Val Loss: 0.7532, Test Accuracy: 0.4758 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2936403751373291\n",
      "Epoch 41, Train Loss: 0.7591, Val Loss: 0.7521, Test Accuracy: 0.4744 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2928812503814697\n",
      "Epoch 42, Train Loss: 0.7594, Val Loss: 0.7510, Test Accuracy: 0.4692 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29399991035461426\n",
      "Epoch 43, Train Loss: 0.7581, Val Loss: 0.7499, Test Accuracy: 0.4705 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29422473907470703\n",
      "Epoch 44, Train Loss: 0.7575, Val Loss: 0.7489, Test Accuracy: 0.4731 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29509425163269043\n",
      "Epoch 45, Train Loss: 0.7557, Val Loss: 0.7478, Test Accuracy: 0.4731 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29576897621154785\n",
      "Epoch 46, Train Loss: 0.7497, Val Loss: 0.7469, Test Accuracy: 0.4758 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2941160202026367\n",
      "Epoch 47, Train Loss: 0.7462, Val Loss: 0.7459, Test Accuracy: 0.4784 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.2951815128326416\n",
      "Epoch 48, Train Loss: 0.7548, Val Loss: 0.7448, Test Accuracy: 0.4784 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29493069648742676\n",
      "Epoch 49, Train Loss: 0.7477, Val Loss: 0.7438, Test Accuracy: 0.4771 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.29245948791503906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:43:19,152] Trial 1 finished with value: 0.4927916120576671 and parameters: {'HIDDEN_DIMENSION': 103, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 1024, 'DROP_OUT': 0.12366135111140807, 'LEARNING_RATE': 4.444213029341879e-05}. Best is trial 1 with value: 0.4927916120576671.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7464, Val Loss: 0.7427, Test Accuracy: 0.4771 ,Learning Rate: 4.444213029341879e-05 , Time Taken : 0.4925954341888428\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 87, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.15838352362616967, 'LEARNING_RATE': 0.000891156666297818}\n",
      "Epoch 1, Train Loss: 0.7267, Val Loss: 0.7032, Test Accuracy: 0.4902 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.028637409210205\n",
      "Epoch 2, Train Loss: 0.7023, Val Loss: 0.6909, Test Accuracy: 0.5360 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0305655002593994\n",
      "Epoch 3, Train Loss: 0.6937, Val Loss: 0.6999, Test Accuracy: 0.4705 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0311877727508545\n",
      "Epoch 4, Train Loss: 0.6941, Val Loss: 0.6920, Test Accuracy: 0.5203 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0274291038513184\n",
      "Epoch 5, Train Loss: 0.6941, Val Loss: 0.6931, Test Accuracy: 0.5177 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0302910804748535\n",
      "Epoch 6, Train Loss: 0.6940, Val Loss: 0.6975, Test Accuracy: 0.4849 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0284450054168701\n",
      "Epoch 7, Train Loss: 0.6890, Val Loss: 0.6907, Test Accuracy: 0.5374 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0299112796783447\n",
      "Epoch 8, Train Loss: 0.6859, Val Loss: 0.6956, Test Accuracy: 0.5177 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0291063785552979\n",
      "Epoch 9, Train Loss: 0.6876, Val Loss: 0.6926, Test Accuracy: 0.5295 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.028414249420166\n",
      "Epoch 10, Train Loss: 0.6893, Val Loss: 0.6936, Test Accuracy: 0.5321 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.026811122894287\n",
      "Epoch 11, Train Loss: 0.6871, Val Loss: 0.6982, Test Accuracy: 0.5256 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0233888626098633\n",
      "Epoch 12, Train Loss: 0.6840, Val Loss: 0.6884, Test Accuracy: 0.5413 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0284333229064941\n",
      "Epoch 13, Train Loss: 0.6865, Val Loss: 0.6997, Test Accuracy: 0.5177 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0293564796447754\n",
      "Epoch 14, Train Loss: 0.6833, Val Loss: 0.6948, Test Accuracy: 0.5374 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0330336093902588\n",
      "Epoch 15, Train Loss: 0.6826, Val Loss: 0.6918, Test Accuracy: 0.5400 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0259766578674316\n",
      "Epoch 16, Train Loss: 0.6814, Val Loss: 0.6982, Test Accuracy: 0.5360 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0270755290985107\n",
      "Epoch 17, Train Loss: 0.6818, Val Loss: 0.6903, Test Accuracy: 0.5583 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.030014991760254\n",
      "Epoch 18, Train Loss: 0.6834, Val Loss: 0.7020, Test Accuracy: 0.5138 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0299475193023682\n",
      "Epoch 19, Train Loss: 0.6808, Val Loss: 0.6903, Test Accuracy: 0.5518 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0331225395202637\n",
      "Epoch 20, Train Loss: 0.6811, Val Loss: 0.7017, Test Accuracy: 0.5269 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.027160406112671\n",
      "Epoch 21, Train Loss: 0.6770, Val Loss: 0.6936, Test Accuracy: 0.5387 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0276570320129395\n",
      "Epoch 22, Train Loss: 0.6790, Val Loss: 0.7041, Test Accuracy: 0.5203 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0348947048187256\n",
      "Epoch 23, Train Loss: 0.6776, Val Loss: 0.6943, Test Accuracy: 0.5426 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.024848222732544\n",
      "Epoch 24, Train Loss: 0.6761, Val Loss: 0.7013, Test Accuracy: 0.5203 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0332891941070557\n",
      "Epoch 25, Train Loss: 0.6733, Val Loss: 0.7003, Test Accuracy: 0.5321 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0317392349243164\n",
      "Epoch 26, Train Loss: 0.6775, Val Loss: 0.6943, Test Accuracy: 0.5400 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0313458442687988\n",
      "Epoch 27, Train Loss: 0.6723, Val Loss: 0.7020, Test Accuracy: 0.5216 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0375819206237793\n",
      "Epoch 28, Train Loss: 0.6722, Val Loss: 0.7018, Test Accuracy: 0.5347 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0299477577209473\n",
      "Epoch 29, Train Loss: 0.6706, Val Loss: 0.7048, Test Accuracy: 0.5256 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0310900211334229\n",
      "Epoch 30, Train Loss: 0.6707, Val Loss: 0.7026, Test Accuracy: 0.5308 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.031038522720337\n",
      "Epoch 31, Train Loss: 0.6696, Val Loss: 0.7086, Test Accuracy: 0.5138 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.032818078994751\n",
      "Epoch 32, Train Loss: 0.6675, Val Loss: 0.7031, Test Accuracy: 0.5308 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0327398777008057\n",
      "Epoch 33, Train Loss: 0.6666, Val Loss: 0.7062, Test Accuracy: 0.5269 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0308809280395508\n",
      "Epoch 34, Train Loss: 0.6674, Val Loss: 0.7069, Test Accuracy: 0.5229 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0400679111480713\n",
      "Epoch 35, Train Loss: 0.6672, Val Loss: 0.7152, Test Accuracy: 0.4941 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.031613826751709\n",
      "Epoch 36, Train Loss: 0.6637, Val Loss: 0.7039, Test Accuracy: 0.5374 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0351014137268066\n",
      "Epoch 37, Train Loss: 0.6653, Val Loss: 0.7163, Test Accuracy: 0.5033 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0296525955200195\n",
      "Epoch 38, Train Loss: 0.6605, Val Loss: 0.7173, Test Accuracy: 0.5072 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0337626934051514\n",
      "Epoch 39, Train Loss: 0.6588, Val Loss: 0.7119, Test Accuracy: 0.5334 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.028611183166504\n",
      "Epoch 40, Train Loss: 0.6546, Val Loss: 0.7251, Test Accuracy: 0.4797 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.03363037109375\n",
      "Epoch 41, Train Loss: 0.6554, Val Loss: 0.7212, Test Accuracy: 0.5177 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0356347560882568\n",
      "Epoch 42, Train Loss: 0.6527, Val Loss: 0.7255, Test Accuracy: 0.5007 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.032087802886963\n",
      "Epoch 43, Train Loss: 0.6499, Val Loss: 0.7259, Test Accuracy: 0.5059 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0352046489715576\n",
      "Epoch 44, Train Loss: 0.6466, Val Loss: 0.7282, Test Accuracy: 0.5098 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0353033542633057\n",
      "Epoch 45, Train Loss: 0.6420, Val Loss: 0.7321, Test Accuracy: 0.5033 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0365190505981445\n",
      "Epoch 46, Train Loss: 0.6419, Val Loss: 0.7296, Test Accuracy: 0.5046 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0372254848480225\n",
      "Epoch 47, Train Loss: 0.6390, Val Loss: 0.7298, Test Accuracy: 0.5269 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0307118892669678\n",
      "Epoch 48, Train Loss: 0.6327, Val Loss: 0.7405, Test Accuracy: 0.5111 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0352699756622314\n",
      "Epoch 49, Train Loss: 0.6335, Val Loss: 0.7396, Test Accuracy: 0.5216 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.0328271389007568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:44:10,810] Trial 2 finished with value: 0.5216251638269986 and parameters: {'HIDDEN_DIMENSION': 87, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.15838352362616967, 'LEARNING_RATE': 0.000891156666297818}. Best is trial 2 with value: 0.5216251638269986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6336, Val Loss: 0.7495, Test Accuracy: 0.5177 ,Learning Rate: 0.000891156666297818 , Time Taken : 1.037951946258545\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 125, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.22447643284566254, 'LEARNING_RATE': 0.00012585476001500062}\n",
      "Epoch 1, Train Loss: 0.7868, Val Loss: 0.7278, Test Accuracy: 0.4889 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5535504817962646\n",
      "Epoch 2, Train Loss: 0.7550, Val Loss: 0.7223, Test Accuracy: 0.4731 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5498790740966797\n",
      "Epoch 3, Train Loss: 0.7381, Val Loss: 0.7160, Test Accuracy: 0.4771 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5508663654327393\n",
      "Epoch 4, Train Loss: 0.7268, Val Loss: 0.7114, Test Accuracy: 0.4731 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5481016635894775\n",
      "Epoch 5, Train Loss: 0.7146, Val Loss: 0.7075, Test Accuracy: 0.4718 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.546640157699585\n",
      "Epoch 6, Train Loss: 0.7140, Val Loss: 0.7055, Test Accuracy: 0.4653 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5399646759033203\n",
      "Epoch 7, Train Loss: 0.7119, Val Loss: 0.7048, Test Accuracy: 0.4495 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5403404235839844\n",
      "Epoch 8, Train Loss: 0.7095, Val Loss: 0.7016, Test Accuracy: 0.4679 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5420153141021729\n",
      "Epoch 9, Train Loss: 0.7053, Val Loss: 0.7005, Test Accuracy: 0.4810 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5467746257781982\n",
      "Epoch 10, Train Loss: 0.7026, Val Loss: 0.6986, Test Accuracy: 0.5020 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5500319004058838\n",
      "Epoch 11, Train Loss: 0.7011, Val Loss: 0.6999, Test Accuracy: 0.4889 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5456483364105225\n",
      "Epoch 12, Train Loss: 0.6988, Val Loss: 0.6982, Test Accuracy: 0.4980 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5427224636077881\n",
      "Epoch 13, Train Loss: 0.7026, Val Loss: 0.6971, Test Accuracy: 0.5216 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5421645641326904\n",
      "Epoch 14, Train Loss: 0.6948, Val Loss: 0.6977, Test Accuracy: 0.5164 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.542788028717041\n",
      "Epoch 15, Train Loss: 0.6933, Val Loss: 0.6960, Test Accuracy: 0.5216 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5378010272979736\n",
      "Epoch 16, Train Loss: 0.6987, Val Loss: 0.6954, Test Accuracy: 0.5256 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5390846729278564\n",
      "Epoch 17, Train Loss: 0.6965, Val Loss: 0.6960, Test Accuracy: 0.5256 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5381941795349121\n",
      "Epoch 18, Train Loss: 0.6942, Val Loss: 0.6947, Test Accuracy: 0.5308 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5388007164001465\n",
      "Epoch 19, Train Loss: 0.6943, Val Loss: 0.6956, Test Accuracy: 0.5242 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5375816822052002\n",
      "Epoch 20, Train Loss: 0.6925, Val Loss: 0.6963, Test Accuracy: 0.5203 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5427167415618896\n",
      "Epoch 21, Train Loss: 0.6930, Val Loss: 0.6959, Test Accuracy: 0.5177 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5421788692474365\n",
      "Epoch 22, Train Loss: 0.6938, Val Loss: 0.6958, Test Accuracy: 0.5242 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.542769193649292\n",
      "Epoch 23, Train Loss: 0.6887, Val Loss: 0.6958, Test Accuracy: 0.5203 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5428433418273926\n",
      "Epoch 24, Train Loss: 0.6923, Val Loss: 0.6950, Test Accuracy: 0.5269 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5415966510772705\n",
      "Epoch 25, Train Loss: 0.6894, Val Loss: 0.6942, Test Accuracy: 0.5203 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5436828136444092\n",
      "Epoch 26, Train Loss: 0.6899, Val Loss: 0.6953, Test Accuracy: 0.5216 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5410549640655518\n",
      "Epoch 27, Train Loss: 0.6898, Val Loss: 0.6953, Test Accuracy: 0.5203 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5417840480804443\n",
      "Epoch 28, Train Loss: 0.6883, Val Loss: 0.6954, Test Accuracy: 0.5190 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5398609638214111\n",
      "Epoch 29, Train Loss: 0.6905, Val Loss: 0.6953, Test Accuracy: 0.5164 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5432682037353516\n",
      "Epoch 30, Train Loss: 0.6888, Val Loss: 0.6953, Test Accuracy: 0.5216 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5427308082580566\n",
      "Epoch 31, Train Loss: 0.6906, Val Loss: 0.6954, Test Accuracy: 0.5177 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5438799858093262\n",
      "Epoch 32, Train Loss: 0.6864, Val Loss: 0.6953, Test Accuracy: 0.5164 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5347819328308105\n",
      "Epoch 33, Train Loss: 0.6895, Val Loss: 0.6937, Test Accuracy: 0.5151 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5287339687347412\n",
      "Epoch 34, Train Loss: 0.6863, Val Loss: 0.6955, Test Accuracy: 0.5177 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5409984588623047\n",
      "Epoch 35, Train Loss: 0.6846, Val Loss: 0.6957, Test Accuracy: 0.5177 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5460882186889648\n",
      "Epoch 36, Train Loss: 0.6864, Val Loss: 0.6958, Test Accuracy: 0.5138 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.539691686630249\n",
      "Epoch 37, Train Loss: 0.6857, Val Loss: 0.6955, Test Accuracy: 0.5085 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5443160533905029\n",
      "Epoch 38, Train Loss: 0.6851, Val Loss: 0.6953, Test Accuracy: 0.5190 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5426309108734131\n",
      "Epoch 39, Train Loss: 0.6885, Val Loss: 0.6946, Test Accuracy: 0.5177 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5417168140411377\n",
      "Epoch 40, Train Loss: 0.6867, Val Loss: 0.6951, Test Accuracy: 0.5151 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5407721996307373\n",
      "Epoch 41, Train Loss: 0.6874, Val Loss: 0.6952, Test Accuracy: 0.5177 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5425624847412109\n",
      "Epoch 42, Train Loss: 0.6849, Val Loss: 0.6951, Test Accuracy: 0.5151 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5409231185913086\n",
      "Epoch 43, Train Loss: 0.6839, Val Loss: 0.6955, Test Accuracy: 0.5125 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5430102348327637\n",
      "Epoch 44, Train Loss: 0.6846, Val Loss: 0.6962, Test Accuracy: 0.5072 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5444056987762451\n",
      "Epoch 45, Train Loss: 0.6833, Val Loss: 0.6972, Test Accuracy: 0.5033 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5495615005493164\n",
      "Epoch 46, Train Loss: 0.6835, Val Loss: 0.6961, Test Accuracy: 0.5046 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5442728996276855\n",
      "Epoch 47, Train Loss: 0.6808, Val Loss: 0.6960, Test Accuracy: 0.5085 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5441274642944336\n",
      "Epoch 48, Train Loss: 0.6808, Val Loss: 0.6977, Test Accuracy: 0.5020 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5405216217041016\n",
      "Epoch 49, Train Loss: 0.6827, Val Loss: 0.6971, Test Accuracy: 0.5033 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5403702259063721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:44:37,996] Trial 3 finished with value: 0.5583224115334207 and parameters: {'HIDDEN_DIMENSION': 125, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 64, 'DROP_OUT': 0.22447643284566254, 'LEARNING_RATE': 0.00012585476001500062}. Best is trial 3 with value: 0.5583224115334207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6805, Val Loss: 0.6957, Test Accuracy: 0.5072 ,Learning Rate: 0.00012585476001500062 , Time Taken : 0.5475625991821289\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 18, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.2330000996911964, 'LEARNING_RATE': 0.0005302628927086526}\n",
      "Epoch 1, Train Loss: 0.8274, Val Loss: 0.7708, Test Accuracy: 0.4928 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5281846523284912\n",
      "Epoch 2, Train Loss: 0.7640, Val Loss: 0.7300, Test Accuracy: 0.4993 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5351672172546387\n",
      "Epoch 3, Train Loss: 0.7280, Val Loss: 0.7170, Test Accuracy: 0.4928 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5357661247253418\n",
      "Epoch 4, Train Loss: 0.7158, Val Loss: 0.7074, Test Accuracy: 0.4967 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5393600463867188\n",
      "Epoch 5, Train Loss: 0.7068, Val Loss: 0.7008, Test Accuracy: 0.5007 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5321965217590332\n",
      "Epoch 6, Train Loss: 0.6955, Val Loss: 0.6991, Test Accuracy: 0.5111 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5403745174407959\n",
      "Epoch 7, Train Loss: 0.6975, Val Loss: 0.6958, Test Accuracy: 0.5151 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5399007797241211\n",
      "Epoch 8, Train Loss: 0.6970, Val Loss: 0.6976, Test Accuracy: 0.5033 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5341942310333252\n",
      "Epoch 9, Train Loss: 0.6932, Val Loss: 0.6963, Test Accuracy: 0.5033 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5210974216461182\n",
      "Epoch 10, Train Loss: 0.6908, Val Loss: 0.6977, Test Accuracy: 0.4928 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5353038311004639\n",
      "Epoch 11, Train Loss: 0.6925, Val Loss: 0.6977, Test Accuracy: 0.4928 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5370666980743408\n",
      "Epoch 12, Train Loss: 0.6847, Val Loss: 0.6980, Test Accuracy: 0.4993 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5335688591003418\n",
      "Epoch 13, Train Loss: 0.6866, Val Loss: 0.6938, Test Accuracy: 0.5229 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5407536029815674\n",
      "Epoch 14, Train Loss: 0.6868, Val Loss: 0.6962, Test Accuracy: 0.5151 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5333163738250732\n",
      "Epoch 15, Train Loss: 0.6864, Val Loss: 0.6964, Test Accuracy: 0.5085 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.533350944519043\n",
      "Epoch 16, Train Loss: 0.6861, Val Loss: 0.6957, Test Accuracy: 0.5164 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5329909324645996\n",
      "Epoch 17, Train Loss: 0.6838, Val Loss: 0.6941, Test Accuracy: 0.5203 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5353569984436035\n",
      "Epoch 18, Train Loss: 0.6848, Val Loss: 0.6953, Test Accuracy: 0.5151 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5348639488220215\n",
      "Epoch 19, Train Loss: 0.6796, Val Loss: 0.6979, Test Accuracy: 0.5125 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.530205488204956\n",
      "Epoch 20, Train Loss: 0.6811, Val Loss: 0.6964, Test Accuracy: 0.5190 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5308506488800049\n",
      "Epoch 21, Train Loss: 0.6825, Val Loss: 0.6959, Test Accuracy: 0.5203 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5316386222839355\n",
      "Epoch 22, Train Loss: 0.6792, Val Loss: 0.6971, Test Accuracy: 0.5138 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5345046520233154\n",
      "Epoch 23, Train Loss: 0.6792, Val Loss: 0.6982, Test Accuracy: 0.5164 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5374355316162109\n",
      "Epoch 24, Train Loss: 0.6760, Val Loss: 0.6993, Test Accuracy: 0.5190 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5375409126281738\n",
      "Epoch 25, Train Loss: 0.6762, Val Loss: 0.7016, Test Accuracy: 0.5229 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.535473108291626\n",
      "Epoch 26, Train Loss: 0.6740, Val Loss: 0.7014, Test Accuracy: 0.5360 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5393280982971191\n",
      "Epoch 27, Train Loss: 0.6721, Val Loss: 0.6998, Test Accuracy: 0.5334 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5366525650024414\n",
      "Epoch 28, Train Loss: 0.6734, Val Loss: 0.7037, Test Accuracy: 0.5269 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5400793552398682\n",
      "Epoch 29, Train Loss: 0.6747, Val Loss: 0.7043, Test Accuracy: 0.5203 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.531907320022583\n",
      "Epoch 30, Train Loss: 0.6715, Val Loss: 0.7068, Test Accuracy: 0.5111 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5119590759277344\n",
      "Epoch 31, Train Loss: 0.6708, Val Loss: 0.7056, Test Accuracy: 0.5269 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5325298309326172\n",
      "Epoch 32, Train Loss: 0.6688, Val Loss: 0.7108, Test Accuracy: 0.5151 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5389404296875\n",
      "Epoch 33, Train Loss: 0.6689, Val Loss: 0.7108, Test Accuracy: 0.5072 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5386850833892822\n",
      "Epoch 34, Train Loss: 0.6694, Val Loss: 0.7070, Test Accuracy: 0.5229 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5361475944519043\n",
      "Epoch 35, Train Loss: 0.6670, Val Loss: 0.7065, Test Accuracy: 0.5347 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5353329181671143\n",
      "Epoch 36, Train Loss: 0.6663, Val Loss: 0.7082, Test Accuracy: 0.5269 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5392837524414062\n",
      "Epoch 37, Train Loss: 0.6633, Val Loss: 0.7095, Test Accuracy: 0.5256 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5371837615966797\n",
      "Epoch 38, Train Loss: 0.6651, Val Loss: 0.7149, Test Accuracy: 0.5229 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5392811298370361\n",
      "Epoch 39, Train Loss: 0.6619, Val Loss: 0.7098, Test Accuracy: 0.5413 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5367686748504639\n",
      "Epoch 40, Train Loss: 0.6604, Val Loss: 0.7133, Test Accuracy: 0.5347 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5356044769287109\n",
      "Epoch 41, Train Loss: 0.6620, Val Loss: 0.7119, Test Accuracy: 0.5360 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5351443290710449\n",
      "Epoch 42, Train Loss: 0.6581, Val Loss: 0.7171, Test Accuracy: 0.5203 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5354547500610352\n",
      "Epoch 43, Train Loss: 0.6564, Val Loss: 0.7226, Test Accuracy: 0.5256 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5346176624298096\n",
      "Epoch 44, Train Loss: 0.6539, Val Loss: 0.7153, Test Accuracy: 0.5295 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5290064811706543\n",
      "Epoch 45, Train Loss: 0.6536, Val Loss: 0.7254, Test Accuracy: 0.5138 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5345633029937744\n",
      "Epoch 46, Train Loss: 0.6531, Val Loss: 0.7244, Test Accuracy: 0.5295 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5374019145965576\n",
      "Epoch 47, Train Loss: 0.6527, Val Loss: 0.7286, Test Accuracy: 0.5216 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5281901359558105\n",
      "Epoch 48, Train Loss: 0.6523, Val Loss: 0.7287, Test Accuracy: 0.5046 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5347862243652344\n",
      "Epoch 49, Train Loss: 0.6477, Val Loss: 0.7283, Test Accuracy: 0.5256 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5353519916534424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:45:04,776] Trial 4 finished with value: 0.5058977719528178 and parameters: {'HIDDEN_DIMENSION': 18, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 64, 'DROP_OUT': 0.2330000996911964, 'LEARNING_RATE': 0.0005302628927086526}. Best is trial 3 with value: 0.5583224115334207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6480, Val Loss: 0.7300, Test Accuracy: 0.5164 ,Learning Rate: 0.0005302628927086526 , Time Taken : 0.5379881858825684\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 66, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 1024, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.20906997535552097, 'LEARNING_RATE': 0.00019294355287868416}\n",
      "Epoch 1, Train Loss: 0.7832, Val Loss: 0.7882, Test Accuracy: 0.4430 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.7127399444580078\n",
      "Epoch 2, Train Loss: 0.7672, Val Loss: 0.7737, Test Accuracy: 0.4522 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5340754985809326\n",
      "Epoch 3, Train Loss: 0.7646, Val Loss: 0.7615, Test Accuracy: 0.4587 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5384979248046875\n",
      "Epoch 4, Train Loss: 0.7556, Val Loss: 0.7514, Test Accuracy: 0.4771 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5352022647857666\n",
      "Epoch 5, Train Loss: 0.7536, Val Loss: 0.7431, Test Accuracy: 0.4836 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5333657264709473\n",
      "Epoch 6, Train Loss: 0.7476, Val Loss: 0.7363, Test Accuracy: 0.4941 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5358457565307617\n",
      "Epoch 7, Train Loss: 0.7404, Val Loss: 0.7309, Test Accuracy: 0.4980 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5331645011901855\n",
      "Epoch 8, Train Loss: 0.7442, Val Loss: 0.7265, Test Accuracy: 0.5046 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5345945358276367\n",
      "Epoch 9, Train Loss: 0.7329, Val Loss: 0.7227, Test Accuracy: 0.5072 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.53399658203125\n",
      "Epoch 10, Train Loss: 0.7291, Val Loss: 0.7195, Test Accuracy: 0.5059 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5341176986694336\n",
      "Epoch 11, Train Loss: 0.7371, Val Loss: 0.7173, Test Accuracy: 0.5098 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5342154502868652\n",
      "Epoch 12, Train Loss: 0.7281, Val Loss: 0.7150, Test Accuracy: 0.5111 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5383565425872803\n",
      "Epoch 13, Train Loss: 0.7226, Val Loss: 0.7137, Test Accuracy: 0.5111 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.534778356552124\n",
      "Epoch 14, Train Loss: 0.7208, Val Loss: 0.7120, Test Accuracy: 0.5111 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5358860492706299\n",
      "Epoch 15, Train Loss: 0.7202, Val Loss: 0.7105, Test Accuracy: 0.5125 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5327243804931641\n",
      "Epoch 16, Train Loss: 0.7165, Val Loss: 0.7088, Test Accuracy: 0.5125 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5378198623657227\n",
      "Epoch 17, Train Loss: 0.7136, Val Loss: 0.7071, Test Accuracy: 0.5203 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.534600019454956\n",
      "Epoch 18, Train Loss: 0.7126, Val Loss: 0.7057, Test Accuracy: 0.5242 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5348014831542969\n",
      "Epoch 19, Train Loss: 0.7140, Val Loss: 0.7048, Test Accuracy: 0.5229 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5367801189422607\n",
      "Epoch 20, Train Loss: 0.7105, Val Loss: 0.7041, Test Accuracy: 0.5203 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5370998382568359\n",
      "Epoch 21, Train Loss: 0.7121, Val Loss: 0.7034, Test Accuracy: 0.5125 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5332846641540527\n",
      "Epoch 22, Train Loss: 0.7065, Val Loss: 0.7030, Test Accuracy: 0.5125 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5370209217071533\n",
      "Epoch 23, Train Loss: 0.7126, Val Loss: 0.7028, Test Accuracy: 0.5125 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.7106966972351074\n",
      "Epoch 24, Train Loss: 0.7096, Val Loss: 0.7021, Test Accuracy: 0.5125 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5344562530517578\n",
      "Epoch 25, Train Loss: 0.7109, Val Loss: 0.7015, Test Accuracy: 0.5138 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.535649299621582\n",
      "Epoch 26, Train Loss: 0.7046, Val Loss: 0.7011, Test Accuracy: 0.5190 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5360867977142334\n",
      "Epoch 27, Train Loss: 0.7090, Val Loss: 0.7003, Test Accuracy: 0.5203 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5333256721496582\n",
      "Epoch 28, Train Loss: 0.7013, Val Loss: 0.6995, Test Accuracy: 0.5229 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5352671146392822\n",
      "Epoch 29, Train Loss: 0.7039, Val Loss: 0.6990, Test Accuracy: 0.5269 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5373175144195557\n",
      "Epoch 30, Train Loss: 0.7045, Val Loss: 0.6982, Test Accuracy: 0.5269 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5361301898956299\n",
      "Epoch 31, Train Loss: 0.7024, Val Loss: 0.6976, Test Accuracy: 0.5282 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5334053039550781\n",
      "Epoch 32, Train Loss: 0.7036, Val Loss: 0.6965, Test Accuracy: 0.5295 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5328125953674316\n",
      "Epoch 33, Train Loss: 0.7020, Val Loss: 0.6960, Test Accuracy: 0.5308 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5382506847381592\n",
      "Epoch 34, Train Loss: 0.6987, Val Loss: 0.6954, Test Accuracy: 0.5295 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5331106185913086\n",
      "Epoch 35, Train Loss: 0.6988, Val Loss: 0.6948, Test Accuracy: 0.5282 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.536623477935791\n",
      "Epoch 36, Train Loss: 0.6991, Val Loss: 0.6944, Test Accuracy: 0.5308 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5343279838562012\n",
      "Epoch 37, Train Loss: 0.7041, Val Loss: 0.6946, Test Accuracy: 0.5308 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5377590656280518\n",
      "Epoch 38, Train Loss: 0.7003, Val Loss: 0.6949, Test Accuracy: 0.5282 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5353128910064697\n",
      "Epoch 39, Train Loss: 0.6988, Val Loss: 0.6948, Test Accuracy: 0.5321 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5336885452270508\n",
      "Epoch 40, Train Loss: 0.6984, Val Loss: 0.6948, Test Accuracy: 0.5347 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5388553142547607\n",
      "Epoch 41, Train Loss: 0.6969, Val Loss: 0.6947, Test Accuracy: 0.5321 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5360639095306396\n",
      "Epoch 42, Train Loss: 0.6960, Val Loss: 0.6942, Test Accuracy: 0.5282 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5347325801849365\n",
      "Epoch 43, Train Loss: 0.6953, Val Loss: 0.6936, Test Accuracy: 0.5321 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5397117137908936\n",
      "Epoch 44, Train Loss: 0.6982, Val Loss: 0.6929, Test Accuracy: 0.5374 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.538301944732666\n",
      "Epoch 45, Train Loss: 0.6963, Val Loss: 0.6927, Test Accuracy: 0.5360 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.7168107032775879\n",
      "Epoch 46, Train Loss: 0.6927, Val Loss: 0.6928, Test Accuracy: 0.5426 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5352671146392822\n",
      "Epoch 47, Train Loss: 0.6982, Val Loss: 0.6927, Test Accuracy: 0.5439 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5375649929046631\n",
      "Epoch 48, Train Loss: 0.6955, Val Loss: 0.6929, Test Accuracy: 0.5413 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5408194065093994\n",
      "Epoch 49, Train Loss: 0.6944, Val Loss: 0.6928, Test Accuracy: 0.5426 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5367648601531982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:45:32,149] Trial 5 finished with value: 0.5137614678899083 and parameters: {'HIDDEN_DIMENSION': 66, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 1024, 'DROP_OUT': 0.20906997535552097, 'LEARNING_RATE': 0.00019294355287868416}. Best is trial 3 with value: 0.5583224115334207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6950, Val Loss: 0.6929, Test Accuracy: 0.5374 ,Learning Rate: 0.00019294355287868416 , Time Taken : 0.5360779762268066\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 110, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 1024, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.4519083011343309, 'LEARNING_RATE': 6.898956767288799e-05}\n",
      "Epoch 1, Train Loss: 0.7881, Val Loss: 0.6898, Test Accuracy: 0.5767 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.039959192276001\n",
      "Epoch 2, Train Loss: 0.7823, Val Loss: 0.6905, Test Accuracy: 0.5754 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0421810150146484\n",
      "Epoch 3, Train Loss: 0.7669, Val Loss: 0.6913, Test Accuracy: 0.5714 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0432109832763672\n",
      "Epoch 4, Train Loss: 0.7637, Val Loss: 0.6921, Test Accuracy: 0.5623 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0404856204986572\n",
      "Epoch 5, Train Loss: 0.7649, Val Loss: 0.6922, Test Accuracy: 0.5636 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0458803176879883\n",
      "Epoch 6, Train Loss: 0.7612, Val Loss: 0.6921, Test Accuracy: 0.5609 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0433521270751953\n",
      "Epoch 7, Train Loss: 0.7540, Val Loss: 0.6915, Test Accuracy: 0.5609 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0296964645385742\n",
      "Epoch 8, Train Loss: 0.7418, Val Loss: 0.6910, Test Accuracy: 0.5609 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0442538261413574\n",
      "Epoch 9, Train Loss: 0.7486, Val Loss: 0.6911, Test Accuracy: 0.5609 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.042717456817627\n",
      "Epoch 10, Train Loss: 0.7453, Val Loss: 0.6907, Test Accuracy: 0.5596 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0413479804992676\n",
      "Epoch 11, Train Loss: 0.7384, Val Loss: 0.6898, Test Accuracy: 0.5570 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0416021347045898\n",
      "Epoch 12, Train Loss: 0.7401, Val Loss: 0.6886, Test Accuracy: 0.5583 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0436768531799316\n",
      "Epoch 13, Train Loss: 0.7385, Val Loss: 0.6880, Test Accuracy: 0.5609 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.039473295211792\n",
      "Epoch 14, Train Loss: 0.7349, Val Loss: 0.6881, Test Accuracy: 0.5583 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0464117527008057\n",
      "Epoch 15, Train Loss: 0.7390, Val Loss: 0.6889, Test Accuracy: 0.5531 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0421547889709473\n",
      "Epoch 16, Train Loss: 0.7348, Val Loss: 0.6889, Test Accuracy: 0.5478 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.041463851928711\n",
      "Epoch 17, Train Loss: 0.7244, Val Loss: 0.6886, Test Accuracy: 0.5452 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0431599617004395\n",
      "Epoch 18, Train Loss: 0.7282, Val Loss: 0.6880, Test Accuracy: 0.5465 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0419130325317383\n",
      "Epoch 19, Train Loss: 0.7262, Val Loss: 0.6881, Test Accuracy: 0.5491 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0459225177764893\n",
      "Epoch 20, Train Loss: 0.7212, Val Loss: 0.6883, Test Accuracy: 0.5465 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0435564517974854\n",
      "Epoch 21, Train Loss: 0.7209, Val Loss: 0.6883, Test Accuracy: 0.5465 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.2412676811218262\n",
      "Epoch 22, Train Loss: 0.7130, Val Loss: 0.6887, Test Accuracy: 0.5413 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0424320697784424\n",
      "Epoch 23, Train Loss: 0.7186, Val Loss: 0.6889, Test Accuracy: 0.5387 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0464625358581543\n",
      "Epoch 24, Train Loss: 0.7209, Val Loss: 0.6889, Test Accuracy: 0.5387 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0457632541656494\n",
      "Epoch 25, Train Loss: 0.7206, Val Loss: 0.6888, Test Accuracy: 0.5387 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0448508262634277\n",
      "Epoch 26, Train Loss: 0.7247, Val Loss: 0.6886, Test Accuracy: 0.5400 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0444293022155762\n",
      "Epoch 27, Train Loss: 0.7162, Val Loss: 0.6883, Test Accuracy: 0.5400 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.046483039855957\n",
      "Epoch 28, Train Loss: 0.7192, Val Loss: 0.6880, Test Accuracy: 0.5439 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0425450801849365\n",
      "Epoch 29, Train Loss: 0.7234, Val Loss: 0.6884, Test Accuracy: 0.5413 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0498051643371582\n",
      "Epoch 30, Train Loss: 0.7162, Val Loss: 0.6883, Test Accuracy: 0.5426 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0446178913116455\n",
      "Epoch 31, Train Loss: 0.7173, Val Loss: 0.6887, Test Accuracy: 0.5426 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0451099872589111\n",
      "Epoch 32, Train Loss: 0.7160, Val Loss: 0.6892, Test Accuracy: 0.5400 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0432369709014893\n",
      "Epoch 33, Train Loss: 0.7171, Val Loss: 0.6894, Test Accuracy: 0.5360 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0463356971740723\n",
      "Epoch 34, Train Loss: 0.7115, Val Loss: 0.6901, Test Accuracy: 0.5321 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0463683605194092\n",
      "Epoch 35, Train Loss: 0.7181, Val Loss: 0.6906, Test Accuracy: 0.5242 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0450501441955566\n",
      "Epoch 36, Train Loss: 0.7113, Val Loss: 0.6905, Test Accuracy: 0.5282 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0464863777160645\n",
      "Epoch 37, Train Loss: 0.7018, Val Loss: 0.6907, Test Accuracy: 0.5256 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0465867519378662\n",
      "Epoch 38, Train Loss: 0.7094, Val Loss: 0.6905, Test Accuracy: 0.5282 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0491366386413574\n",
      "Epoch 39, Train Loss: 0.7083, Val Loss: 0.6898, Test Accuracy: 0.5321 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0510056018829346\n",
      "Epoch 40, Train Loss: 0.7083, Val Loss: 0.6889, Test Accuracy: 0.5426 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0518360137939453\n",
      "Epoch 41, Train Loss: 0.7108, Val Loss: 0.6890, Test Accuracy: 0.5439 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0506885051727295\n",
      "Epoch 42, Train Loss: 0.7126, Val Loss: 0.6893, Test Accuracy: 0.5413 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0457720756530762\n",
      "Epoch 43, Train Loss: 0.7105, Val Loss: 0.6899, Test Accuracy: 0.5308 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0442097187042236\n",
      "Epoch 44, Train Loss: 0.7103, Val Loss: 0.6903, Test Accuracy: 0.5229 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.2192506790161133\n",
      "Epoch 45, Train Loss: 0.7078, Val Loss: 0.6906, Test Accuracy: 0.5242 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0467088222503662\n",
      "Epoch 46, Train Loss: 0.7072, Val Loss: 0.6906, Test Accuracy: 0.5190 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0496313571929932\n",
      "Epoch 47, Train Loss: 0.7049, Val Loss: 0.6906, Test Accuracy: 0.5203 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0475401878356934\n",
      "Epoch 48, Train Loss: 0.7066, Val Loss: 0.6902, Test Accuracy: 0.5216 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0554468631744385\n",
      "Epoch 49, Train Loss: 0.7061, Val Loss: 0.6898, Test Accuracy: 0.5256 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0479545593261719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:46:24,855] Trial 6 finished with value: 0.49148099606815204 and parameters: {'HIDDEN_DIMENSION': 110, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 1024, 'DROP_OUT': 0.4519083011343309, 'LEARNING_RATE': 6.898956767288799e-05}. Best is trial 3 with value: 0.5583224115334207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7032, Val Loss: 0.6897, Test Accuracy: 0.5269 ,Learning Rate: 6.898956767288799e-05 , Time Taken : 1.0469744205474854\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 52, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 1024, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.23152006931951072, 'LEARNING_RATE': 8.399480149738918e-05}\n",
      "Epoch 1, Train Loss: 0.7843, Val Loss: 0.7654, Test Accuracy: 0.5151 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7709457874298096\n",
      "Epoch 2, Train Loss: 0.7822, Val Loss: 0.7623, Test Accuracy: 0.5098 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7755084037780762\n",
      "Epoch 3, Train Loss: 0.7868, Val Loss: 0.7600, Test Accuracy: 0.5111 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7753057479858398\n",
      "Epoch 4, Train Loss: 0.7713, Val Loss: 0.7572, Test Accuracy: 0.5085 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7716095447540283\n",
      "Epoch 5, Train Loss: 0.7680, Val Loss: 0.7547, Test Accuracy: 0.5085 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.773101806640625\n",
      "Epoch 6, Train Loss: 0.7685, Val Loss: 0.7519, Test Accuracy: 0.5111 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7783486843109131\n",
      "Epoch 7, Train Loss: 0.7592, Val Loss: 0.7496, Test Accuracy: 0.5111 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7757563591003418\n",
      "Epoch 8, Train Loss: 0.7646, Val Loss: 0.7467, Test Accuracy: 0.5125 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7735068798065186\n",
      "Epoch 9, Train Loss: 0.7534, Val Loss: 0.7444, Test Accuracy: 0.5125 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7702925205230713\n",
      "Epoch 10, Train Loss: 0.7543, Val Loss: 0.7424, Test Accuracy: 0.5111 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7749941349029541\n",
      "Epoch 11, Train Loss: 0.7454, Val Loss: 0.7397, Test Accuracy: 0.5111 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7756621837615967\n",
      "Epoch 12, Train Loss: 0.7478, Val Loss: 0.7367, Test Accuracy: 0.5111 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7791526317596436\n",
      "Epoch 13, Train Loss: 0.7468, Val Loss: 0.7347, Test Accuracy: 0.5085 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7761495113372803\n",
      "Epoch 14, Train Loss: 0.7426, Val Loss: 0.7330, Test Accuracy: 0.5098 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7721536159515381\n",
      "Epoch 15, Train Loss: 0.7393, Val Loss: 0.7312, Test Accuracy: 0.5085 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7752547264099121\n",
      "Epoch 16, Train Loss: 0.7379, Val Loss: 0.7295, Test Accuracy: 0.5072 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.9527201652526855\n",
      "Epoch 17, Train Loss: 0.7352, Val Loss: 0.7280, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7785909175872803\n",
      "Epoch 18, Train Loss: 0.7404, Val Loss: 0.7265, Test Accuracy: 0.5059 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7761671543121338\n",
      "Epoch 19, Train Loss: 0.7347, Val Loss: 0.7252, Test Accuracy: 0.5020 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7746686935424805\n",
      "Epoch 20, Train Loss: 0.7326, Val Loss: 0.7239, Test Accuracy: 0.5059 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.772301435470581\n",
      "Epoch 21, Train Loss: 0.7303, Val Loss: 0.7224, Test Accuracy: 0.5059 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7710168361663818\n",
      "Epoch 22, Train Loss: 0.7334, Val Loss: 0.7211, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7726395130157471\n",
      "Epoch 23, Train Loss: 0.7351, Val Loss: 0.7199, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7756993770599365\n",
      "Epoch 24, Train Loss: 0.7343, Val Loss: 0.7185, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7752363681793213\n",
      "Epoch 25, Train Loss: 0.7255, Val Loss: 0.7175, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.771521806716919\n",
      "Epoch 26, Train Loss: 0.7236, Val Loss: 0.7166, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7749886512756348\n",
      "Epoch 27, Train Loss: 0.7257, Val Loss: 0.7157, Test Accuracy: 0.5059 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7767500877380371\n",
      "Epoch 28, Train Loss: 0.7183, Val Loss: 0.7146, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7838497161865234\n",
      "Epoch 29, Train Loss: 0.7248, Val Loss: 0.7142, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7821698188781738\n",
      "Epoch 30, Train Loss: 0.7200, Val Loss: 0.7136, Test Accuracy: 0.5059 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.77620530128479\n",
      "Epoch 31, Train Loss: 0.7146, Val Loss: 0.7127, Test Accuracy: 0.5072 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7754452228546143\n",
      "Epoch 32, Train Loss: 0.7128, Val Loss: 0.7121, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7751007080078125\n",
      "Epoch 33, Train Loss: 0.7190, Val Loss: 0.7111, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7721385955810547\n",
      "Epoch 34, Train Loss: 0.7161, Val Loss: 0.7099, Test Accuracy: 0.5059 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.779991626739502\n",
      "Epoch 35, Train Loss: 0.7188, Val Loss: 0.7091, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7784030437469482\n",
      "Epoch 36, Train Loss: 0.7223, Val Loss: 0.7083, Test Accuracy: 0.5020 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7733705043792725\n",
      "Epoch 37, Train Loss: 0.7144, Val Loss: 0.7077, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.775850772857666\n",
      "Epoch 38, Train Loss: 0.7132, Val Loss: 0.7070, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.9554798603057861\n",
      "Epoch 39, Train Loss: 0.7076, Val Loss: 0.7064, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7782902717590332\n",
      "Epoch 40, Train Loss: 0.7114, Val Loss: 0.7059, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7760326862335205\n",
      "Epoch 41, Train Loss: 0.7112, Val Loss: 0.7058, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7752532958984375\n",
      "Epoch 42, Train Loss: 0.7145, Val Loss: 0.7056, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7757787704467773\n",
      "Epoch 43, Train Loss: 0.7007, Val Loss: 0.7052, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7749152183532715\n",
      "Epoch 44, Train Loss: 0.7106, Val Loss: 0.7047, Test Accuracy: 0.5046 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7763643264770508\n",
      "Epoch 45, Train Loss: 0.7114, Val Loss: 0.7044, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7724230289459229\n",
      "Epoch 46, Train Loss: 0.7097, Val Loss: 0.7039, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7744870185852051\n",
      "Epoch 47, Train Loss: 0.7079, Val Loss: 0.7033, Test Accuracy: 0.5059 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7764663696289062\n",
      "Epoch 48, Train Loss: 0.7088, Val Loss: 0.7029, Test Accuracy: 0.5072 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7747509479522705\n",
      "Epoch 49, Train Loss: 0.7102, Val Loss: 0.7032, Test Accuracy: 0.5033 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7739505767822266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:47:04,047] Trial 7 finished with value: 0.5058977719528178 and parameters: {'HIDDEN_DIMENSION': 52, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 1024, 'DROP_OUT': 0.23152006931951072, 'LEARNING_RATE': 8.399480149738918e-05}. Best is trial 3 with value: 0.5583224115334207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7098, Val Loss: 0.7030, Test Accuracy: 0.5007 ,Learning Rate: 8.399480149738918e-05 , Time Taken : 0.7734057903289795\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 114, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.13977059386791366, 'LEARNING_RATE': 0.00010920926664585334}\n",
      "Epoch 1, Train Loss: 0.7345, Val Loss: 0.7146, Test Accuracy: 0.4967 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0656218528747559\n",
      "Epoch 2, Train Loss: 0.7211, Val Loss: 0.7183, Test Accuracy: 0.4705 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0690562725067139\n",
      "Epoch 3, Train Loss: 0.7166, Val Loss: 0.7173, Test Accuracy: 0.4705 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0668683052062988\n",
      "Epoch 4, Train Loss: 0.7126, Val Loss: 0.7090, Test Accuracy: 0.4744 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0635066032409668\n",
      "Epoch 5, Train Loss: 0.7096, Val Loss: 0.7047, Test Accuracy: 0.4810 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.065234661102295\n",
      "Epoch 6, Train Loss: 0.7084, Val Loss: 0.7016, Test Accuracy: 0.4836 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0640621185302734\n",
      "Epoch 7, Train Loss: 0.7064, Val Loss: 0.6989, Test Accuracy: 0.4928 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0647366046905518\n",
      "Epoch 8, Train Loss: 0.7042, Val Loss: 0.6989, Test Accuracy: 0.4797 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0650851726531982\n",
      "Epoch 9, Train Loss: 0.7015, Val Loss: 0.6964, Test Accuracy: 0.4941 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0668971538543701\n",
      "Epoch 10, Train Loss: 0.7029, Val Loss: 0.6957, Test Accuracy: 0.4889 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0665562152862549\n",
      "Epoch 11, Train Loss: 0.6992, Val Loss: 0.6959, Test Accuracy: 0.4915 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.068464756011963\n",
      "Epoch 12, Train Loss: 0.7004, Val Loss: 0.6949, Test Accuracy: 0.4915 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0640454292297363\n",
      "Epoch 13, Train Loss: 0.6992, Val Loss: 0.6947, Test Accuracy: 0.4928 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0665717124938965\n",
      "Epoch 14, Train Loss: 0.6997, Val Loss: 0.6944, Test Accuracy: 0.4902 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0679652690887451\n",
      "Epoch 15, Train Loss: 0.6959, Val Loss: 0.6934, Test Accuracy: 0.5020 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0664479732513428\n",
      "Epoch 16, Train Loss: 0.6983, Val Loss: 0.6932, Test Accuracy: 0.4954 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.069216012954712\n",
      "Epoch 17, Train Loss: 0.6971, Val Loss: 0.6937, Test Accuracy: 0.4993 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0658833980560303\n",
      "Epoch 18, Train Loss: 0.6962, Val Loss: 0.6926, Test Accuracy: 0.5125 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0776903629302979\n",
      "Epoch 19, Train Loss: 0.6946, Val Loss: 0.6920, Test Accuracy: 0.5216 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0658955574035645\n",
      "Epoch 20, Train Loss: 0.6947, Val Loss: 0.6929, Test Accuracy: 0.5138 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.2410202026367188\n",
      "Epoch 21, Train Loss: 0.6962, Val Loss: 0.6920, Test Accuracy: 0.5256 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0702402591705322\n",
      "Epoch 22, Train Loss: 0.6953, Val Loss: 0.6917, Test Accuracy: 0.5282 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0672235488891602\n",
      "Epoch 23, Train Loss: 0.6955, Val Loss: 0.6921, Test Accuracy: 0.5190 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0663092136383057\n",
      "Epoch 24, Train Loss: 0.6945, Val Loss: 0.6921, Test Accuracy: 0.5203 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0709624290466309\n",
      "Epoch 25, Train Loss: 0.6947, Val Loss: 0.6917, Test Accuracy: 0.5256 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0695600509643555\n",
      "Epoch 26, Train Loss: 0.6939, Val Loss: 0.6912, Test Accuracy: 0.5308 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.066819190979004\n",
      "Epoch 27, Train Loss: 0.6947, Val Loss: 0.6915, Test Accuracy: 0.5295 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0660946369171143\n",
      "Epoch 28, Train Loss: 0.6945, Val Loss: 0.6915, Test Accuracy: 0.5321 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0696799755096436\n",
      "Epoch 29, Train Loss: 0.6919, Val Loss: 0.6920, Test Accuracy: 0.5308 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0654480457305908\n",
      "Epoch 30, Train Loss: 0.6920, Val Loss: 0.6905, Test Accuracy: 0.5360 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0653936862945557\n",
      "Epoch 31, Train Loss: 0.6930, Val Loss: 0.6914, Test Accuracy: 0.5308 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0665688514709473\n",
      "Epoch 32, Train Loss: 0.6946, Val Loss: 0.6895, Test Accuracy: 0.5347 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.067875862121582\n",
      "Epoch 33, Train Loss: 0.6938, Val Loss: 0.6909, Test Accuracy: 0.5308 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0666580200195312\n",
      "Epoch 34, Train Loss: 0.6904, Val Loss: 0.6918, Test Accuracy: 0.5308 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0671935081481934\n",
      "Epoch 35, Train Loss: 0.6907, Val Loss: 0.6910, Test Accuracy: 0.5321 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0683796405792236\n",
      "Epoch 36, Train Loss: 0.6929, Val Loss: 0.6906, Test Accuracy: 0.5334 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0665807723999023\n",
      "Epoch 37, Train Loss: 0.6918, Val Loss: 0.6892, Test Accuracy: 0.5308 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0663039684295654\n",
      "Epoch 38, Train Loss: 0.6907, Val Loss: 0.6897, Test Accuracy: 0.5334 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.068160057067871\n",
      "Epoch 39, Train Loss: 0.6906, Val Loss: 0.6904, Test Accuracy: 0.5360 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0673713684082031\n",
      "Epoch 40, Train Loss: 0.6911, Val Loss: 0.6912, Test Accuracy: 0.5334 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.066849946975708\n",
      "Epoch 41, Train Loss: 0.6926, Val Loss: 0.6900, Test Accuracy: 0.5308 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0684738159179688\n",
      "Epoch 42, Train Loss: 0.6924, Val Loss: 0.6897, Test Accuracy: 0.5347 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0667965412139893\n",
      "Epoch 43, Train Loss: 0.6906, Val Loss: 0.6902, Test Accuracy: 0.5295 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0679004192352295\n",
      "Epoch 44, Train Loss: 0.6900, Val Loss: 0.6894, Test Accuracy: 0.5400 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.066328763961792\n",
      "Epoch 45, Train Loss: 0.6917, Val Loss: 0.6895, Test Accuracy: 0.5413 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0676403045654297\n",
      "Epoch 46, Train Loss: 0.6902, Val Loss: 0.6899, Test Accuracy: 0.5321 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0673813819885254\n",
      "Epoch 47, Train Loss: 0.6900, Val Loss: 0.6905, Test Accuracy: 0.5321 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.08125901222229\n",
      "Epoch 48, Train Loss: 0.6906, Val Loss: 0.6893, Test Accuracy: 0.5478 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0766170024871826\n",
      "Epoch 49, Train Loss: 0.6902, Val Loss: 0.6898, Test Accuracy: 0.5360 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.082071304321289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:47:57,717] Trial 8 finished with value: 0.5570117955439057 and parameters: {'HIDDEN_DIMENSION': 114, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.13977059386791366, 'LEARNING_RATE': 0.00010920926664585334}. Best is trial 3 with value: 0.5583224115334207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6891, Val Loss: 0.6897, Test Accuracy: 0.5387 ,Learning Rate: 0.00010920926664585334 , Time Taken : 1.0748093128204346\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 73, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 1024, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.4897903535307605, 'LEARNING_RATE': 0.00025519086999254597}\n",
      "Epoch 1, Train Loss: 0.9605, Val Loss: 0.7870, Test Accuracy: 0.5177 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5433971881866455\n",
      "Epoch 2, Train Loss: 0.9334, Val Loss: 0.7758, Test Accuracy: 0.5138 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5422558784484863\n",
      "Epoch 3, Train Loss: 0.9310, Val Loss: 0.7654, Test Accuracy: 0.5151 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5435795783996582\n",
      "Epoch 4, Train Loss: 0.8945, Val Loss: 0.7550, Test Accuracy: 0.5151 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5405950546264648\n",
      "Epoch 5, Train Loss: 0.8775, Val Loss: 0.7476, Test Accuracy: 0.5164 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5417835712432861\n",
      "Epoch 6, Train Loss: 0.8718, Val Loss: 0.7420, Test Accuracy: 0.5138 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5563547611236572\n",
      "Epoch 7, Train Loss: 0.8495, Val Loss: 0.7374, Test Accuracy: 0.5098 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5408008098602295\n",
      "Epoch 8, Train Loss: 0.8497, Val Loss: 0.7331, Test Accuracy: 0.5138 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5411553382873535\n",
      "Epoch 9, Train Loss: 0.8447, Val Loss: 0.7300, Test Accuracy: 0.5111 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5452263355255127\n",
      "Epoch 10, Train Loss: 0.8248, Val Loss: 0.7253, Test Accuracy: 0.5098 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5435340404510498\n",
      "Epoch 11, Train Loss: 0.8119, Val Loss: 0.7210, Test Accuracy: 0.5164 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5419838428497314\n",
      "Epoch 12, Train Loss: 0.8244, Val Loss: 0.7156, Test Accuracy: 0.5256 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5494842529296875\n",
      "Epoch 13, Train Loss: 0.8093, Val Loss: 0.7105, Test Accuracy: 0.5269 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5400445461273193\n",
      "Epoch 14, Train Loss: 0.8077, Val Loss: 0.7074, Test Accuracy: 0.5269 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5411877632141113\n",
      "Epoch 15, Train Loss: 0.7924, Val Loss: 0.7059, Test Accuracy: 0.5216 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5409896373748779\n",
      "Epoch 16, Train Loss: 0.7795, Val Loss: 0.7046, Test Accuracy: 0.5203 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5402481555938721\n",
      "Epoch 17, Train Loss: 0.7930, Val Loss: 0.7048, Test Accuracy: 0.5151 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5399630069732666\n",
      "Epoch 18, Train Loss: 0.7771, Val Loss: 0.7055, Test Accuracy: 0.5138 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5428266525268555\n",
      "Epoch 19, Train Loss: 0.7638, Val Loss: 0.7054, Test Accuracy: 0.5111 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5439097881317139\n",
      "Epoch 20, Train Loss: 0.7683, Val Loss: 0.7038, Test Accuracy: 0.5098 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5438222885131836\n",
      "Epoch 21, Train Loss: 0.7585, Val Loss: 0.7021, Test Accuracy: 0.5125 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5417735576629639\n",
      "Epoch 22, Train Loss: 0.7515, Val Loss: 0.7003, Test Accuracy: 0.5138 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5432858467102051\n",
      "Epoch 23, Train Loss: 0.7644, Val Loss: 0.7000, Test Accuracy: 0.5098 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5416054725646973\n",
      "Epoch 24, Train Loss: 0.7569, Val Loss: 0.6990, Test Accuracy: 0.5125 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5441291332244873\n",
      "Epoch 25, Train Loss: 0.7510, Val Loss: 0.6975, Test Accuracy: 0.5151 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.7429409027099609\n",
      "Epoch 26, Train Loss: 0.7341, Val Loss: 0.6975, Test Accuracy: 0.5190 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5456206798553467\n",
      "Epoch 27, Train Loss: 0.7314, Val Loss: 0.6970, Test Accuracy: 0.5164 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5432109832763672\n",
      "Epoch 28, Train Loss: 0.7440, Val Loss: 0.6962, Test Accuracy: 0.5164 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5410134792327881\n",
      "Epoch 29, Train Loss: 0.7366, Val Loss: 0.6956, Test Accuracy: 0.5216 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.541607141494751\n",
      "Epoch 30, Train Loss: 0.7308, Val Loss: 0.6955, Test Accuracy: 0.5203 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5441937446594238\n",
      "Epoch 31, Train Loss: 0.7362, Val Loss: 0.6955, Test Accuracy: 0.5229 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5433175563812256\n",
      "Epoch 32, Train Loss: 0.7218, Val Loss: 0.6956, Test Accuracy: 0.5229 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5445704460144043\n",
      "Epoch 33, Train Loss: 0.7303, Val Loss: 0.6957, Test Accuracy: 0.5216 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5472345352172852\n",
      "Epoch 34, Train Loss: 0.7195, Val Loss: 0.6955, Test Accuracy: 0.5203 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5400960445404053\n",
      "Epoch 35, Train Loss: 0.7213, Val Loss: 0.6951, Test Accuracy: 0.5164 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5426361560821533\n",
      "Epoch 36, Train Loss: 0.7191, Val Loss: 0.6945, Test Accuracy: 0.5151 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5426931381225586\n",
      "Epoch 37, Train Loss: 0.7232, Val Loss: 0.6937, Test Accuracy: 0.5177 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5411546230316162\n",
      "Epoch 38, Train Loss: 0.7225, Val Loss: 0.6928, Test Accuracy: 0.5229 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5461969375610352\n",
      "Epoch 39, Train Loss: 0.7191, Val Loss: 0.6919, Test Accuracy: 0.5308 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5423903465270996\n",
      "Epoch 40, Train Loss: 0.7131, Val Loss: 0.6924, Test Accuracy: 0.5321 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5458111763000488\n",
      "Epoch 41, Train Loss: 0.7199, Val Loss: 0.6929, Test Accuracy: 0.5229 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5402634143829346\n",
      "Epoch 42, Train Loss: 0.7075, Val Loss: 0.6937, Test Accuracy: 0.5203 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5421292781829834\n",
      "Epoch 43, Train Loss: 0.7101, Val Loss: 0.6940, Test Accuracy: 0.5177 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5413789749145508\n",
      "Epoch 44, Train Loss: 0.7159, Val Loss: 0.6948, Test Accuracy: 0.5085 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.542189359664917\n",
      "Epoch 45, Train Loss: 0.7081, Val Loss: 0.6944, Test Accuracy: 0.5111 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5444858074188232\n",
      "Epoch 46, Train Loss: 0.7130, Val Loss: 0.6937, Test Accuracy: 0.5125 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5440878868103027\n",
      "Epoch 47, Train Loss: 0.7038, Val Loss: 0.6932, Test Accuracy: 0.5203 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5437862873077393\n",
      "Epoch 48, Train Loss: 0.7074, Val Loss: 0.6923, Test Accuracy: 0.5164 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5432686805725098\n",
      "Epoch 49, Train Loss: 0.7067, Val Loss: 0.6927, Test Accuracy: 0.5138 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5435507297515869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:48:25,135] Trial 9 finished with value: 0.4941022280471822 and parameters: {'HIDDEN_DIMENSION': 73, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 1024, 'DROP_OUT': 0.4897903535307605, 'LEARNING_RATE': 0.00025519086999254597}. Best is trial 3 with value: 0.5583224115334207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7105, Val Loss: 0.6924, Test Accuracy: 0.5098 ,Learning Rate: 0.00025519086999254597 , Time Taken : 0.5486302375793457\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 30, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.3282299474281164, 'LEARNING_RATE': 1.2252191924359754e-05}\n",
      "Epoch 1, Train Loss: 0.7960, Val Loss: 0.7675, Test Accuracy: 0.4823 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.537384033203125\n",
      "Epoch 2, Train Loss: 0.8040, Val Loss: 0.7658, Test Accuracy: 0.4823 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5470952987670898\n",
      "Epoch 3, Train Loss: 0.7960, Val Loss: 0.7641, Test Accuracy: 0.4836 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5502488613128662\n",
      "Epoch 4, Train Loss: 0.8014, Val Loss: 0.7624, Test Accuracy: 0.4823 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5510714054107666\n",
      "Epoch 5, Train Loss: 0.7924, Val Loss: 0.7609, Test Accuracy: 0.4823 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5431196689605713\n",
      "Epoch 6, Train Loss: 0.7892, Val Loss: 0.7593, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5437707901000977\n",
      "Epoch 7, Train Loss: 0.7893, Val Loss: 0.7580, Test Accuracy: 0.4810 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5487513542175293\n",
      "Epoch 8, Train Loss: 0.7922, Val Loss: 0.7564, Test Accuracy: 0.4810 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5432608127593994\n",
      "Epoch 9, Train Loss: 0.7845, Val Loss: 0.7550, Test Accuracy: 0.4810 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5490455627441406\n",
      "Epoch 10, Train Loss: 0.7876, Val Loss: 0.7535, Test Accuracy: 0.4810 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5515091419219971\n",
      "Epoch 11, Train Loss: 0.7888, Val Loss: 0.7520, Test Accuracy: 0.4823 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5490143299102783\n",
      "Epoch 12, Train Loss: 0.7852, Val Loss: 0.7507, Test Accuracy: 0.4836 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5506777763366699\n",
      "Epoch 13, Train Loss: 0.7726, Val Loss: 0.7495, Test Accuracy: 0.4836 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5496060848236084\n",
      "Epoch 14, Train Loss: 0.7848, Val Loss: 0.7482, Test Accuracy: 0.4823 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5495226383209229\n",
      "Epoch 15, Train Loss: 0.7710, Val Loss: 0.7472, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5485563278198242\n",
      "Epoch 16, Train Loss: 0.7778, Val Loss: 0.7460, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.544703483581543\n",
      "Epoch 17, Train Loss: 0.7726, Val Loss: 0.7450, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5513381958007812\n",
      "Epoch 18, Train Loss: 0.7748, Val Loss: 0.7439, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5519556999206543\n",
      "Epoch 19, Train Loss: 0.7790, Val Loss: 0.7428, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5513646602630615\n",
      "Epoch 20, Train Loss: 0.7717, Val Loss: 0.7417, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5520780086517334\n",
      "Epoch 21, Train Loss: 0.7714, Val Loss: 0.7407, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5528059005737305\n",
      "Epoch 22, Train Loss: 0.7703, Val Loss: 0.7395, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5495407581329346\n",
      "Epoch 23, Train Loss: 0.7605, Val Loss: 0.7386, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5530734062194824\n",
      "Epoch 24, Train Loss: 0.7652, Val Loss: 0.7377, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5471603870391846\n",
      "Epoch 25, Train Loss: 0.7660, Val Loss: 0.7368, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5468907356262207\n",
      "Epoch 26, Train Loss: 0.7609, Val Loss: 0.7359, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5473957061767578\n",
      "Epoch 27, Train Loss: 0.7649, Val Loss: 0.7351, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5492715835571289\n",
      "Epoch 28, Train Loss: 0.7637, Val Loss: 0.7341, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5455121994018555\n",
      "Epoch 29, Train Loss: 0.7644, Val Loss: 0.7332, Test Accuracy: 0.4810 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.552473783493042\n",
      "Epoch 30, Train Loss: 0.7629, Val Loss: 0.7323, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5504601001739502\n",
      "Epoch 31, Train Loss: 0.7591, Val Loss: 0.7315, Test Accuracy: 0.4771 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5504412651062012\n",
      "Epoch 32, Train Loss: 0.7539, Val Loss: 0.7308, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5463833808898926\n",
      "Epoch 33, Train Loss: 0.7673, Val Loss: 0.7300, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5480220317840576\n",
      "Epoch 34, Train Loss: 0.7558, Val Loss: 0.7292, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5486252307891846\n",
      "Epoch 35, Train Loss: 0.7531, Val Loss: 0.7286, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5486860275268555\n",
      "Epoch 36, Train Loss: 0.7556, Val Loss: 0.7278, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5468103885650635\n",
      "Epoch 37, Train Loss: 0.7518, Val Loss: 0.7271, Test Accuracy: 0.4797 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5481016635894775\n",
      "Epoch 38, Train Loss: 0.7510, Val Loss: 0.7263, Test Accuracy: 0.4784 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5468025207519531\n",
      "Epoch 39, Train Loss: 0.7520, Val Loss: 0.7255, Test Accuracy: 0.4758 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5524444580078125\n",
      "Epoch 40, Train Loss: 0.7496, Val Loss: 0.7248, Test Accuracy: 0.4758 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5514328479766846\n",
      "Epoch 41, Train Loss: 0.7495, Val Loss: 0.7240, Test Accuracy: 0.4758 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5456607341766357\n",
      "Epoch 42, Train Loss: 0.7532, Val Loss: 0.7236, Test Accuracy: 0.4758 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5490615367889404\n",
      "Epoch 43, Train Loss: 0.7416, Val Loss: 0.7228, Test Accuracy: 0.4758 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5469353199005127\n",
      "Epoch 44, Train Loss: 0.7367, Val Loss: 0.7221, Test Accuracy: 0.4758 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.549030065536499\n",
      "Epoch 45, Train Loss: 0.7442, Val Loss: 0.7216, Test Accuracy: 0.4744 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5487933158874512\n",
      "Epoch 46, Train Loss: 0.7433, Val Loss: 0.7210, Test Accuracy: 0.4744 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5499682426452637\n",
      "Epoch 47, Train Loss: 0.7450, Val Loss: 0.7204, Test Accuracy: 0.4744 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5457444190979004\n",
      "Epoch 48, Train Loss: 0.7462, Val Loss: 0.7199, Test Accuracy: 0.4744 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5461990833282471\n",
      "Epoch 49, Train Loss: 0.7447, Val Loss: 0.7194, Test Accuracy: 0.4744 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5509963035583496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:48:52,640] Trial 10 finished with value: 0.47182175622542594 and parameters: {'HIDDEN_DIMENSION': 30, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 64, 'DROP_OUT': 0.3282299474281164, 'LEARNING_RATE': 1.2252191924359754e-05}. Best is trial 3 with value: 0.5583224115334207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7406, Val Loss: 0.7188, Test Accuracy: 0.4744 ,Learning Rate: 1.2252191924359754e-05 , Time Taken : 0.5467631816864014\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 126, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.12993644704680013, 'LEARNING_RATE': 0.00015607305727562257}\n",
      "Epoch 1, Train Loss: 0.7708, Val Loss: 0.7445, Test Accuracy: 0.4849 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8176407814025879\n",
      "Epoch 2, Train Loss: 0.7453, Val Loss: 0.7337, Test Accuracy: 0.4875 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8199117183685303\n",
      "Epoch 3, Train Loss: 0.7278, Val Loss: 0.7198, Test Accuracy: 0.4954 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8263728618621826\n",
      "Epoch 4, Train Loss: 0.7195, Val Loss: 0.7106, Test Accuracy: 0.5098 ,Learning Rate: 0.00015607305727562257 , Time Taken : 1.0050437450408936\n",
      "Epoch 5, Train Loss: 0.7132, Val Loss: 0.7039, Test Accuracy: 0.5125 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8246994018554688\n",
      "Epoch 6, Train Loss: 0.7056, Val Loss: 0.7022, Test Accuracy: 0.5203 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8245270252227783\n",
      "Epoch 7, Train Loss: 0.7045, Val Loss: 0.6995, Test Accuracy: 0.5177 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8197293281555176\n",
      "Epoch 8, Train Loss: 0.7043, Val Loss: 0.6988, Test Accuracy: 0.5242 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8194675445556641\n",
      "Epoch 9, Train Loss: 0.7010, Val Loss: 0.6947, Test Accuracy: 0.5216 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8180897235870361\n",
      "Epoch 10, Train Loss: 0.6974, Val Loss: 0.6923, Test Accuracy: 0.5269 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8217430114746094\n",
      "Epoch 11, Train Loss: 0.6995, Val Loss: 0.6949, Test Accuracy: 0.5203 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.817202091217041\n",
      "Epoch 12, Train Loss: 0.6982, Val Loss: 0.6941, Test Accuracy: 0.5190 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8218955993652344\n",
      "Epoch 13, Train Loss: 0.6962, Val Loss: 0.6922, Test Accuracy: 0.5203 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.818662166595459\n",
      "Epoch 14, Train Loss: 0.6965, Val Loss: 0.6930, Test Accuracy: 0.5138 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8213765621185303\n",
      "Epoch 15, Train Loss: 0.6930, Val Loss: 0.6948, Test Accuracy: 0.5125 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8250048160552979\n",
      "Epoch 16, Train Loss: 0.6969, Val Loss: 0.6917, Test Accuracy: 0.5177 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8242952823638916\n",
      "Epoch 17, Train Loss: 0.6952, Val Loss: 0.6927, Test Accuracy: 0.5072 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8250045776367188\n",
      "Epoch 18, Train Loss: 0.6943, Val Loss: 0.6928, Test Accuracy: 0.5111 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8243203163146973\n",
      "Epoch 19, Train Loss: 0.6948, Val Loss: 0.6941, Test Accuracy: 0.5085 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.821897029876709\n",
      "Epoch 20, Train Loss: 0.6911, Val Loss: 0.6923, Test Accuracy: 0.5125 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8213019371032715\n",
      "Epoch 21, Train Loss: 0.6924, Val Loss: 0.6925, Test Accuracy: 0.5125 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8160190582275391\n",
      "Epoch 22, Train Loss: 0.6937, Val Loss: 0.6912, Test Accuracy: 0.5269 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8282344341278076\n",
      "Epoch 23, Train Loss: 0.6934, Val Loss: 0.6915, Test Accuracy: 0.5282 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8211991786956787\n",
      "Epoch 24, Train Loss: 0.6924, Val Loss: 0.6926, Test Accuracy: 0.5256 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8231279850006104\n",
      "Epoch 25, Train Loss: 0.6918, Val Loss: 0.6924, Test Accuracy: 0.5321 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8247954845428467\n",
      "Epoch 26, Train Loss: 0.6909, Val Loss: 0.6924, Test Accuracy: 0.5334 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8216578960418701\n",
      "Epoch 27, Train Loss: 0.6925, Val Loss: 0.6928, Test Accuracy: 0.5229 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8205361366271973\n",
      "Epoch 28, Train Loss: 0.6925, Val Loss: 0.6919, Test Accuracy: 0.5216 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8296666145324707\n",
      "Epoch 29, Train Loss: 0.6897, Val Loss: 0.6904, Test Accuracy: 0.5347 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8182406425476074\n",
      "Epoch 30, Train Loss: 0.6905, Val Loss: 0.6919, Test Accuracy: 0.5282 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8188085556030273\n",
      "Epoch 31, Train Loss: 0.6882, Val Loss: 0.6910, Test Accuracy: 0.5374 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8194503784179688\n",
      "Epoch 32, Train Loss: 0.6900, Val Loss: 0.6922, Test Accuracy: 0.5282 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8196568489074707\n",
      "Epoch 33, Train Loss: 0.6864, Val Loss: 0.6930, Test Accuracy: 0.5269 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8178746700286865\n",
      "Epoch 34, Train Loss: 0.6858, Val Loss: 0.6926, Test Accuracy: 0.5374 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.826779842376709\n",
      "Epoch 35, Train Loss: 0.6890, Val Loss: 0.6929, Test Accuracy: 0.5347 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8162643909454346\n",
      "Epoch 36, Train Loss: 0.6884, Val Loss: 0.6924, Test Accuracy: 0.5360 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8184523582458496\n",
      "Epoch 37, Train Loss: 0.6892, Val Loss: 0.6933, Test Accuracy: 0.5347 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8189427852630615\n",
      "Epoch 38, Train Loss: 0.6907, Val Loss: 0.6948, Test Accuracy: 0.5282 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8187711238861084\n",
      "Epoch 39, Train Loss: 0.6889, Val Loss: 0.6917, Test Accuracy: 0.5400 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8194048404693604\n",
      "Epoch 40, Train Loss: 0.6861, Val Loss: 0.6906, Test Accuracy: 0.5491 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8211531639099121\n",
      "Epoch 41, Train Loss: 0.6863, Val Loss: 0.6944, Test Accuracy: 0.5413 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8192107677459717\n",
      "Epoch 42, Train Loss: 0.6848, Val Loss: 0.6952, Test Accuracy: 0.5360 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8178987503051758\n",
      "Epoch 43, Train Loss: 0.6870, Val Loss: 0.6923, Test Accuracy: 0.5491 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8212738037109375\n",
      "Epoch 44, Train Loss: 0.6868, Val Loss: 0.6926, Test Accuracy: 0.5531 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8307151794433594\n",
      "Epoch 45, Train Loss: 0.6875, Val Loss: 0.6941, Test Accuracy: 0.5413 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8205196857452393\n",
      "Epoch 46, Train Loss: 0.6856, Val Loss: 0.6944, Test Accuracy: 0.5439 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.818596363067627\n",
      "Epoch 47, Train Loss: 0.6880, Val Loss: 0.6957, Test Accuracy: 0.5439 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.818936824798584\n",
      "Epoch 48, Train Loss: 0.6824, Val Loss: 0.6935, Test Accuracy: 0.5452 ,Learning Rate: 0.00015607305727562257 , Time Taken : 1.0179574489593506\n",
      "Epoch 49, Train Loss: 0.6840, Val Loss: 0.6939, Test Accuracy: 0.5439 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8256688117980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:49:34,190] Trial 11 finished with value: 0.5674967234600262 and parameters: {'HIDDEN_DIMENSION': 126, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'DROP_OUT': 0.12993644704680013, 'LEARNING_RATE': 0.00015607305727562257}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6871, Val Loss: 0.6954, Test Accuracy: 0.5518 ,Learning Rate: 0.00015607305727562257 , Time Taken : 0.8163998126983643\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 127, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.10270723107018082, 'LEARNING_RATE': 0.00018388492519697043}\n",
      "Epoch 1, Train Loss: 0.7387, Val Loss: 0.7065, Test Accuracy: 0.5033 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1640963554382324\n",
      "Epoch 2, Train Loss: 0.6987, Val Loss: 0.7071, Test Accuracy: 0.4705 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1728851795196533\n",
      "Epoch 3, Train Loss: 0.6943, Val Loss: 0.6924, Test Accuracy: 0.5295 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1660053730010986\n",
      "Epoch 4, Train Loss: 0.6919, Val Loss: 0.6947, Test Accuracy: 0.5020 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1681716442108154\n",
      "Epoch 5, Train Loss: 0.6904, Val Loss: 0.6846, Test Accuracy: 0.5544 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1764776706695557\n",
      "Epoch 6, Train Loss: 0.6921, Val Loss: 0.6953, Test Accuracy: 0.5046 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1717236042022705\n",
      "Epoch 7, Train Loss: 0.6884, Val Loss: 0.6937, Test Accuracy: 0.5256 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.175072193145752\n",
      "Epoch 8, Train Loss: 0.6892, Val Loss: 0.6953, Test Accuracy: 0.5190 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.175276279449463\n",
      "Epoch 9, Train Loss: 0.6881, Val Loss: 0.6915, Test Accuracy: 0.5334 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.171889305114746\n",
      "Epoch 10, Train Loss: 0.6877, Val Loss: 0.6862, Test Accuracy: 0.5478 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.171476125717163\n",
      "Epoch 11, Train Loss: 0.6878, Val Loss: 0.6972, Test Accuracy: 0.5059 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1714003086090088\n",
      "Epoch 12, Train Loss: 0.6859, Val Loss: 0.6905, Test Accuracy: 0.5308 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.179375171661377\n",
      "Epoch 13, Train Loss: 0.6853, Val Loss: 0.6932, Test Accuracy: 0.5242 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.17116379737854\n",
      "Epoch 14, Train Loss: 0.6847, Val Loss: 0.6886, Test Accuracy: 0.5347 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.170220136642456\n",
      "Epoch 15, Train Loss: 0.6840, Val Loss: 0.6954, Test Accuracy: 0.5151 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1745502948760986\n",
      "Epoch 16, Train Loss: 0.6819, Val Loss: 0.6882, Test Accuracy: 0.5505 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1667120456695557\n",
      "Epoch 17, Train Loss: 0.6827, Val Loss: 0.6949, Test Accuracy: 0.5190 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1758325099945068\n",
      "Epoch 18, Train Loss: 0.6804, Val Loss: 0.6923, Test Accuracy: 0.5190 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.170114517211914\n",
      "Epoch 19, Train Loss: 0.6806, Val Loss: 0.6959, Test Accuracy: 0.5151 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1689908504486084\n",
      "Epoch 20, Train Loss: 0.6800, Val Loss: 0.6919, Test Accuracy: 0.5256 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1403307914733887\n",
      "Epoch 21, Train Loss: 0.6778, Val Loss: 0.6931, Test Accuracy: 0.5242 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1704959869384766\n",
      "Epoch 22, Train Loss: 0.6781, Val Loss: 0.7026, Test Accuracy: 0.4928 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.168105125427246\n",
      "Epoch 23, Train Loss: 0.6793, Val Loss: 0.6970, Test Accuracy: 0.5085 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1736230850219727\n",
      "Epoch 24, Train Loss: 0.6783, Val Loss: 0.6947, Test Accuracy: 0.5177 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.164757490158081\n",
      "Epoch 25, Train Loss: 0.6762, Val Loss: 0.7090, Test Accuracy: 0.4889 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1647930145263672\n",
      "Epoch 26, Train Loss: 0.6765, Val Loss: 0.6937, Test Accuracy: 0.5256 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1668972969055176\n",
      "Epoch 27, Train Loss: 0.6759, Val Loss: 0.6934, Test Accuracy: 0.5242 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1586954593658447\n",
      "Epoch 28, Train Loss: 0.6763, Val Loss: 0.6973, Test Accuracy: 0.5085 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.161649227142334\n",
      "Epoch 29, Train Loss: 0.6753, Val Loss: 0.7038, Test Accuracy: 0.4928 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1636712551116943\n",
      "Epoch 30, Train Loss: 0.6735, Val Loss: 0.7013, Test Accuracy: 0.4941 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1632628440856934\n",
      "Epoch 31, Train Loss: 0.6725, Val Loss: 0.7057, Test Accuracy: 0.4836 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1628828048706055\n",
      "Epoch 32, Train Loss: 0.6732, Val Loss: 0.7008, Test Accuracy: 0.5046 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.163766860961914\n",
      "Epoch 33, Train Loss: 0.6700, Val Loss: 0.6923, Test Accuracy: 0.5387 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1635282039642334\n",
      "Epoch 34, Train Loss: 0.6695, Val Loss: 0.7035, Test Accuracy: 0.4928 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1688520908355713\n",
      "Epoch 35, Train Loss: 0.6714, Val Loss: 0.7040, Test Accuracy: 0.4967 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.160135269165039\n",
      "Epoch 36, Train Loss: 0.6694, Val Loss: 0.7022, Test Accuracy: 0.5007 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.144239902496338\n",
      "Epoch 37, Train Loss: 0.6686, Val Loss: 0.7045, Test Accuracy: 0.4849 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1623578071594238\n",
      "Epoch 38, Train Loss: 0.6686, Val Loss: 0.6983, Test Accuracy: 0.5151 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1545932292938232\n",
      "Epoch 39, Train Loss: 0.6667, Val Loss: 0.7039, Test Accuracy: 0.5007 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.156815528869629\n",
      "Epoch 40, Train Loss: 0.6670, Val Loss: 0.6940, Test Accuracy: 0.5374 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.169076919555664\n",
      "Epoch 41, Train Loss: 0.6675, Val Loss: 0.7159, Test Accuracy: 0.4784 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1521475315093994\n",
      "Epoch 42, Train Loss: 0.6672, Val Loss: 0.7070, Test Accuracy: 0.4862 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1718649864196777\n",
      "Epoch 43, Train Loss: 0.6628, Val Loss: 0.6999, Test Accuracy: 0.5177 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1632561683654785\n",
      "Epoch 44, Train Loss: 0.6638, Val Loss: 0.7024, Test Accuracy: 0.5151 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1639366149902344\n",
      "Epoch 45, Train Loss: 0.6609, Val Loss: 0.7076, Test Accuracy: 0.5046 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1644721031188965\n",
      "Epoch 46, Train Loss: 0.6610, Val Loss: 0.7061, Test Accuracy: 0.5111 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.16292405128479\n",
      "Epoch 47, Train Loss: 0.6600, Val Loss: 0.7040, Test Accuracy: 0.5164 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1613380908966064\n",
      "Epoch 48, Train Loss: 0.6613, Val Loss: 0.7072, Test Accuracy: 0.5033 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1676039695739746\n",
      "Epoch 49, Train Loss: 0.6592, Val Loss: 0.7039, Test Accuracy: 0.5177 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1667194366455078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:50:32,604] Trial 12 finished with value: 0.5334207077326344 and parameters: {'HIDDEN_DIMENSION': 127, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.10270723107018082, 'LEARNING_RATE': 0.00018388492519697043}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6601, Val Loss: 0.7122, Test Accuracy: 0.5059 ,Learning Rate: 0.00018388492519697043 , Time Taken : 1.1638505458831787\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 94, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1907576697119489, 'LEARNING_RATE': 0.0003357891389023947}\n",
      "Epoch 1, Train Loss: 0.7303, Val Loss: 0.6928, Test Accuracy: 0.5151 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1710851192474365\n",
      "Epoch 2, Train Loss: 0.7060, Val Loss: 0.7013, Test Accuracy: 0.4758 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.159956455230713\n",
      "Epoch 3, Train Loss: 0.6996, Val Loss: 0.6919, Test Accuracy: 0.5085 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1569581031799316\n",
      "Epoch 4, Train Loss: 0.6955, Val Loss: 0.6995, Test Accuracy: 0.4456 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.158125638961792\n",
      "Epoch 5, Train Loss: 0.6953, Val Loss: 0.6944, Test Accuracy: 0.4771 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1617083549499512\n",
      "Epoch 6, Train Loss: 0.6923, Val Loss: 0.7024, Test Accuracy: 0.4548 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1633381843566895\n",
      "Epoch 7, Train Loss: 0.6917, Val Loss: 0.6909, Test Accuracy: 0.5229 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1598122119903564\n",
      "Epoch 8, Train Loss: 0.6875, Val Loss: 0.6878, Test Accuracy: 0.5334 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1570794582366943\n",
      "Epoch 9, Train Loss: 0.6869, Val Loss: 0.6972, Test Accuracy: 0.5033 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.167339563369751\n",
      "Epoch 10, Train Loss: 0.6864, Val Loss: 0.6951, Test Accuracy: 0.5085 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1603622436523438\n",
      "Epoch 11, Train Loss: 0.6822, Val Loss: 0.6953, Test Accuracy: 0.5138 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1532015800476074\n",
      "Epoch 12, Train Loss: 0.6844, Val Loss: 0.6964, Test Accuracy: 0.5111 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1491296291351318\n",
      "Epoch 13, Train Loss: 0.6844, Val Loss: 0.6897, Test Accuracy: 0.5269 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1611037254333496\n",
      "Epoch 14, Train Loss: 0.6813, Val Loss: 0.7003, Test Accuracy: 0.5046 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1598165035247803\n",
      "Epoch 15, Train Loss: 0.6760, Val Loss: 0.7003, Test Accuracy: 0.5164 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1653096675872803\n",
      "Epoch 16, Train Loss: 0.6792, Val Loss: 0.7022, Test Accuracy: 0.5033 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1604621410369873\n",
      "Epoch 17, Train Loss: 0.6792, Val Loss: 0.6984, Test Accuracy: 0.5164 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1583902835845947\n",
      "Epoch 18, Train Loss: 0.6766, Val Loss: 0.7021, Test Accuracy: 0.5072 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1618902683258057\n",
      "Epoch 19, Train Loss: 0.6758, Val Loss: 0.7137, Test Accuracy: 0.4849 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1594440937042236\n",
      "Epoch 20, Train Loss: 0.6739, Val Loss: 0.6960, Test Accuracy: 0.5256 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1636931896209717\n",
      "Epoch 21, Train Loss: 0.6738, Val Loss: 0.7022, Test Accuracy: 0.5295 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1216707229614258\n",
      "Epoch 22, Train Loss: 0.6712, Val Loss: 0.7011, Test Accuracy: 0.5229 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1187591552734375\n",
      "Epoch 23, Train Loss: 0.6720, Val Loss: 0.7050, Test Accuracy: 0.5151 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.102647066116333\n",
      "Epoch 24, Train Loss: 0.6720, Val Loss: 0.7026, Test Accuracy: 0.5138 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1083340644836426\n",
      "Epoch 25, Train Loss: 0.6707, Val Loss: 0.7036, Test Accuracy: 0.5164 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1087920665740967\n",
      "Epoch 26, Train Loss: 0.6707, Val Loss: 0.7025, Test Accuracy: 0.5203 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1103901863098145\n",
      "Epoch 27, Train Loss: 0.6701, Val Loss: 0.7107, Test Accuracy: 0.5020 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.102461338043213\n",
      "Epoch 28, Train Loss: 0.6681, Val Loss: 0.7059, Test Accuracy: 0.5242 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1104381084442139\n",
      "Epoch 29, Train Loss: 0.6688, Val Loss: 0.7070, Test Accuracy: 0.5085 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.148160457611084\n",
      "Epoch 30, Train Loss: 0.6684, Val Loss: 0.7129, Test Accuracy: 0.5177 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1739835739135742\n",
      "Epoch 31, Train Loss: 0.6666, Val Loss: 0.7135, Test Accuracy: 0.5007 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1904664039611816\n",
      "Epoch 32, Train Loss: 0.6649, Val Loss: 0.7023, Test Accuracy: 0.5282 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.153266429901123\n",
      "Epoch 33, Train Loss: 0.6645, Val Loss: 0.7128, Test Accuracy: 0.5046 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1391792297363281\n",
      "Epoch 34, Train Loss: 0.6634, Val Loss: 0.7121, Test Accuracy: 0.5046 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1466541290283203\n",
      "Epoch 35, Train Loss: 0.6625, Val Loss: 0.7178, Test Accuracy: 0.5020 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1461570262908936\n",
      "Epoch 36, Train Loss: 0.6604, Val Loss: 0.7079, Test Accuracy: 0.5216 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1513736248016357\n",
      "Epoch 37, Train Loss: 0.6636, Val Loss: 0.7149, Test Accuracy: 0.5046 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1636412143707275\n",
      "Epoch 38, Train Loss: 0.6601, Val Loss: 0.7136, Test Accuracy: 0.5020 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1529524326324463\n",
      "Epoch 39, Train Loss: 0.6613, Val Loss: 0.7155, Test Accuracy: 0.5111 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1456549167633057\n",
      "Epoch 40, Train Loss: 0.6592, Val Loss: 0.7176, Test Accuracy: 0.5164 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1436822414398193\n",
      "Epoch 41, Train Loss: 0.6565, Val Loss: 0.7285, Test Accuracy: 0.4902 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1475136280059814\n",
      "Epoch 42, Train Loss: 0.6573, Val Loss: 0.7230, Test Accuracy: 0.5177 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.153740406036377\n",
      "Epoch 43, Train Loss: 0.6572, Val Loss: 0.7315, Test Accuracy: 0.4941 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1420564651489258\n",
      "Epoch 44, Train Loss: 0.6511, Val Loss: 0.7266, Test Accuracy: 0.4993 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1534583568572998\n",
      "Epoch 45, Train Loss: 0.6492, Val Loss: 0.7353, Test Accuracy: 0.4823 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1470232009887695\n",
      "Epoch 46, Train Loss: 0.6490, Val Loss: 0.7251, Test Accuracy: 0.5203 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1447031497955322\n",
      "Epoch 47, Train Loss: 0.6491, Val Loss: 0.7242, Test Accuracy: 0.5216 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1481883525848389\n",
      "Epoch 48, Train Loss: 0.6497, Val Loss: 0.7341, Test Accuracy: 0.5007 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1512880325317383\n",
      "Epoch 49, Train Loss: 0.6430, Val Loss: 0.7374, Test Accuracy: 0.4849 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1481456756591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:51:30,159] Trial 13 finished with value: 0.5163826998689384 and parameters: {'HIDDEN_DIMENSION': 94, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.1907576697119489, 'LEARNING_RATE': 0.0003357891389023947}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6454, Val Loss: 0.7453, Test Accuracy: 0.4862 ,Learning Rate: 0.0003357891389023947 , Time Taken : 1.1585807800292969\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 128, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.27951486974643647, 'LEARNING_RATE': 0.00011652784973727726}\n",
      "Epoch 1, Train Loss: 0.8053, Val Loss: 0.7993, Test Accuracy: 0.4692 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5717718601226807\n",
      "Epoch 2, Train Loss: 0.7917, Val Loss: 0.7846, Test Accuracy: 0.4810 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.568718433380127\n",
      "Epoch 3, Train Loss: 0.7755, Val Loss: 0.7739, Test Accuracy: 0.4771 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5692486763000488\n",
      "Epoch 4, Train Loss: 0.7748, Val Loss: 0.7633, Test Accuracy: 0.4784 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5668239593505859\n",
      "Epoch 5, Train Loss: 0.7619, Val Loss: 0.7541, Test Accuracy: 0.4784 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5675687789916992\n",
      "Epoch 6, Train Loss: 0.7562, Val Loss: 0.7476, Test Accuracy: 0.4758 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5668458938598633\n",
      "Epoch 7, Train Loss: 0.7485, Val Loss: 0.7419, Test Accuracy: 0.4810 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5681729316711426\n",
      "Epoch 8, Train Loss: 0.7458, Val Loss: 0.7362, Test Accuracy: 0.4797 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.569918155670166\n",
      "Epoch 9, Train Loss: 0.7363, Val Loss: 0.7307, Test Accuracy: 0.4823 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5678894519805908\n",
      "Epoch 10, Train Loss: 0.7334, Val Loss: 0.7261, Test Accuracy: 0.4862 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5682260990142822\n",
      "Epoch 11, Train Loss: 0.7243, Val Loss: 0.7235, Test Accuracy: 0.4731 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5713541507720947\n",
      "Epoch 12, Train Loss: 0.7250, Val Loss: 0.7193, Test Accuracy: 0.4771 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5680515766143799\n",
      "Epoch 13, Train Loss: 0.7262, Val Loss: 0.7158, Test Accuracy: 0.4758 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5675957202911377\n",
      "Epoch 14, Train Loss: 0.7181, Val Loss: 0.7133, Test Accuracy: 0.4758 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.566901445388794\n",
      "Epoch 15, Train Loss: 0.7198, Val Loss: 0.7111, Test Accuracy: 0.4836 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5680005550384521\n",
      "Epoch 16, Train Loss: 0.7207, Val Loss: 0.7090, Test Accuracy: 0.4849 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5678091049194336\n",
      "Epoch 17, Train Loss: 0.7133, Val Loss: 0.7088, Test Accuracy: 0.4705 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5665149688720703\n",
      "Epoch 18, Train Loss: 0.7198, Val Loss: 0.7079, Test Accuracy: 0.4666 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5672962665557861\n",
      "Epoch 19, Train Loss: 0.7138, Val Loss: 0.7062, Test Accuracy: 0.4784 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5647463798522949\n",
      "Epoch 20, Train Loss: 0.7134, Val Loss: 0.7050, Test Accuracy: 0.4784 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5669281482696533\n",
      "Epoch 21, Train Loss: 0.7099, Val Loss: 0.7039, Test Accuracy: 0.4758 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5619254112243652\n",
      "Epoch 22, Train Loss: 0.7124, Val Loss: 0.7037, Test Accuracy: 0.4875 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5690431594848633\n",
      "Epoch 23, Train Loss: 0.7068, Val Loss: 0.7034, Test Accuracy: 0.4928 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5793874263763428\n",
      "Epoch 24, Train Loss: 0.7121, Val Loss: 0.7015, Test Accuracy: 0.5007 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5659167766571045\n",
      "Epoch 25, Train Loss: 0.7089, Val Loss: 0.7003, Test Accuracy: 0.5046 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5625665187835693\n",
      "Epoch 26, Train Loss: 0.7040, Val Loss: 0.6992, Test Accuracy: 0.5072 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5785765647888184\n",
      "Epoch 27, Train Loss: 0.7031, Val Loss: 0.6989, Test Accuracy: 0.5033 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5652306079864502\n",
      "Epoch 28, Train Loss: 0.7046, Val Loss: 0.6982, Test Accuracy: 0.5033 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.566148042678833\n",
      "Epoch 29, Train Loss: 0.7033, Val Loss: 0.6983, Test Accuracy: 0.5033 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5685725212097168\n",
      "Epoch 30, Train Loss: 0.7046, Val Loss: 0.6982, Test Accuracy: 0.5111 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5686888694763184\n",
      "Epoch 31, Train Loss: 0.7075, Val Loss: 0.6971, Test Accuracy: 0.5085 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5646607875823975\n",
      "Epoch 32, Train Loss: 0.7064, Val Loss: 0.6970, Test Accuracy: 0.5098 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.565138578414917\n",
      "Epoch 33, Train Loss: 0.7036, Val Loss: 0.6975, Test Accuracy: 0.5125 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5653679370880127\n",
      "Epoch 34, Train Loss: 0.6966, Val Loss: 0.6964, Test Accuracy: 0.5085 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.566387414932251\n",
      "Epoch 35, Train Loss: 0.6995, Val Loss: 0.6962, Test Accuracy: 0.5072 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5627617835998535\n",
      "Epoch 36, Train Loss: 0.6992, Val Loss: 0.6964, Test Accuracy: 0.5059 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5630815029144287\n",
      "Epoch 37, Train Loss: 0.7035, Val Loss: 0.6964, Test Accuracy: 0.5085 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5767059326171875\n",
      "Epoch 38, Train Loss: 0.6993, Val Loss: 0.6962, Test Accuracy: 0.5059 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.566169023513794\n",
      "Epoch 39, Train Loss: 0.6999, Val Loss: 0.6964, Test Accuracy: 0.5059 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.570880651473999\n",
      "Epoch 40, Train Loss: 0.7000, Val Loss: 0.6959, Test Accuracy: 0.5072 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5624189376831055\n",
      "Epoch 41, Train Loss: 0.6939, Val Loss: 0.6951, Test Accuracy: 0.5085 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5613164901733398\n",
      "Epoch 42, Train Loss: 0.6981, Val Loss: 0.6946, Test Accuracy: 0.5085 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5669436454772949\n",
      "Epoch 43, Train Loss: 0.6938, Val Loss: 0.6945, Test Accuracy: 0.5111 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.7507283687591553\n",
      "Epoch 44, Train Loss: 0.6972, Val Loss: 0.6945, Test Accuracy: 0.5098 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5632712841033936\n",
      "Epoch 45, Train Loss: 0.7000, Val Loss: 0.6936, Test Accuracy: 0.5059 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5674188137054443\n",
      "Epoch 46, Train Loss: 0.6936, Val Loss: 0.6936, Test Accuracy: 0.5098 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5660676956176758\n",
      "Epoch 47, Train Loss: 0.6973, Val Loss: 0.6938, Test Accuracy: 0.5138 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5730338096618652\n",
      "Epoch 48, Train Loss: 0.6940, Val Loss: 0.6944, Test Accuracy: 0.5138 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5687904357910156\n",
      "Epoch 49, Train Loss: 0.6963, Val Loss: 0.6939, Test Accuracy: 0.5151 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5662949085235596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:51:58,812] Trial 14 finished with value: 0.5242463958060288 and parameters: {'HIDDEN_DIMENSION': 128, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 512, 'DROP_OUT': 0.27951486974643647, 'LEARNING_RATE': 0.00011652784973727726}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6949, Val Loss: 0.6937, Test Accuracy: 0.5111 ,Learning Rate: 0.00011652784973727726 , Time Taken : 0.5695233345031738\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 84, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.17177405294612696, 'LEARNING_RATE': 0.0001440564379446349}\n",
      "Epoch 1, Train Loss: 0.7560, Val Loss: 0.7214, Test Accuracy: 0.4902 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1497833728790283\n",
      "Epoch 2, Train Loss: 0.7289, Val Loss: 0.7144, Test Accuracy: 0.4862 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.160628318786621\n",
      "Epoch 3, Train Loss: 0.7134, Val Loss: 0.7023, Test Accuracy: 0.5033 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1543078422546387\n",
      "Epoch 4, Train Loss: 0.7079, Val Loss: 0.7038, Test Accuracy: 0.4980 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.164010763168335\n",
      "Epoch 5, Train Loss: 0.7028, Val Loss: 0.6979, Test Accuracy: 0.4980 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1646435260772705\n",
      "Epoch 6, Train Loss: 0.7065, Val Loss: 0.6978, Test Accuracy: 0.4980 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.160151720046997\n",
      "Epoch 7, Train Loss: 0.6989, Val Loss: 0.6998, Test Accuracy: 0.4967 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.166015386581421\n",
      "Epoch 8, Train Loss: 0.6984, Val Loss: 0.6950, Test Accuracy: 0.5072 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1669299602508545\n",
      "Epoch 9, Train Loss: 0.6967, Val Loss: 0.6968, Test Accuracy: 0.4967 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1558878421783447\n",
      "Epoch 10, Train Loss: 0.6974, Val Loss: 0.6974, Test Accuracy: 0.4967 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.145071029663086\n",
      "Epoch 11, Train Loss: 0.6955, Val Loss: 0.6969, Test Accuracy: 0.4967 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1622662544250488\n",
      "Epoch 12, Train Loss: 0.6921, Val Loss: 0.6928, Test Accuracy: 0.5125 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1586337089538574\n",
      "Epoch 13, Train Loss: 0.6953, Val Loss: 0.6978, Test Accuracy: 0.4941 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1657812595367432\n",
      "Epoch 14, Train Loss: 0.6895, Val Loss: 0.6936, Test Accuracy: 0.5164 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1648361682891846\n",
      "Epoch 15, Train Loss: 0.6927, Val Loss: 0.6958, Test Accuracy: 0.5033 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.155813217163086\n",
      "Epoch 16, Train Loss: 0.6907, Val Loss: 0.6929, Test Accuracy: 0.5229 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1095807552337646\n",
      "Epoch 17, Train Loss: 0.6909, Val Loss: 0.6960, Test Accuracy: 0.5033 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1183524131774902\n",
      "Epoch 18, Train Loss: 0.6908, Val Loss: 0.6943, Test Accuracy: 0.5111 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.123948574066162\n",
      "Epoch 19, Train Loss: 0.6905, Val Loss: 0.6949, Test Accuracy: 0.5020 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1079316139221191\n",
      "Epoch 20, Train Loss: 0.6911, Val Loss: 0.6971, Test Accuracy: 0.5072 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1138458251953125\n",
      "Epoch 21, Train Loss: 0.6897, Val Loss: 0.6942, Test Accuracy: 0.5046 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1080353260040283\n",
      "Epoch 22, Train Loss: 0.6878, Val Loss: 0.6944, Test Accuracy: 0.5098 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1086041927337646\n",
      "Epoch 23, Train Loss: 0.6892, Val Loss: 0.6951, Test Accuracy: 0.5138 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.115077018737793\n",
      "Epoch 24, Train Loss: 0.6885, Val Loss: 0.6962, Test Accuracy: 0.5098 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1073565483093262\n",
      "Epoch 25, Train Loss: 0.6853, Val Loss: 0.6978, Test Accuracy: 0.5020 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.111828327178955\n",
      "Epoch 26, Train Loss: 0.6842, Val Loss: 0.6962, Test Accuracy: 0.5151 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1117143630981445\n",
      "Epoch 27, Train Loss: 0.6847, Val Loss: 0.6955, Test Accuracy: 0.5164 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1360163688659668\n",
      "Epoch 28, Train Loss: 0.6865, Val Loss: 0.6956, Test Accuracy: 0.5229 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1582837104797363\n",
      "Epoch 29, Train Loss: 0.6839, Val Loss: 0.6998, Test Accuracy: 0.4941 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1581923961639404\n",
      "Epoch 30, Train Loss: 0.6835, Val Loss: 0.6934, Test Accuracy: 0.5321 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1695961952209473\n",
      "Epoch 31, Train Loss: 0.6846, Val Loss: 0.6993, Test Accuracy: 0.4954 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.161916732788086\n",
      "Epoch 32, Train Loss: 0.6845, Val Loss: 0.7007, Test Accuracy: 0.4941 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.158454418182373\n",
      "Epoch 33, Train Loss: 0.6818, Val Loss: 0.7033, Test Accuracy: 0.4941 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1547832489013672\n",
      "Epoch 34, Train Loss: 0.6790, Val Loss: 0.6934, Test Accuracy: 0.5321 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.14849853515625\n",
      "Epoch 35, Train Loss: 0.6818, Val Loss: 0.6980, Test Accuracy: 0.4993 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1638987064361572\n",
      "Epoch 36, Train Loss: 0.6798, Val Loss: 0.7004, Test Accuracy: 0.5020 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.159538745880127\n",
      "Epoch 37, Train Loss: 0.6817, Val Loss: 0.7052, Test Accuracy: 0.4980 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1584908962249756\n",
      "Epoch 38, Train Loss: 0.6811, Val Loss: 0.6972, Test Accuracy: 0.5151 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.146364450454712\n",
      "Epoch 39, Train Loss: 0.6820, Val Loss: 0.6959, Test Accuracy: 0.5177 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1637487411499023\n",
      "Epoch 40, Train Loss: 0.6826, Val Loss: 0.7016, Test Accuracy: 0.4980 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1603000164031982\n",
      "Epoch 41, Train Loss: 0.6805, Val Loss: 0.7020, Test Accuracy: 0.4993 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1585087776184082\n",
      "Epoch 42, Train Loss: 0.6794, Val Loss: 0.7018, Test Accuracy: 0.5020 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1615808010101318\n",
      "Epoch 43, Train Loss: 0.6795, Val Loss: 0.7011, Test Accuracy: 0.5020 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.168105125427246\n",
      "Epoch 44, Train Loss: 0.6786, Val Loss: 0.7026, Test Accuracy: 0.4993 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1632318496704102\n",
      "Epoch 45, Train Loss: 0.6788, Val Loss: 0.7052, Test Accuracy: 0.4954 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1613929271697998\n",
      "Epoch 46, Train Loss: 0.6760, Val Loss: 0.7010, Test Accuracy: 0.5203 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1660254001617432\n",
      "Epoch 47, Train Loss: 0.6768, Val Loss: 0.7006, Test Accuracy: 0.5151 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1728127002716064\n",
      "Epoch 48, Train Loss: 0.6765, Val Loss: 0.7039, Test Accuracy: 0.5072 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1530945301055908\n",
      "Epoch 49, Train Loss: 0.6760, Val Loss: 0.7013, Test Accuracy: 0.5125 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.170992136001587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:52:56,398] Trial 15 finished with value: 0.54521625163827 and parameters: {'HIDDEN_DIMENSION': 84, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.17177405294612696, 'LEARNING_RATE': 0.0001440564379446349}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6756, Val Loss: 0.7010, Test Accuracy: 0.5151 ,Learning Rate: 0.0001440564379446349 , Time Taken : 1.1690292358398438\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 111, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.10126890396003116, 'LEARNING_RATE': 0.00034304297363360424}\n",
      "Epoch 1, Train Loss: 0.8152, Val Loss: 0.7684, Test Accuracy: 0.4993 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3215982913970947\n",
      "Epoch 2, Train Loss: 0.7929, Val Loss: 0.7492, Test Accuracy: 0.5020 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32335996627807617\n",
      "Epoch 3, Train Loss: 0.7767, Val Loss: 0.7353, Test Accuracy: 0.5007 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3223097324371338\n",
      "Epoch 4, Train Loss: 0.7573, Val Loss: 0.7228, Test Accuracy: 0.5059 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3184351921081543\n",
      "Epoch 5, Train Loss: 0.7422, Val Loss: 0.7130, Test Accuracy: 0.5111 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.317533016204834\n",
      "Epoch 6, Train Loss: 0.7369, Val Loss: 0.7049, Test Accuracy: 0.5216 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32097649574279785\n",
      "Epoch 7, Train Loss: 0.7262, Val Loss: 0.7013, Test Accuracy: 0.5203 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3191237449645996\n",
      "Epoch 8, Train Loss: 0.7188, Val Loss: 0.6964, Test Accuracy: 0.5295 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3175022602081299\n",
      "Epoch 9, Train Loss: 0.7166, Val Loss: 0.6943, Test Accuracy: 0.5491 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3183889389038086\n",
      "Epoch 10, Train Loss: 0.7116, Val Loss: 0.6919, Test Accuracy: 0.5505 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3172621726989746\n",
      "Epoch 11, Train Loss: 0.7080, Val Loss: 0.6914, Test Accuracy: 0.5413 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.328411340713501\n",
      "Epoch 12, Train Loss: 0.7008, Val Loss: 0.6902, Test Accuracy: 0.5387 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.320145845413208\n",
      "Epoch 13, Train Loss: 0.7025, Val Loss: 0.6908, Test Accuracy: 0.5308 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3194715976715088\n",
      "Epoch 14, Train Loss: 0.6952, Val Loss: 0.6904, Test Accuracy: 0.5216 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3197975158691406\n",
      "Epoch 15, Train Loss: 0.6937, Val Loss: 0.6906, Test Accuracy: 0.5177 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32091522216796875\n",
      "Epoch 16, Train Loss: 0.7001, Val Loss: 0.6908, Test Accuracy: 0.5282 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.31975317001342773\n",
      "Epoch 17, Train Loss: 0.6966, Val Loss: 0.6889, Test Accuracy: 0.5360 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.31806063652038574\n",
      "Epoch 18, Train Loss: 0.6933, Val Loss: 0.6896, Test Accuracy: 0.5452 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3225712776184082\n",
      "Epoch 19, Train Loss: 0.6900, Val Loss: 0.6914, Test Accuracy: 0.5413 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.31705641746520996\n",
      "Epoch 20, Train Loss: 0.6930, Val Loss: 0.6913, Test Accuracy: 0.5465 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32929110527038574\n",
      "Epoch 21, Train Loss: 0.6924, Val Loss: 0.6919, Test Accuracy: 0.5400 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3227064609527588\n",
      "Epoch 22, Train Loss: 0.6892, Val Loss: 0.6918, Test Accuracy: 0.5387 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3196265697479248\n",
      "Epoch 23, Train Loss: 0.6916, Val Loss: 0.6928, Test Accuracy: 0.5321 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3157615661621094\n",
      "Epoch 24, Train Loss: 0.6933, Val Loss: 0.6928, Test Accuracy: 0.5413 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3195493221282959\n",
      "Epoch 25, Train Loss: 0.6882, Val Loss: 0.6939, Test Accuracy: 0.5269 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32149672508239746\n",
      "Epoch 26, Train Loss: 0.6884, Val Loss: 0.6932, Test Accuracy: 0.5387 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3249671459197998\n",
      "Epoch 27, Train Loss: 0.6852, Val Loss: 0.6932, Test Accuracy: 0.5347 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3248162269592285\n",
      "Epoch 28, Train Loss: 0.6840, Val Loss: 0.6932, Test Accuracy: 0.5334 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32155680656433105\n",
      "Epoch 29, Train Loss: 0.6874, Val Loss: 0.6928, Test Accuracy: 0.5452 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3242912292480469\n",
      "Epoch 30, Train Loss: 0.6908, Val Loss: 0.6930, Test Accuracy: 0.5413 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3213508129119873\n",
      "Epoch 31, Train Loss: 0.6901, Val Loss: 0.6944, Test Accuracy: 0.5374 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32004451751708984\n",
      "Epoch 32, Train Loss: 0.6872, Val Loss: 0.6943, Test Accuracy: 0.5400 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.31935572624206543\n",
      "Epoch 33, Train Loss: 0.6889, Val Loss: 0.6948, Test Accuracy: 0.5347 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.31999945640563965\n",
      "Epoch 34, Train Loss: 0.6919, Val Loss: 0.6954, Test Accuracy: 0.5308 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3194119930267334\n",
      "Epoch 35, Train Loss: 0.6868, Val Loss: 0.6955, Test Accuracy: 0.5282 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3200085163116455\n",
      "Epoch 36, Train Loss: 0.6871, Val Loss: 0.6950, Test Accuracy: 0.5256 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3183097839355469\n",
      "Epoch 37, Train Loss: 0.6842, Val Loss: 0.6947, Test Accuracy: 0.5242 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.31742024421691895\n",
      "Epoch 38, Train Loss: 0.6853, Val Loss: 0.6941, Test Accuracy: 0.5387 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3172645568847656\n",
      "Epoch 39, Train Loss: 0.6864, Val Loss: 0.6956, Test Accuracy: 0.5256 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32100486755371094\n",
      "Epoch 40, Train Loss: 0.6865, Val Loss: 0.6957, Test Accuracy: 0.5321 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3224782943725586\n",
      "Epoch 41, Train Loss: 0.6887, Val Loss: 0.6954, Test Accuracy: 0.5347 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32032012939453125\n",
      "Epoch 42, Train Loss: 0.6840, Val Loss: 0.6965, Test Accuracy: 0.5229 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3208944797515869\n",
      "Epoch 43, Train Loss: 0.6836, Val Loss: 0.6970, Test Accuracy: 0.5229 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3280515670776367\n",
      "Epoch 44, Train Loss: 0.6858, Val Loss: 0.6960, Test Accuracy: 0.5308 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.31984782218933105\n",
      "Epoch 45, Train Loss: 0.6850, Val Loss: 0.6969, Test Accuracy: 0.5295 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32015466690063477\n",
      "Epoch 46, Train Loss: 0.6855, Val Loss: 0.6972, Test Accuracy: 0.5282 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.318666934967041\n",
      "Epoch 47, Train Loss: 0.6807, Val Loss: 0.6965, Test Accuracy: 0.5347 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.32205748558044434\n",
      "Epoch 48, Train Loss: 0.6831, Val Loss: 0.6969, Test Accuracy: 0.5413 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.3168659210205078\n",
      "Epoch 49, Train Loss: 0.6834, Val Loss: 0.6963, Test Accuracy: 0.5360 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.318312406539917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:53:12,501] Trial 16 finished with value: 0.5321100917431193 and parameters: {'HIDDEN_DIMENSION': 111, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 512, 'DROP_OUT': 0.10126890396003116, 'LEARNING_RATE': 0.00034304297363360424}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6820, Val Loss: 0.6970, Test Accuracy: 0.5439 ,Learning Rate: 0.00034304297363360424 , Time Taken : 0.31876158714294434\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 53, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1595485180427248, 'LEARNING_RATE': 6.422468611793918e-05}\n",
      "Epoch 1, Train Loss: 0.8002, Val Loss: 0.7347, Test Accuracy: 0.5321 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8460516929626465\n",
      "Epoch 2, Train Loss: 0.7562, Val Loss: 0.7331, Test Accuracy: 0.5321 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8533892631530762\n",
      "Epoch 3, Train Loss: 0.7487, Val Loss: 0.7311, Test Accuracy: 0.5321 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8585250377655029\n",
      "Epoch 4, Train Loss: 0.7391, Val Loss: 0.7283, Test Accuracy: 0.5269 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8503086566925049\n",
      "Epoch 5, Train Loss: 0.7341, Val Loss: 0.7246, Test Accuracy: 0.5256 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8529107570648193\n",
      "Epoch 6, Train Loss: 0.7283, Val Loss: 0.7227, Test Accuracy: 0.5295 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8581855297088623\n",
      "Epoch 7, Train Loss: 0.7235, Val Loss: 0.7182, Test Accuracy: 0.5334 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8539180755615234\n",
      "Epoch 8, Train Loss: 0.7175, Val Loss: 0.7159, Test Accuracy: 0.5190 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.858119010925293\n",
      "Epoch 9, Train Loss: 0.7142, Val Loss: 0.7135, Test Accuracy: 0.5190 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8525762557983398\n",
      "Epoch 10, Train Loss: 0.7134, Val Loss: 0.7122, Test Accuracy: 0.5138 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8536360263824463\n",
      "Epoch 11, Train Loss: 0.7090, Val Loss: 0.7103, Test Accuracy: 0.5046 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8548717498779297\n",
      "Epoch 12, Train Loss: 0.7037, Val Loss: 0.7094, Test Accuracy: 0.4993 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8529675006866455\n",
      "Epoch 13, Train Loss: 0.7062, Val Loss: 0.7071, Test Accuracy: 0.5007 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8529016971588135\n",
      "Epoch 14, Train Loss: 0.7014, Val Loss: 0.7067, Test Accuracy: 0.4980 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8562898635864258\n",
      "Epoch 15, Train Loss: 0.7058, Val Loss: 0.7056, Test Accuracy: 0.4980 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8570823669433594\n",
      "Epoch 16, Train Loss: 0.6985, Val Loss: 0.7050, Test Accuracy: 0.4967 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8563048839569092\n",
      "Epoch 17, Train Loss: 0.7002, Val Loss: 0.7045, Test Accuracy: 0.4941 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8513400554656982\n",
      "Epoch 18, Train Loss: 0.6980, Val Loss: 0.7036, Test Accuracy: 0.4980 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8539223670959473\n",
      "Epoch 19, Train Loss: 0.6988, Val Loss: 0.7037, Test Accuracy: 0.4993 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.85660719871521\n",
      "Epoch 20, Train Loss: 0.6954, Val Loss: 0.7032, Test Accuracy: 0.4980 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8543117046356201\n",
      "Epoch 21, Train Loss: 0.6970, Val Loss: 0.7012, Test Accuracy: 0.4980 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8541254997253418\n",
      "Epoch 22, Train Loss: 0.6943, Val Loss: 0.7021, Test Accuracy: 0.4902 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.846365213394165\n",
      "Epoch 23, Train Loss: 0.6979, Val Loss: 0.7013, Test Accuracy: 0.4915 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8119018077850342\n",
      "Epoch 24, Train Loss: 0.6927, Val Loss: 0.7020, Test Accuracy: 0.4928 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.813812255859375\n",
      "Epoch 25, Train Loss: 0.6971, Val Loss: 0.7011, Test Accuracy: 0.4875 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8163273334503174\n",
      "Epoch 26, Train Loss: 0.6945, Val Loss: 0.7003, Test Accuracy: 0.4902 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8143117427825928\n",
      "Epoch 27, Train Loss: 0.6958, Val Loss: 0.7004, Test Accuracy: 0.4902 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8168001174926758\n",
      "Epoch 28, Train Loss: 0.6948, Val Loss: 0.7002, Test Accuracy: 0.4993 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8157432079315186\n",
      "Epoch 29, Train Loss: 0.6934, Val Loss: 0.6997, Test Accuracy: 0.5046 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8136270046234131\n",
      "Epoch 30, Train Loss: 0.6918, Val Loss: 0.7010, Test Accuracy: 0.5072 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8151051998138428\n",
      "Epoch 31, Train Loss: 0.6904, Val Loss: 0.7003, Test Accuracy: 0.5085 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.811638355255127\n",
      "Epoch 32, Train Loss: 0.6930, Val Loss: 0.6996, Test Accuracy: 0.5111 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8108162879943848\n",
      "Epoch 33, Train Loss: 0.6908, Val Loss: 0.6996, Test Accuracy: 0.5164 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8128736019134521\n",
      "Epoch 34, Train Loss: 0.6964, Val Loss: 0.7001, Test Accuracy: 0.5151 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8136415481567383\n",
      "Epoch 35, Train Loss: 0.6891, Val Loss: 0.6997, Test Accuracy: 0.5216 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8186097145080566\n",
      "Epoch 36, Train Loss: 0.6903, Val Loss: 0.7008, Test Accuracy: 0.5190 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8148555755615234\n",
      "Epoch 37, Train Loss: 0.6898, Val Loss: 0.7008, Test Accuracy: 0.5216 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8179833889007568\n",
      "Epoch 38, Train Loss: 0.6931, Val Loss: 0.6999, Test Accuracy: 0.5242 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8170068264007568\n",
      "Epoch 39, Train Loss: 0.6910, Val Loss: 0.6982, Test Accuracy: 0.5242 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8140528202056885\n",
      "Epoch 40, Train Loss: 0.6906, Val Loss: 0.6991, Test Accuracy: 0.5229 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.821739912033081\n",
      "Epoch 41, Train Loss: 0.6884, Val Loss: 0.7001, Test Accuracy: 0.5256 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8145971298217773\n",
      "Epoch 42, Train Loss: 0.6875, Val Loss: 0.6996, Test Accuracy: 0.5164 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.820986270904541\n",
      "Epoch 43, Train Loss: 0.6887, Val Loss: 0.6993, Test Accuracy: 0.5151 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8193933963775635\n",
      "Epoch 44, Train Loss: 0.6904, Val Loss: 0.6987, Test Accuracy: 0.5190 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8127574920654297\n",
      "Epoch 45, Train Loss: 0.6882, Val Loss: 0.6981, Test Accuracy: 0.5216 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8160851001739502\n",
      "Epoch 46, Train Loss: 0.6866, Val Loss: 0.6981, Test Accuracy: 0.5216 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8210361003875732\n",
      "Epoch 47, Train Loss: 0.6877, Val Loss: 0.6990, Test Accuracy: 0.5098 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8581044673919678\n",
      "Epoch 48, Train Loss: 0.6887, Val Loss: 0.6982, Test Accuracy: 0.5177 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8351337909698486\n",
      "Epoch 49, Train Loss: 0.6872, Val Loss: 0.6979, Test Accuracy: 0.5177 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8558998107910156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:53:54,361] Trial 17 finished with value: 0.5203145478374837 and parameters: {'HIDDEN_DIMENSION': 53, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'DROP_OUT': 0.1595485180427248, 'LEARNING_RATE': 6.422468611793918e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6863, Val Loss: 0.6989, Test Accuracy: 0.5138 ,Learning Rate: 6.422468611793918e-05 , Time Taken : 0.8549096584320068\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 97, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.26674470298068387, 'LEARNING_RATE': 0.00019621816446518896}\n",
      "Epoch 1, Train Loss: 0.7427, Val Loss: 0.7180, Test Accuracy: 0.5125 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8333590030670166\n",
      "Epoch 2, Train Loss: 0.7311, Val Loss: 0.7112, Test Accuracy: 0.5334 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8209366798400879\n",
      "Epoch 3, Train Loss: 0.7173, Val Loss: 0.7086, Test Accuracy: 0.5321 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8222494125366211\n",
      "Epoch 4, Train Loss: 0.7133, Val Loss: 0.7048, Test Accuracy: 0.5229 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8270761966705322\n",
      "Epoch 5, Train Loss: 0.7095, Val Loss: 0.7025, Test Accuracy: 0.5374 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8170230388641357\n",
      "Epoch 6, Train Loss: 0.7073, Val Loss: 0.7002, Test Accuracy: 0.5387 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8140168190002441\n",
      "Epoch 7, Train Loss: 0.7038, Val Loss: 0.6990, Test Accuracy: 0.5360 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8171641826629639\n",
      "Epoch 8, Train Loss: 0.7045, Val Loss: 0.6983, Test Accuracy: 0.5282 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8188667297363281\n",
      "Epoch 9, Train Loss: 0.7016, Val Loss: 0.6992, Test Accuracy: 0.5269 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.824307918548584\n",
      "Epoch 10, Train Loss: 0.7006, Val Loss: 0.6973, Test Accuracy: 0.5242 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8194882869720459\n",
      "Epoch 11, Train Loss: 0.7001, Val Loss: 0.6957, Test Accuracy: 0.5347 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8186440467834473\n",
      "Epoch 12, Train Loss: 0.6999, Val Loss: 0.6964, Test Accuracy: 0.5177 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8199341297149658\n",
      "Epoch 13, Train Loss: 0.6955, Val Loss: 0.6966, Test Accuracy: 0.5138 ,Learning Rate: 0.00019621816446518896 , Time Taken : 1.0249285697937012\n",
      "Epoch 14, Train Loss: 0.6949, Val Loss: 0.6963, Test Accuracy: 0.5177 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8195021152496338\n",
      "Epoch 15, Train Loss: 0.6973, Val Loss: 0.6949, Test Accuracy: 0.5308 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8205702304840088\n",
      "Epoch 16, Train Loss: 0.6972, Val Loss: 0.6950, Test Accuracy: 0.5295 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8175404071807861\n",
      "Epoch 17, Train Loss: 0.6958, Val Loss: 0.6944, Test Accuracy: 0.5360 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8192775249481201\n",
      "Epoch 18, Train Loss: 0.6948, Val Loss: 0.6957, Test Accuracy: 0.5151 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.821141242980957\n",
      "Epoch 19, Train Loss: 0.6913, Val Loss: 0.6953, Test Accuracy: 0.5216 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8176126480102539\n",
      "Epoch 20, Train Loss: 0.6956, Val Loss: 0.6933, Test Accuracy: 0.5465 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8164820671081543\n",
      "Epoch 21, Train Loss: 0.6917, Val Loss: 0.6935, Test Accuracy: 0.5465 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8187642097473145\n",
      "Epoch 22, Train Loss: 0.6928, Val Loss: 0.6940, Test Accuracy: 0.5334 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8233039379119873\n",
      "Epoch 23, Train Loss: 0.6910, Val Loss: 0.6962, Test Accuracy: 0.5111 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8208401203155518\n",
      "Epoch 24, Train Loss: 0.6900, Val Loss: 0.6974, Test Accuracy: 0.5111 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8184168338775635\n",
      "Epoch 25, Train Loss: 0.6921, Val Loss: 0.6941, Test Accuracy: 0.5321 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8202621936798096\n",
      "Epoch 26, Train Loss: 0.6924, Val Loss: 0.6925, Test Accuracy: 0.5387 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8195207118988037\n",
      "Epoch 27, Train Loss: 0.6927, Val Loss: 0.6934, Test Accuracy: 0.5321 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8178410530090332\n",
      "Epoch 28, Train Loss: 0.6907, Val Loss: 0.6954, Test Accuracy: 0.5295 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8183870315551758\n",
      "Epoch 29, Train Loss: 0.6896, Val Loss: 0.6950, Test Accuracy: 0.5242 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8175806999206543\n",
      "Epoch 30, Train Loss: 0.6920, Val Loss: 0.6930, Test Accuracy: 0.5413 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8212888240814209\n",
      "Epoch 31, Train Loss: 0.6916, Val Loss: 0.6939, Test Accuracy: 0.5334 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.816331148147583\n",
      "Epoch 32, Train Loss: 0.6894, Val Loss: 0.6950, Test Accuracy: 0.5321 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8174803256988525\n",
      "Epoch 33, Train Loss: 0.6889, Val Loss: 0.6947, Test Accuracy: 0.5387 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8177852630615234\n",
      "Epoch 34, Train Loss: 0.6900, Val Loss: 0.6926, Test Accuracy: 0.5452 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8153886795043945\n",
      "Epoch 35, Train Loss: 0.6886, Val Loss: 0.6945, Test Accuracy: 0.5400 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8176171779632568\n",
      "Epoch 36, Train Loss: 0.6888, Val Loss: 0.6939, Test Accuracy: 0.5452 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8197686672210693\n",
      "Epoch 37, Train Loss: 0.6883, Val Loss: 0.6937, Test Accuracy: 0.5478 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8207573890686035\n",
      "Epoch 38, Train Loss: 0.6911, Val Loss: 0.6931, Test Accuracy: 0.5452 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8199648857116699\n",
      "Epoch 39, Train Loss: 0.6887, Val Loss: 0.6925, Test Accuracy: 0.5347 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.816173791885376\n",
      "Epoch 40, Train Loss: 0.6872, Val Loss: 0.6951, Test Accuracy: 0.5282 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8149738311767578\n",
      "Epoch 41, Train Loss: 0.6872, Val Loss: 0.6943, Test Accuracy: 0.5360 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.819157600402832\n",
      "Epoch 42, Train Loss: 0.6887, Val Loss: 0.6948, Test Accuracy: 0.5308 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8185298442840576\n",
      "Epoch 43, Train Loss: 0.6901, Val Loss: 0.6948, Test Accuracy: 0.5308 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.818873405456543\n",
      "Epoch 44, Train Loss: 0.6871, Val Loss: 0.6933, Test Accuracy: 0.5308 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8182141780853271\n",
      "Epoch 45, Train Loss: 0.6870, Val Loss: 0.6935, Test Accuracy: 0.5308 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8206331729888916\n",
      "Epoch 46, Train Loss: 0.6866, Val Loss: 0.6937, Test Accuracy: 0.5308 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8186511993408203\n",
      "Epoch 47, Train Loss: 0.6873, Val Loss: 0.6954, Test Accuracy: 0.5164 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8185133934020996\n",
      "Epoch 48, Train Loss: 0.6854, Val Loss: 0.6940, Test Accuracy: 0.5308 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8175418376922607\n",
      "Epoch 49, Train Loss: 0.6884, Val Loss: 0.6928, Test Accuracy: 0.5321 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8171100616455078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:54:35,636] Trial 18 finished with value: 0.5190039318479686 and parameters: {'HIDDEN_DIMENSION': 97, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'DROP_OUT': 0.26674470298068387, 'LEARNING_RATE': 0.00019621816446518896}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6863, Val Loss: 0.6943, Test Accuracy: 0.5242 ,Learning Rate: 0.00019621816446518896 , Time Taken : 0.8176124095916748\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 116, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.19899538547221363, 'LEARNING_RATE': 0.00012267467804654016}\n",
      "Epoch 1, Train Loss: 0.7507, Val Loss: 0.7243, Test Accuracy: 0.5033 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4843087196350098\n",
      "Epoch 2, Train Loss: 0.7145, Val Loss: 0.7073, Test Accuracy: 0.5098 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4872591495513916\n",
      "Epoch 3, Train Loss: 0.7068, Val Loss: 0.6993, Test Accuracy: 0.5190 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4967305660247803\n",
      "Epoch 4, Train Loss: 0.7014, Val Loss: 0.6970, Test Accuracy: 0.5138 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4973196983337402\n",
      "Epoch 5, Train Loss: 0.6974, Val Loss: 0.6972, Test Accuracy: 0.5085 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4953696727752686\n",
      "Epoch 6, Train Loss: 0.6980, Val Loss: 0.6965, Test Accuracy: 0.4980 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.5074031352996826\n",
      "Epoch 7, Train Loss: 0.6932, Val Loss: 0.6929, Test Accuracy: 0.5072 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4954030513763428\n",
      "Epoch 8, Train Loss: 0.6953, Val Loss: 0.6913, Test Accuracy: 0.5072 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4929463863372803\n",
      "Epoch 9, Train Loss: 0.6907, Val Loss: 0.6957, Test Accuracy: 0.5059 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4839134216308594\n",
      "Epoch 10, Train Loss: 0.6891, Val Loss: 0.6889, Test Accuracy: 0.5203 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4868414402008057\n",
      "Epoch 11, Train Loss: 0.6882, Val Loss: 0.6940, Test Accuracy: 0.5007 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.5077669620513916\n",
      "Epoch 12, Train Loss: 0.6905, Val Loss: 0.6974, Test Accuracy: 0.4967 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.5168125629425049\n",
      "Epoch 13, Train Loss: 0.6891, Val Loss: 0.6968, Test Accuracy: 0.4967 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4984827041625977\n",
      "Epoch 14, Train Loss: 0.6844, Val Loss: 0.6964, Test Accuracy: 0.5007 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4913296699523926\n",
      "Epoch 15, Train Loss: 0.6847, Val Loss: 0.6917, Test Accuracy: 0.5203 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4836947917938232\n",
      "Epoch 16, Train Loss: 0.6861, Val Loss: 0.6961, Test Accuracy: 0.5059 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4902758598327637\n",
      "Epoch 17, Train Loss: 0.6853, Val Loss: 0.6907, Test Accuracy: 0.5256 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.499483585357666\n",
      "Epoch 18, Train Loss: 0.6845, Val Loss: 0.6936, Test Accuracy: 0.5111 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4896469116210938\n",
      "Epoch 19, Train Loss: 0.6842, Val Loss: 0.6996, Test Accuracy: 0.4954 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.500053882598877\n",
      "Epoch 20, Train Loss: 0.6854, Val Loss: 0.6969, Test Accuracy: 0.5125 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4834251403808594\n",
      "Epoch 21, Train Loss: 0.6842, Val Loss: 0.7010, Test Accuracy: 0.4875 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4883341789245605\n",
      "Epoch 22, Train Loss: 0.6823, Val Loss: 0.6905, Test Accuracy: 0.5282 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4992129802703857\n",
      "Epoch 23, Train Loss: 0.6817, Val Loss: 0.6944, Test Accuracy: 0.5151 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4997079372406006\n",
      "Epoch 24, Train Loss: 0.6815, Val Loss: 0.6992, Test Accuracy: 0.5007 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.501844882965088\n",
      "Epoch 25, Train Loss: 0.6826, Val Loss: 0.7005, Test Accuracy: 0.4915 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4980270862579346\n",
      "Epoch 26, Train Loss: 0.6803, Val Loss: 0.6967, Test Accuracy: 0.5111 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4928960800170898\n",
      "Epoch 27, Train Loss: 0.6809, Val Loss: 0.6975, Test Accuracy: 0.5098 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4958901405334473\n",
      "Epoch 28, Train Loss: 0.6817, Val Loss: 0.6988, Test Accuracy: 0.4980 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.5032057762145996\n",
      "Epoch 29, Train Loss: 0.6778, Val Loss: 0.6979, Test Accuracy: 0.5177 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.53092360496521\n",
      "Epoch 30, Train Loss: 0.6771, Val Loss: 0.7056, Test Accuracy: 0.4797 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.5331306457519531\n",
      "Epoch 31, Train Loss: 0.6781, Val Loss: 0.6951, Test Accuracy: 0.5177 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4916245937347412\n",
      "Epoch 32, Train Loss: 0.6759, Val Loss: 0.6998, Test Accuracy: 0.5125 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4977641105651855\n",
      "Epoch 33, Train Loss: 0.6776, Val Loss: 0.6947, Test Accuracy: 0.5229 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4958703517913818\n",
      "Epoch 34, Train Loss: 0.6786, Val Loss: 0.7052, Test Accuracy: 0.4836 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.5075311660766602\n",
      "Epoch 35, Train Loss: 0.6765, Val Loss: 0.7007, Test Accuracy: 0.5111 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.491840124130249\n",
      "Epoch 36, Train Loss: 0.6779, Val Loss: 0.6950, Test Accuracy: 0.5190 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4911143779754639\n",
      "Epoch 37, Train Loss: 0.6728, Val Loss: 0.7021, Test Accuracy: 0.5033 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4809834957122803\n",
      "Epoch 38, Train Loss: 0.6743, Val Loss: 0.7018, Test Accuracy: 0.5033 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.500244379043579\n",
      "Epoch 39, Train Loss: 0.6750, Val Loss: 0.7016, Test Accuracy: 0.5033 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4955456256866455\n",
      "Epoch 40, Train Loss: 0.6728, Val Loss: 0.7028, Test Accuracy: 0.5059 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.482013463973999\n",
      "Epoch 41, Train Loss: 0.6722, Val Loss: 0.7081, Test Accuracy: 0.4836 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.486729383468628\n",
      "Epoch 42, Train Loss: 0.6715, Val Loss: 0.6996, Test Accuracy: 0.5229 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.495774745941162\n",
      "Epoch 43, Train Loss: 0.6737, Val Loss: 0.7052, Test Accuracy: 0.4928 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4921724796295166\n",
      "Epoch 44, Train Loss: 0.6689, Val Loss: 0.7058, Test Accuracy: 0.4954 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4979002475738525\n",
      "Epoch 45, Train Loss: 0.6704, Val Loss: 0.7028, Test Accuracy: 0.5033 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4950244426727295\n",
      "Epoch 46, Train Loss: 0.6718, Val Loss: 0.7056, Test Accuracy: 0.4993 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.5020685195922852\n",
      "Epoch 47, Train Loss: 0.6711, Val Loss: 0.7021, Test Accuracy: 0.5125 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.507861852645874\n",
      "Epoch 48, Train Loss: 0.6711, Val Loss: 0.7030, Test Accuracy: 0.5098 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.5118160247802734\n",
      "Epoch 49, Train Loss: 0.6685, Val Loss: 0.7009, Test Accuracy: 0.5138 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.528196096420288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:55:50,647] Trial 19 finished with value: 0.4849279161205767 and parameters: {'HIDDEN_DIMENSION': 116, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 64, 'DROP_OUT': 0.19899538547221363, 'LEARNING_RATE': 0.00012267467804654016}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6663, Val Loss: 0.7100, Test Accuracy: 0.4862 ,Learning Rate: 0.00012267467804654016 , Time Taken : 1.4959123134613037\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 76, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.13256233556556257, 'LEARNING_RATE': 4.925292978290732e-05}\n",
      "Epoch 1, Train Loss: 0.7415, Val Loss: 0.7545, Test Accuracy: 0.4915 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3197004795074463\n",
      "Epoch 2, Train Loss: 0.7393, Val Loss: 0.7538, Test Accuracy: 0.4993 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3239414691925049\n",
      "Epoch 3, Train Loss: 0.7372, Val Loss: 0.7531, Test Accuracy: 0.5046 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31553125381469727\n",
      "Epoch 4, Train Loss: 0.7387, Val Loss: 0.7524, Test Accuracy: 0.5033 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31450724601745605\n",
      "Epoch 5, Train Loss: 0.7354, Val Loss: 0.7517, Test Accuracy: 0.4954 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3282136917114258\n",
      "Epoch 6, Train Loss: 0.7362, Val Loss: 0.7512, Test Accuracy: 0.4941 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3119230270385742\n",
      "Epoch 7, Train Loss: 0.7347, Val Loss: 0.7504, Test Accuracy: 0.4980 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31462669372558594\n",
      "Epoch 8, Train Loss: 0.7301, Val Loss: 0.7497, Test Accuracy: 0.4993 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31472158432006836\n",
      "Epoch 9, Train Loss: 0.7310, Val Loss: 0.7490, Test Accuracy: 0.4980 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31748127937316895\n",
      "Epoch 10, Train Loss: 0.7296, Val Loss: 0.7483, Test Accuracy: 0.4941 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3139510154724121\n",
      "Epoch 11, Train Loss: 0.7266, Val Loss: 0.7475, Test Accuracy: 0.4941 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3145558834075928\n",
      "Epoch 12, Train Loss: 0.7285, Val Loss: 0.7468, Test Accuracy: 0.4902 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3160068988800049\n",
      "Epoch 13, Train Loss: 0.7290, Val Loss: 0.7460, Test Accuracy: 0.4875 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3141591548919678\n",
      "Epoch 14, Train Loss: 0.7260, Val Loss: 0.7452, Test Accuracy: 0.4889 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3158841133117676\n",
      "Epoch 15, Train Loss: 0.7250, Val Loss: 0.7445, Test Accuracy: 0.4902 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3188631534576416\n",
      "Epoch 16, Train Loss: 0.7285, Val Loss: 0.7439, Test Accuracy: 0.4915 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3310256004333496\n",
      "Epoch 17, Train Loss: 0.7217, Val Loss: 0.7431, Test Accuracy: 0.4928 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31320786476135254\n",
      "Epoch 18, Train Loss: 0.7204, Val Loss: 0.7424, Test Accuracy: 0.4941 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31625914573669434\n",
      "Epoch 19, Train Loss: 0.7217, Val Loss: 0.7417, Test Accuracy: 0.4928 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3265376091003418\n",
      "Epoch 20, Train Loss: 0.7211, Val Loss: 0.7411, Test Accuracy: 0.4928 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3212761878967285\n",
      "Epoch 21, Train Loss: 0.7181, Val Loss: 0.7403, Test Accuracy: 0.4928 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.32192182540893555\n",
      "Epoch 22, Train Loss: 0.7185, Val Loss: 0.7396, Test Accuracy: 0.4941 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3135030269622803\n",
      "Epoch 23, Train Loss: 0.7212, Val Loss: 0.7389, Test Accuracy: 0.4954 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31905388832092285\n",
      "Epoch 24, Train Loss: 0.7208, Val Loss: 0.7381, Test Accuracy: 0.4941 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3174262046813965\n",
      "Epoch 25, Train Loss: 0.7178, Val Loss: 0.7374, Test Accuracy: 0.4928 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31618833541870117\n",
      "Epoch 26, Train Loss: 0.7139, Val Loss: 0.7367, Test Accuracy: 0.4915 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31623196601867676\n",
      "Epoch 27, Train Loss: 0.7127, Val Loss: 0.7362, Test Accuracy: 0.4902 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3175537586212158\n",
      "Epoch 28, Train Loss: 0.7160, Val Loss: 0.7355, Test Accuracy: 0.4928 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3195333480834961\n",
      "Epoch 29, Train Loss: 0.7162, Val Loss: 0.7348, Test Accuracy: 0.4928 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31638383865356445\n",
      "Epoch 30, Train Loss: 0.7153, Val Loss: 0.7342, Test Accuracy: 0.4915 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3154728412628174\n",
      "Epoch 31, Train Loss: 0.7174, Val Loss: 0.7334, Test Accuracy: 0.4915 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3151586055755615\n",
      "Epoch 32, Train Loss: 0.7175, Val Loss: 0.7328, Test Accuracy: 0.4941 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31648778915405273\n",
      "Epoch 33, Train Loss: 0.7101, Val Loss: 0.7323, Test Accuracy: 0.4915 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31516098976135254\n",
      "Epoch 34, Train Loss: 0.7130, Val Loss: 0.7316, Test Accuracy: 0.4915 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31560683250427246\n",
      "Epoch 35, Train Loss: 0.7130, Val Loss: 0.7310, Test Accuracy: 0.4902 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31702208518981934\n",
      "Epoch 36, Train Loss: 0.7106, Val Loss: 0.7304, Test Accuracy: 0.4889 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3151531219482422\n",
      "Epoch 37, Train Loss: 0.7117, Val Loss: 0.7298, Test Accuracy: 0.4889 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3169684410095215\n",
      "Epoch 38, Train Loss: 0.7122, Val Loss: 0.7291, Test Accuracy: 0.4875 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.32313990592956543\n",
      "Epoch 39, Train Loss: 0.7105, Val Loss: 0.7287, Test Accuracy: 0.4836 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3146505355834961\n",
      "Epoch 40, Train Loss: 0.7123, Val Loss: 0.7283, Test Accuracy: 0.4836 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31537532806396484\n",
      "Epoch 41, Train Loss: 0.7102, Val Loss: 0.7277, Test Accuracy: 0.4836 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31166911125183105\n",
      "Epoch 42, Train Loss: 0.7082, Val Loss: 0.7272, Test Accuracy: 0.4836 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31723570823669434\n",
      "Epoch 43, Train Loss: 0.7090, Val Loss: 0.7267, Test Accuracy: 0.4849 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3155815601348877\n",
      "Epoch 44, Train Loss: 0.7078, Val Loss: 0.7261, Test Accuracy: 0.4889 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.5280919075012207\n",
      "Epoch 45, Train Loss: 0.7055, Val Loss: 0.7256, Test Accuracy: 0.4902 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3153717517852783\n",
      "Epoch 46, Train Loss: 0.7091, Val Loss: 0.7252, Test Accuracy: 0.4902 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3185274600982666\n",
      "Epoch 47, Train Loss: 0.7075, Val Loss: 0.7246, Test Accuracy: 0.4849 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31566762924194336\n",
      "Epoch 48, Train Loss: 0.7066, Val Loss: 0.7243, Test Accuracy: 0.4875 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.3164098262786865\n",
      "Epoch 49, Train Loss: 0.7108, Val Loss: 0.7238, Test Accuracy: 0.4902 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.32030200958251953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:56:06,800] Trial 20 finished with value: 0.4941022280471822 and parameters: {'HIDDEN_DIMENSION': 76, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 512, 'DROP_OUT': 0.13256233556556257, 'LEARNING_RATE': 4.925292978290732e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7075, Val Loss: 0.7233, Test Accuracy: 0.4915 ,Learning Rate: 4.925292978290732e-05 , Time Taken : 0.31944870948791504\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 117, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1461258860426837, 'LEARNING_RATE': 0.0001009834801905927}\n",
      "Epoch 1, Train Loss: 0.7686, Val Loss: 0.7120, Test Accuracy: 0.5203 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0725491046905518\n",
      "Epoch 2, Train Loss: 0.7372, Val Loss: 0.7201, Test Accuracy: 0.4771 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0819146633148193\n",
      "Epoch 3, Train Loss: 0.7277, Val Loss: 0.7288, Test Accuracy: 0.4666 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0800514221191406\n",
      "Epoch 4, Train Loss: 0.7235, Val Loss: 0.7268, Test Accuracy: 0.4653 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0846431255340576\n",
      "Epoch 5, Train Loss: 0.7179, Val Loss: 0.7205, Test Accuracy: 0.4718 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0797371864318848\n",
      "Epoch 6, Train Loss: 0.7124, Val Loss: 0.7140, Test Accuracy: 0.4810 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0819995403289795\n",
      "Epoch 7, Train Loss: 0.7064, Val Loss: 0.7096, Test Accuracy: 0.4875 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0782530307769775\n",
      "Epoch 8, Train Loss: 0.7080, Val Loss: 0.7072, Test Accuracy: 0.4849 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0765087604522705\n",
      "Epoch 9, Train Loss: 0.7054, Val Loss: 0.7083, Test Accuracy: 0.4771 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0922746658325195\n",
      "Epoch 10, Train Loss: 0.7027, Val Loss: 0.7080, Test Accuracy: 0.4744 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0863351821899414\n",
      "Epoch 11, Train Loss: 0.7051, Val Loss: 0.7054, Test Accuracy: 0.4784 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0823311805725098\n",
      "Epoch 12, Train Loss: 0.7046, Val Loss: 0.7032, Test Accuracy: 0.4849 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.089456558227539\n",
      "Epoch 13, Train Loss: 0.7020, Val Loss: 0.7024, Test Accuracy: 0.4849 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0860517024993896\n",
      "Epoch 14, Train Loss: 0.6985, Val Loss: 0.7023, Test Accuracy: 0.4836 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0882134437561035\n",
      "Epoch 15, Train Loss: 0.6975, Val Loss: 0.7036, Test Accuracy: 0.4771 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0848829746246338\n",
      "Epoch 16, Train Loss: 0.6989, Val Loss: 0.7009, Test Accuracy: 0.4849 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0807976722717285\n",
      "Epoch 17, Train Loss: 0.7027, Val Loss: 0.7003, Test Accuracy: 0.4889 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.07999587059021\n",
      "Epoch 18, Train Loss: 0.6976, Val Loss: 0.6996, Test Accuracy: 0.4915 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0866332054138184\n",
      "Epoch 19, Train Loss: 0.6991, Val Loss: 0.6997, Test Accuracy: 0.4889 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0837979316711426\n",
      "Epoch 20, Train Loss: 0.6945, Val Loss: 0.6982, Test Accuracy: 0.4928 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0871374607086182\n",
      "Epoch 21, Train Loss: 0.6968, Val Loss: 0.6981, Test Accuracy: 0.4967 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.078075647354126\n",
      "Epoch 22, Train Loss: 0.6927, Val Loss: 0.6967, Test Accuracy: 0.5033 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0818336009979248\n",
      "Epoch 23, Train Loss: 0.6954, Val Loss: 0.6977, Test Accuracy: 0.4993 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.085834264755249\n",
      "Epoch 24, Train Loss: 0.6944, Val Loss: 0.6977, Test Accuracy: 0.4967 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0964627265930176\n",
      "Epoch 25, Train Loss: 0.6947, Val Loss: 0.6978, Test Accuracy: 0.4915 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0795114040374756\n",
      "Epoch 26, Train Loss: 0.6927, Val Loss: 0.6984, Test Accuracy: 0.4915 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0865404605865479\n",
      "Epoch 27, Train Loss: 0.6920, Val Loss: 0.6972, Test Accuracy: 0.4993 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0830841064453125\n",
      "Epoch 28, Train Loss: 0.6950, Val Loss: 0.6959, Test Accuracy: 0.4993 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0782880783081055\n",
      "Epoch 29, Train Loss: 0.6934, Val Loss: 0.6966, Test Accuracy: 0.4967 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.088974952697754\n",
      "Epoch 30, Train Loss: 0.6938, Val Loss: 0.6973, Test Accuracy: 0.4954 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0793728828430176\n",
      "Epoch 31, Train Loss: 0.6920, Val Loss: 0.6977, Test Accuracy: 0.4941 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0921988487243652\n",
      "Epoch 32, Train Loss: 0.6956, Val Loss: 0.6959, Test Accuracy: 0.5059 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0798208713531494\n",
      "Epoch 33, Train Loss: 0.6914, Val Loss: 0.6971, Test Accuracy: 0.5033 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.084157943725586\n",
      "Epoch 34, Train Loss: 0.6925, Val Loss: 0.6978, Test Accuracy: 0.5020 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.081373929977417\n",
      "Epoch 35, Train Loss: 0.6913, Val Loss: 0.6961, Test Accuracy: 0.5046 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0883007049560547\n",
      "Epoch 36, Train Loss: 0.6897, Val Loss: 0.6951, Test Accuracy: 0.5059 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0793259143829346\n",
      "Epoch 37, Train Loss: 0.6907, Val Loss: 0.6969, Test Accuracy: 0.5046 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0804269313812256\n",
      "Epoch 38, Train Loss: 0.6957, Val Loss: 0.6971, Test Accuracy: 0.5059 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0867626667022705\n",
      "Epoch 39, Train Loss: 0.6912, Val Loss: 0.6953, Test Accuracy: 0.5059 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.2686378955841064\n",
      "Epoch 40, Train Loss: 0.6948, Val Loss: 0.6944, Test Accuracy: 0.5085 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0789868831634521\n",
      "Epoch 41, Train Loss: 0.6896, Val Loss: 0.6965, Test Accuracy: 0.5072 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.09437894821167\n",
      "Epoch 42, Train Loss: 0.6896, Val Loss: 0.6974, Test Accuracy: 0.5177 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.083709478378296\n",
      "Epoch 43, Train Loss: 0.6931, Val Loss: 0.6963, Test Accuracy: 0.5046 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0840191841125488\n",
      "Epoch 44, Train Loss: 0.6940, Val Loss: 0.6949, Test Accuracy: 0.5164 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.095205545425415\n",
      "Epoch 45, Train Loss: 0.6908, Val Loss: 0.6958, Test Accuracy: 0.5072 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0835740566253662\n",
      "Epoch 46, Train Loss: 0.6903, Val Loss: 0.6956, Test Accuracy: 0.5164 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0868957042694092\n",
      "Epoch 47, Train Loss: 0.6885, Val Loss: 0.6953, Test Accuracy: 0.5151 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0858149528503418\n",
      "Epoch 48, Train Loss: 0.6877, Val Loss: 0.6949, Test Accuracy: 0.5138 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0926275253295898\n",
      "Epoch 49, Train Loss: 0.6877, Val Loss: 0.6958, Test Accuracy: 0.5190 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.1016995906829834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:57:01,344] Trial 21 finished with value: 0.526867627785059 and parameters: {'HIDDEN_DIMENSION': 117, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.1461258860426837, 'LEARNING_RATE': 0.0001009834801905927}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6888, Val Loss: 0.6966, Test Accuracy: 0.5151 ,Learning Rate: 0.0001009834801905927 , Time Taken : 1.0884308815002441\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 119, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1344994111933855, 'LEARNING_RATE': 0.00013354964626653443}\n",
      "Epoch 1, Train Loss: 0.7810, Val Loss: 0.7100, Test Accuracy: 0.5452 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0850398540496826\n",
      "Epoch 2, Train Loss: 0.7447, Val Loss: 0.7134, Test Accuracy: 0.4915 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.088913917541504\n",
      "Epoch 3, Train Loss: 0.7271, Val Loss: 0.7206, Test Accuracy: 0.4522 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0895540714263916\n",
      "Epoch 4, Train Loss: 0.7206, Val Loss: 0.7190, Test Accuracy: 0.4469 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0884215831756592\n",
      "Epoch 5, Train Loss: 0.7123, Val Loss: 0.7103, Test Accuracy: 0.4469 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0900030136108398\n",
      "Epoch 6, Train Loss: 0.7109, Val Loss: 0.7040, Test Accuracy: 0.4613 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.088912010192871\n",
      "Epoch 7, Train Loss: 0.7043, Val Loss: 0.7006, Test Accuracy: 0.4626 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0901494026184082\n",
      "Epoch 8, Train Loss: 0.7053, Val Loss: 0.6995, Test Accuracy: 0.4600 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0879194736480713\n",
      "Epoch 9, Train Loss: 0.7020, Val Loss: 0.6996, Test Accuracy: 0.4561 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0915334224700928\n",
      "Epoch 10, Train Loss: 0.7018, Val Loss: 0.6986, Test Accuracy: 0.4600 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0838305950164795\n",
      "Epoch 11, Train Loss: 0.7004, Val Loss: 0.6981, Test Accuracy: 0.4574 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0913655757904053\n",
      "Epoch 12, Train Loss: 0.6969, Val Loss: 0.6977, Test Accuracy: 0.4626 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0869178771972656\n",
      "Epoch 13, Train Loss: 0.6964, Val Loss: 0.6983, Test Accuracy: 0.4548 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0854897499084473\n",
      "Epoch 14, Train Loss: 0.6997, Val Loss: 0.6977, Test Accuracy: 0.4509 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0939161777496338\n",
      "Epoch 15, Train Loss: 0.6969, Val Loss: 0.6969, Test Accuracy: 0.4640 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0877230167388916\n",
      "Epoch 16, Train Loss: 0.6958, Val Loss: 0.6966, Test Accuracy: 0.4653 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0835258960723877\n",
      "Epoch 17, Train Loss: 0.6967, Val Loss: 0.6961, Test Accuracy: 0.4771 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0832970142364502\n",
      "Epoch 18, Train Loss: 0.6974, Val Loss: 0.6965, Test Accuracy: 0.4731 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0958833694458008\n",
      "Epoch 19, Train Loss: 0.6963, Val Loss: 0.6964, Test Accuracy: 0.4744 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.08811616897583\n",
      "Epoch 20, Train Loss: 0.6960, Val Loss: 0.6975, Test Accuracy: 0.4718 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.1048340797424316\n",
      "Epoch 21, Train Loss: 0.6947, Val Loss: 0.6976, Test Accuracy: 0.4718 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0863804817199707\n",
      "Epoch 22, Train Loss: 0.6935, Val Loss: 0.6967, Test Accuracy: 0.4797 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0902953147888184\n",
      "Epoch 23, Train Loss: 0.6924, Val Loss: 0.6964, Test Accuracy: 0.4836 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0849206447601318\n",
      "Epoch 24, Train Loss: 0.6939, Val Loss: 0.6963, Test Accuracy: 0.4889 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0878911018371582\n",
      "Epoch 25, Train Loss: 0.6944, Val Loss: 0.6957, Test Accuracy: 0.4875 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0913763046264648\n",
      "Epoch 26, Train Loss: 0.6924, Val Loss: 0.6960, Test Accuracy: 0.4889 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0846765041351318\n",
      "Epoch 27, Train Loss: 0.6922, Val Loss: 0.6971, Test Accuracy: 0.4836 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0887327194213867\n",
      "Epoch 28, Train Loss: 0.6946, Val Loss: 0.6978, Test Accuracy: 0.4810 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0878610610961914\n",
      "Epoch 29, Train Loss: 0.6944, Val Loss: 0.6963, Test Accuracy: 0.4889 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0966954231262207\n",
      "Epoch 30, Train Loss: 0.6933, Val Loss: 0.6955, Test Accuracy: 0.4967 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.090804100036621\n",
      "Epoch 31, Train Loss: 0.6925, Val Loss: 0.6957, Test Accuracy: 0.5007 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0883488655090332\n",
      "Epoch 32, Train Loss: 0.6929, Val Loss: 0.6969, Test Accuracy: 0.4810 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.08561372756958\n",
      "Epoch 33, Train Loss: 0.6927, Val Loss: 0.6959, Test Accuracy: 0.4967 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0957355499267578\n",
      "Epoch 34, Train Loss: 0.6912, Val Loss: 0.6970, Test Accuracy: 0.4862 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.2809123992919922\n",
      "Epoch 35, Train Loss: 0.6924, Val Loss: 0.6969, Test Accuracy: 0.4862 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.089343547821045\n",
      "Epoch 36, Train Loss: 0.6903, Val Loss: 0.6970, Test Accuracy: 0.4823 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0881588459014893\n",
      "Epoch 37, Train Loss: 0.6943, Val Loss: 0.6965, Test Accuracy: 0.4875 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.089054822921753\n",
      "Epoch 38, Train Loss: 0.6910, Val Loss: 0.6962, Test Accuracy: 0.4889 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0824761390686035\n",
      "Epoch 39, Train Loss: 0.6916, Val Loss: 0.6970, Test Accuracy: 0.4823 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0855252742767334\n",
      "Epoch 40, Train Loss: 0.6920, Val Loss: 0.6972, Test Accuracy: 0.4771 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0963118076324463\n",
      "Epoch 41, Train Loss: 0.6893, Val Loss: 0.6965, Test Accuracy: 0.4797 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0910334587097168\n",
      "Epoch 42, Train Loss: 0.6909, Val Loss: 0.6954, Test Accuracy: 0.5020 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0865533351898193\n",
      "Epoch 43, Train Loss: 0.6898, Val Loss: 0.6970, Test Accuracy: 0.4810 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0924649238586426\n",
      "Epoch 44, Train Loss: 0.6898, Val Loss: 0.6978, Test Accuracy: 0.4875 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0825016498565674\n",
      "Epoch 45, Train Loss: 0.6900, Val Loss: 0.6973, Test Accuracy: 0.4954 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.085157871246338\n",
      "Epoch 46, Train Loss: 0.6881, Val Loss: 0.6968, Test Accuracy: 0.5007 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0892870426177979\n",
      "Epoch 47, Train Loss: 0.6901, Val Loss: 0.6973, Test Accuracy: 0.4928 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0837218761444092\n",
      "Epoch 48, Train Loss: 0.6898, Val Loss: 0.6962, Test Accuracy: 0.5033 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0907514095306396\n",
      "Epoch 49, Train Loss: 0.6900, Val Loss: 0.6981, Test Accuracy: 0.4902 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0893354415893555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:57:56,103] Trial 22 finished with value: 0.5032765399737876 and parameters: {'HIDDEN_DIMENSION': 119, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.1344994111933855, 'LEARNING_RATE': 0.00013354964626653443}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6894, Val Loss: 0.6975, Test Accuracy: 0.4875 ,Learning Rate: 0.00013354964626653443 , Time Taken : 1.0875732898712158\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 106, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.17613605580406055, 'LEARNING_RATE': 9.054522114419769e-05}\n",
      "Epoch 1, Train Loss: 0.7779, Val Loss: 0.7450, Test Accuracy: 0.5007 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8313672542572021\n",
      "Epoch 2, Train Loss: 0.7636, Val Loss: 0.7356, Test Accuracy: 0.5098 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8198044300079346\n",
      "Epoch 3, Train Loss: 0.7579, Val Loss: 0.7275, Test Accuracy: 0.5098 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8361217975616455\n",
      "Epoch 4, Train Loss: 0.7483, Val Loss: 0.7235, Test Accuracy: 0.5085 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8257832527160645\n",
      "Epoch 5, Train Loss: 0.7388, Val Loss: 0.7189, Test Accuracy: 0.5177 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8233933448791504\n",
      "Epoch 6, Train Loss: 0.7410, Val Loss: 0.7148, Test Accuracy: 0.5256 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8255984783172607\n",
      "Epoch 7, Train Loss: 0.7328, Val Loss: 0.7136, Test Accuracy: 0.5216 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8214483261108398\n",
      "Epoch 8, Train Loss: 0.7275, Val Loss: 0.7129, Test Accuracy: 0.5216 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8275566101074219\n",
      "Epoch 9, Train Loss: 0.7285, Val Loss: 0.7114, Test Accuracy: 0.5269 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8271927833557129\n",
      "Epoch 10, Train Loss: 0.7221, Val Loss: 0.7085, Test Accuracy: 0.5295 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8227310180664062\n",
      "Epoch 11, Train Loss: 0.7214, Val Loss: 0.7060, Test Accuracy: 0.5334 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8282477855682373\n",
      "Epoch 12, Train Loss: 0.7166, Val Loss: 0.7054, Test Accuracy: 0.5269 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.821162223815918\n",
      "Epoch 13, Train Loss: 0.7166, Val Loss: 0.7053, Test Accuracy: 0.5347 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8234891891479492\n",
      "Epoch 14, Train Loss: 0.7193, Val Loss: 0.7045, Test Accuracy: 0.5334 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.825981616973877\n",
      "Epoch 15, Train Loss: 0.7102, Val Loss: 0.7043, Test Accuracy: 0.5308 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8270444869995117\n",
      "Epoch 16, Train Loss: 0.7121, Val Loss: 0.7038, Test Accuracy: 0.5269 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8197576999664307\n",
      "Epoch 17, Train Loss: 0.7089, Val Loss: 0.7031, Test Accuracy: 0.5321 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8303685188293457\n",
      "Epoch 18, Train Loss: 0.7067, Val Loss: 0.7022, Test Accuracy: 0.5308 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8289821147918701\n",
      "Epoch 19, Train Loss: 0.7094, Val Loss: 0.7016, Test Accuracy: 0.5256 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8205931186676025\n",
      "Epoch 20, Train Loss: 0.7080, Val Loss: 0.7019, Test Accuracy: 0.5216 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8315212726593018\n",
      "Epoch 21, Train Loss: 0.7073, Val Loss: 0.7020, Test Accuracy: 0.5177 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.825575590133667\n",
      "Epoch 22, Train Loss: 0.7117, Val Loss: 0.7015, Test Accuracy: 0.5164 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8339459896087646\n",
      "Epoch 23, Train Loss: 0.7048, Val Loss: 0.7007, Test Accuracy: 0.5203 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8329112529754639\n",
      "Epoch 24, Train Loss: 0.7043, Val Loss: 0.6997, Test Accuracy: 0.5269 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8221316337585449\n",
      "Epoch 25, Train Loss: 0.7059, Val Loss: 0.7000, Test Accuracy: 0.5203 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8285007476806641\n",
      "Epoch 26, Train Loss: 0.7033, Val Loss: 0.7001, Test Accuracy: 0.5177 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8229010105133057\n",
      "Epoch 27, Train Loss: 0.7028, Val Loss: 0.7005, Test Accuracy: 0.5138 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8274078369140625\n",
      "Epoch 28, Train Loss: 0.7052, Val Loss: 0.6995, Test Accuracy: 0.5203 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8367140293121338\n",
      "Epoch 29, Train Loss: 0.7082, Val Loss: 0.6986, Test Accuracy: 0.5190 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8307995796203613\n",
      "Epoch 30, Train Loss: 0.7044, Val Loss: 0.6996, Test Accuracy: 0.5164 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8219888210296631\n",
      "Epoch 31, Train Loss: 0.7010, Val Loss: 0.6988, Test Accuracy: 0.5177 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8285973072052002\n",
      "Epoch 32, Train Loss: 0.7009, Val Loss: 0.7008, Test Accuracy: 0.5059 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8282153606414795\n",
      "Epoch 33, Train Loss: 0.7081, Val Loss: 0.7003, Test Accuracy: 0.5072 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8265769481658936\n",
      "Epoch 34, Train Loss: 0.7007, Val Loss: 0.6990, Test Accuracy: 0.5125 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8216419219970703\n",
      "Epoch 35, Train Loss: 0.7010, Val Loss: 0.6985, Test Accuracy: 0.5098 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8263683319091797\n",
      "Epoch 36, Train Loss: 0.7047, Val Loss: 0.6987, Test Accuracy: 0.5085 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8281705379486084\n",
      "Epoch 37, Train Loss: 0.6997, Val Loss: 0.6990, Test Accuracy: 0.5072 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8249955177307129\n",
      "Epoch 38, Train Loss: 0.7015, Val Loss: 0.6986, Test Accuracy: 0.5085 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8259725570678711\n",
      "Epoch 39, Train Loss: 0.7004, Val Loss: 0.6984, Test Accuracy: 0.5098 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8346176147460938\n",
      "Epoch 40, Train Loss: 0.6995, Val Loss: 0.6983, Test Accuracy: 0.5098 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.81911301612854\n",
      "Epoch 41, Train Loss: 0.6987, Val Loss: 0.6976, Test Accuracy: 0.5151 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.820594310760498\n",
      "Epoch 42, Train Loss: 0.6981, Val Loss: 0.6988, Test Accuracy: 0.5033 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8279788494110107\n",
      "Epoch 43, Train Loss: 0.7003, Val Loss: 0.6995, Test Accuracy: 0.4954 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8185715675354004\n",
      "Epoch 44, Train Loss: 0.6971, Val Loss: 0.6984, Test Accuracy: 0.5046 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8289153575897217\n",
      "Epoch 45, Train Loss: 0.6986, Val Loss: 0.6979, Test Accuracy: 0.5085 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8219778537750244\n",
      "Epoch 46, Train Loss: 0.6920, Val Loss: 0.6977, Test Accuracy: 0.5072 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8352677822113037\n",
      "Epoch 47, Train Loss: 0.6934, Val Loss: 0.6977, Test Accuracy: 0.5085 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8194475173950195\n",
      "Epoch 48, Train Loss: 0.6956, Val Loss: 0.6973, Test Accuracy: 0.5059 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8325033187866211\n",
      "Epoch 49, Train Loss: 0.6958, Val Loss: 0.6984, Test Accuracy: 0.5020 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8225150108337402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:58:37,532] Trial 23 finished with value: 0.5019659239842726 and parameters: {'HIDDEN_DIMENSION': 106, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'DROP_OUT': 0.17613605580406055, 'LEARNING_RATE': 9.054522114419769e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6969, Val Loss: 0.6987, Test Accuracy: 0.5020 ,Learning Rate: 9.054522114419769e-05 , Time Taken : 0.8282363414764404\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 120, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1011439294131398, 'LEARNING_RATE': 0.00015307718932068914}\n",
      "Epoch 1, Train Loss: 0.8399, Val Loss: 0.8707, Test Accuracy: 0.4273 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0865750312805176\n",
      "Epoch 2, Train Loss: 0.7804, Val Loss: 0.7894, Test Accuracy: 0.4600 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0860085487365723\n",
      "Epoch 3, Train Loss: 0.7577, Val Loss: 0.7488, Test Accuracy: 0.4967 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.095583438873291\n",
      "Epoch 4, Train Loss: 0.7370, Val Loss: 0.7322, Test Accuracy: 0.5072 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0843815803527832\n",
      "Epoch 5, Train Loss: 0.7283, Val Loss: 0.7254, Test Accuracy: 0.5007 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0858004093170166\n",
      "Epoch 6, Train Loss: 0.7193, Val Loss: 0.7229, Test Accuracy: 0.5007 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.082899808883667\n",
      "Epoch 7, Train Loss: 0.7148, Val Loss: 0.7193, Test Accuracy: 0.4967 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0826671123504639\n",
      "Epoch 8, Train Loss: 0.7110, Val Loss: 0.7127, Test Accuracy: 0.5059 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.085134506225586\n",
      "Epoch 9, Train Loss: 0.7089, Val Loss: 0.7098, Test Accuracy: 0.5085 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0825183391571045\n",
      "Epoch 10, Train Loss: 0.7042, Val Loss: 0.7070, Test Accuracy: 0.5151 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.089540958404541\n",
      "Epoch 11, Train Loss: 0.7017, Val Loss: 0.7062, Test Accuracy: 0.5072 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0819003582000732\n",
      "Epoch 12, Train Loss: 0.7014, Val Loss: 0.7059, Test Accuracy: 0.5046 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0919544696807861\n",
      "Epoch 13, Train Loss: 0.6965, Val Loss: 0.7021, Test Accuracy: 0.5085 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0888874530792236\n",
      "Epoch 14, Train Loss: 0.7005, Val Loss: 0.7024, Test Accuracy: 0.5033 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.2621490955352783\n",
      "Epoch 15, Train Loss: 0.6974, Val Loss: 0.7010, Test Accuracy: 0.5072 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0889184474945068\n",
      "Epoch 16, Train Loss: 0.6969, Val Loss: 0.7013, Test Accuracy: 0.5046 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0860264301300049\n",
      "Epoch 17, Train Loss: 0.6965, Val Loss: 0.7004, Test Accuracy: 0.5046 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0876364707946777\n",
      "Epoch 18, Train Loss: 0.6965, Val Loss: 0.7006, Test Accuracy: 0.4980 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.097703456878662\n",
      "Epoch 19, Train Loss: 0.6966, Val Loss: 0.6988, Test Accuracy: 0.5072 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.089489459991455\n",
      "Epoch 20, Train Loss: 0.6984, Val Loss: 0.7004, Test Accuracy: 0.4980 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0897700786590576\n",
      "Epoch 21, Train Loss: 0.6979, Val Loss: 0.7004, Test Accuracy: 0.5033 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.081700086593628\n",
      "Epoch 22, Train Loss: 0.6948, Val Loss: 0.6991, Test Accuracy: 0.5046 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0935032367706299\n",
      "Epoch 23, Train Loss: 0.6946, Val Loss: 0.6979, Test Accuracy: 0.5059 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0913426876068115\n",
      "Epoch 24, Train Loss: 0.6935, Val Loss: 0.6986, Test Accuracy: 0.4993 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0839781761169434\n",
      "Epoch 25, Train Loss: 0.6953, Val Loss: 0.6982, Test Accuracy: 0.5059 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0918996334075928\n",
      "Epoch 26, Train Loss: 0.6944, Val Loss: 0.6995, Test Accuracy: 0.4954 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0914289951324463\n",
      "Epoch 27, Train Loss: 0.6928, Val Loss: 0.6991, Test Accuracy: 0.4967 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0840518474578857\n",
      "Epoch 28, Train Loss: 0.6915, Val Loss: 0.6979, Test Accuracy: 0.5059 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.085275411605835\n",
      "Epoch 29, Train Loss: 0.6929, Val Loss: 0.6964, Test Accuracy: 0.5111 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0984337329864502\n",
      "Epoch 30, Train Loss: 0.6907, Val Loss: 0.6980, Test Accuracy: 0.4980 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0912106037139893\n",
      "Epoch 31, Train Loss: 0.6915, Val Loss: 0.6992, Test Accuracy: 0.5033 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0951769351959229\n",
      "Epoch 32, Train Loss: 0.6902, Val Loss: 0.7003, Test Accuracy: 0.4993 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0896046161651611\n",
      "Epoch 33, Train Loss: 0.6897, Val Loss: 0.6980, Test Accuracy: 0.4954 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0861718654632568\n",
      "Epoch 34, Train Loss: 0.6889, Val Loss: 0.6974, Test Accuracy: 0.5072 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0962212085723877\n",
      "Epoch 35, Train Loss: 0.6905, Val Loss: 0.6979, Test Accuracy: 0.5033 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0907115936279297\n",
      "Epoch 36, Train Loss: 0.6878, Val Loss: 0.6995, Test Accuracy: 0.4993 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0918445587158203\n",
      "Epoch 37, Train Loss: 0.6885, Val Loss: 0.6991, Test Accuracy: 0.5072 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0865418910980225\n",
      "Epoch 38, Train Loss: 0.6914, Val Loss: 0.6975, Test Accuracy: 0.5138 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.094916820526123\n",
      "Epoch 39, Train Loss: 0.6898, Val Loss: 0.6980, Test Accuracy: 0.5125 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0885426998138428\n",
      "Epoch 40, Train Loss: 0.6895, Val Loss: 0.6999, Test Accuracy: 0.5033 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.085313320159912\n",
      "Epoch 41, Train Loss: 0.6876, Val Loss: 0.6987, Test Accuracy: 0.5072 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.095353364944458\n",
      "Epoch 42, Train Loss: 0.6892, Val Loss: 0.6984, Test Accuracy: 0.5111 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0897891521453857\n",
      "Epoch 43, Train Loss: 0.6884, Val Loss: 0.6988, Test Accuracy: 0.5138 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0844614505767822\n",
      "Epoch 44, Train Loss: 0.6896, Val Loss: 0.6977, Test Accuracy: 0.5190 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.090745210647583\n",
      "Epoch 45, Train Loss: 0.6875, Val Loss: 0.6998, Test Accuracy: 0.5138 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.098660945892334\n",
      "Epoch 46, Train Loss: 0.6887, Val Loss: 0.7007, Test Accuracy: 0.5138 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0864393711090088\n",
      "Epoch 47, Train Loss: 0.6850, Val Loss: 0.6972, Test Accuracy: 0.5269 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0902340412139893\n",
      "Epoch 48, Train Loss: 0.6864, Val Loss: 0.6992, Test Accuracy: 0.5229 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.087512731552124\n",
      "Epoch 49, Train Loss: 0.6866, Val Loss: 0.7005, Test Accuracy: 0.5256 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.0973095893859863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 06:59:32,292] Trial 24 finished with value: 0.5478374836173001 and parameters: {'HIDDEN_DIMENSION': 120, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.1011439294131398, 'LEARNING_RATE': 0.00015307718932068914}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6862, Val Loss: 0.6992, Test Accuracy: 0.5256 ,Learning Rate: 0.00015307718932068914 , Time Taken : 1.088275671005249\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 99, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.2136682147159974, 'LEARNING_RATE': 0.000260702630165197}\n",
      "Epoch 1, Train Loss: 0.7987, Val Loss: 0.7362, Test Accuracy: 0.5072 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8292841911315918\n",
      "Epoch 2, Train Loss: 0.7604, Val Loss: 0.7092, Test Accuracy: 0.5242 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8323554992675781\n",
      "Epoch 3, Train Loss: 0.7365, Val Loss: 0.7029, Test Accuracy: 0.5020 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8258419036865234\n",
      "Epoch 4, Train Loss: 0.7215, Val Loss: 0.7017, Test Accuracy: 0.4889 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8307368755340576\n",
      "Epoch 5, Train Loss: 0.7228, Val Loss: 0.6996, Test Accuracy: 0.4928 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8250381946563721\n",
      "Epoch 6, Train Loss: 0.7130, Val Loss: 0.6914, Test Accuracy: 0.5229 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8272891044616699\n",
      "Epoch 7, Train Loss: 0.7114, Val Loss: 0.6937, Test Accuracy: 0.5020 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8333747386932373\n",
      "Epoch 8, Train Loss: 0.7056, Val Loss: 0.6926, Test Accuracy: 0.5138 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8277137279510498\n",
      "Epoch 9, Train Loss: 0.7062, Val Loss: 0.6937, Test Accuracy: 0.5072 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.829625129699707\n",
      "Epoch 10, Train Loss: 0.7026, Val Loss: 0.6944, Test Accuracy: 0.5046 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8335781097412109\n",
      "Epoch 11, Train Loss: 0.7007, Val Loss: 0.6944, Test Accuracy: 0.5033 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8209643363952637\n",
      "Epoch 12, Train Loss: 0.7012, Val Loss: 0.6923, Test Accuracy: 0.5085 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8261220455169678\n",
      "Epoch 13, Train Loss: 0.6978, Val Loss: 0.6929, Test Accuracy: 0.5046 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8201963901519775\n",
      "Epoch 14, Train Loss: 0.6950, Val Loss: 0.6931, Test Accuracy: 0.5059 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.9973263740539551\n",
      "Epoch 15, Train Loss: 0.6944, Val Loss: 0.6943, Test Accuracy: 0.5059 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8185391426086426\n",
      "Epoch 16, Train Loss: 0.6920, Val Loss: 0.6900, Test Accuracy: 0.5164 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8185267448425293\n",
      "Epoch 17, Train Loss: 0.6950, Val Loss: 0.6922, Test Accuracy: 0.5164 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8285787105560303\n",
      "Epoch 18, Train Loss: 0.6903, Val Loss: 0.6948, Test Accuracy: 0.5085 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8223745822906494\n",
      "Epoch 19, Train Loss: 0.6927, Val Loss: 0.6944, Test Accuracy: 0.5125 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8305809497833252\n",
      "Epoch 20, Train Loss: 0.6896, Val Loss: 0.6918, Test Accuracy: 0.5190 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8280982971191406\n",
      "Epoch 21, Train Loss: 0.6937, Val Loss: 0.6950, Test Accuracy: 0.5046 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8278965950012207\n",
      "Epoch 22, Train Loss: 0.6899, Val Loss: 0.6928, Test Accuracy: 0.5125 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8301348686218262\n",
      "Epoch 23, Train Loss: 0.6918, Val Loss: 0.6937, Test Accuracy: 0.5138 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8232772350311279\n",
      "Epoch 24, Train Loss: 0.6879, Val Loss: 0.6942, Test Accuracy: 0.5111 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8222978115081787\n",
      "Epoch 25, Train Loss: 0.6896, Val Loss: 0.6913, Test Accuracy: 0.5360 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8241961002349854\n",
      "Epoch 26, Train Loss: 0.6888, Val Loss: 0.6923, Test Accuracy: 0.5334 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8217673301696777\n",
      "Epoch 27, Train Loss: 0.6908, Val Loss: 0.6947, Test Accuracy: 0.5125 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8243143558502197\n",
      "Epoch 28, Train Loss: 0.6883, Val Loss: 0.6981, Test Accuracy: 0.4954 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8255043029785156\n",
      "Epoch 29, Train Loss: 0.6885, Val Loss: 0.6928, Test Accuracy: 0.5387 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8246650695800781\n",
      "Epoch 30, Train Loss: 0.6870, Val Loss: 0.6916, Test Accuracy: 0.5426 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8281757831573486\n",
      "Epoch 31, Train Loss: 0.6877, Val Loss: 0.6934, Test Accuracy: 0.5334 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8247241973876953\n",
      "Epoch 32, Train Loss: 0.6872, Val Loss: 0.6939, Test Accuracy: 0.5229 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8254520893096924\n",
      "Epoch 33, Train Loss: 0.6875, Val Loss: 0.6953, Test Accuracy: 0.5125 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.824378252029419\n",
      "Epoch 34, Train Loss: 0.6872, Val Loss: 0.6956, Test Accuracy: 0.5177 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8307209014892578\n",
      "Epoch 35, Train Loss: 0.6864, Val Loss: 0.6905, Test Accuracy: 0.5491 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8414249420166016\n",
      "Epoch 36, Train Loss: 0.6853, Val Loss: 0.6934, Test Accuracy: 0.5269 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8166790008544922\n",
      "Epoch 37, Train Loss: 0.6859, Val Loss: 0.6972, Test Accuracy: 0.5177 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8316934108734131\n",
      "Epoch 38, Train Loss: 0.6859, Val Loss: 0.6937, Test Accuracy: 0.5269 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8308722972869873\n",
      "Epoch 39, Train Loss: 0.6854, Val Loss: 0.6921, Test Accuracy: 0.5374 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8234591484069824\n",
      "Epoch 40, Train Loss: 0.6861, Val Loss: 0.6958, Test Accuracy: 0.5125 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.824974775314331\n",
      "Epoch 41, Train Loss: 0.6858, Val Loss: 0.6933, Test Accuracy: 0.5321 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8254408836364746\n",
      "Epoch 42, Train Loss: 0.6834, Val Loss: 0.6934, Test Accuracy: 0.5308 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8283469676971436\n",
      "Epoch 43, Train Loss: 0.6846, Val Loss: 0.6960, Test Accuracy: 0.5216 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8263750076293945\n",
      "Epoch 44, Train Loss: 0.6855, Val Loss: 0.6944, Test Accuracy: 0.5308 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8309822082519531\n",
      "Epoch 45, Train Loss: 0.6850, Val Loss: 0.6948, Test Accuracy: 0.5269 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8264474868774414\n",
      "Epoch 46, Train Loss: 0.6835, Val Loss: 0.6930, Test Accuracy: 0.5347 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8268206119537354\n",
      "Epoch 47, Train Loss: 0.6837, Val Loss: 0.6960, Test Accuracy: 0.5203 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8280444145202637\n",
      "Epoch 48, Train Loss: 0.6817, Val Loss: 0.6931, Test Accuracy: 0.5321 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.81787109375\n",
      "Epoch 49, Train Loss: 0.6829, Val Loss: 0.6909, Test Accuracy: 0.5426 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.828411340713501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:00:13,894] Trial 25 finished with value: 0.528178243774574 and parameters: {'HIDDEN_DIMENSION': 99, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'DROP_OUT': 0.2136682147159974, 'LEARNING_RATE': 0.000260702630165197}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6816, Val Loss: 0.6992, Test Accuracy: 0.5164 ,Learning Rate: 0.000260702630165197 , Time Taken : 0.8224649429321289\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 110, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.16039482873209734, 'LEARNING_RATE': 9.755580592761627e-05}\n",
      "Epoch 1, Train Loss: 0.7692, Val Loss: 0.7621, Test Accuracy: 0.4731 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.85516357421875\n",
      "Epoch 2, Train Loss: 0.7392, Val Loss: 0.7395, Test Accuracy: 0.4758 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8605124950408936\n",
      "Epoch 3, Train Loss: 0.7229, Val Loss: 0.7276, Test Accuracy: 0.4915 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8603775501251221\n",
      "Epoch 4, Train Loss: 0.7155, Val Loss: 0.7221, Test Accuracy: 0.4889 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8649723529815674\n",
      "Epoch 5, Train Loss: 0.7122, Val Loss: 0.7149, Test Accuracy: 0.4889 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8589119911193848\n",
      "Epoch 6, Train Loss: 0.7106, Val Loss: 0.7106, Test Accuracy: 0.4849 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8586153984069824\n",
      "Epoch 7, Train Loss: 0.7080, Val Loss: 0.7100, Test Accuracy: 0.4784 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8634753227233887\n",
      "Epoch 8, Train Loss: 0.7032, Val Loss: 0.7047, Test Accuracy: 0.4954 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8635299205780029\n",
      "Epoch 9, Train Loss: 0.7016, Val Loss: 0.7064, Test Accuracy: 0.4797 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8650081157684326\n",
      "Epoch 10, Train Loss: 0.6974, Val Loss: 0.7024, Test Accuracy: 0.4836 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8646647930145264\n",
      "Epoch 11, Train Loss: 0.6963, Val Loss: 0.7025, Test Accuracy: 0.4784 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8664627075195312\n",
      "Epoch 12, Train Loss: 0.6981, Val Loss: 0.7014, Test Accuracy: 0.4810 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8682115077972412\n",
      "Epoch 13, Train Loss: 0.6943, Val Loss: 0.7030, Test Accuracy: 0.4705 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8679015636444092\n",
      "Epoch 14, Train Loss: 0.6939, Val Loss: 0.6982, Test Accuracy: 0.4810 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8624799251556396\n",
      "Epoch 15, Train Loss: 0.6909, Val Loss: 0.6988, Test Accuracy: 0.4758 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8595471382141113\n",
      "Epoch 16, Train Loss: 0.6901, Val Loss: 0.6981, Test Accuracy: 0.4771 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8637692928314209\n",
      "Epoch 17, Train Loss: 0.6923, Val Loss: 0.7015, Test Accuracy: 0.4679 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8602449893951416\n",
      "Epoch 18, Train Loss: 0.6895, Val Loss: 0.6982, Test Accuracy: 0.4823 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8616924285888672\n",
      "Epoch 19, Train Loss: 0.6914, Val Loss: 0.6985, Test Accuracy: 0.4731 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8646085262298584\n",
      "Epoch 20, Train Loss: 0.6892, Val Loss: 0.6971, Test Accuracy: 0.4836 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8659958839416504\n",
      "Epoch 21, Train Loss: 0.6911, Val Loss: 0.6966, Test Accuracy: 0.4862 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8490989208221436\n",
      "Epoch 22, Train Loss: 0.6890, Val Loss: 0.6964, Test Accuracy: 0.4836 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8601925373077393\n",
      "Epoch 23, Train Loss: 0.6864, Val Loss: 0.6976, Test Accuracy: 0.4889 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8646619319915771\n",
      "Epoch 24, Train Loss: 0.6872, Val Loss: 0.6955, Test Accuracy: 0.4928 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8631179332733154\n",
      "Epoch 25, Train Loss: 0.6881, Val Loss: 0.6936, Test Accuracy: 0.5059 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8625004291534424\n",
      "Epoch 26, Train Loss: 0.6873, Val Loss: 0.6972, Test Accuracy: 0.4875 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8676331043243408\n",
      "Epoch 27, Train Loss: 0.6867, Val Loss: 0.6956, Test Accuracy: 0.5085 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8687169551849365\n",
      "Epoch 28, Train Loss: 0.6838, Val Loss: 0.6966, Test Accuracy: 0.4993 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8633031845092773\n",
      "Epoch 29, Train Loss: 0.6848, Val Loss: 0.6970, Test Accuracy: 0.5020 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8691775798797607\n",
      "Epoch 30, Train Loss: 0.6844, Val Loss: 0.6947, Test Accuracy: 0.5125 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8672490119934082\n",
      "Epoch 31, Train Loss: 0.6833, Val Loss: 0.6970, Test Accuracy: 0.5020 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.865088701248169\n",
      "Epoch 32, Train Loss: 0.6846, Val Loss: 0.6933, Test Accuracy: 0.5164 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8634586334228516\n",
      "Epoch 33, Train Loss: 0.6843, Val Loss: 0.6955, Test Accuracy: 0.5059 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8621680736541748\n",
      "Epoch 34, Train Loss: 0.6831, Val Loss: 0.6971, Test Accuracy: 0.4980 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8644886016845703\n",
      "Epoch 35, Train Loss: 0.6824, Val Loss: 0.6975, Test Accuracy: 0.4954 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.864722490310669\n",
      "Epoch 36, Train Loss: 0.6848, Val Loss: 0.6954, Test Accuracy: 0.5046 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8646819591522217\n",
      "Epoch 37, Train Loss: 0.6817, Val Loss: 0.6951, Test Accuracy: 0.5098 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8557775020599365\n",
      "Epoch 38, Train Loss: 0.6823, Val Loss: 0.6993, Test Accuracy: 0.5072 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8571851253509521\n",
      "Epoch 39, Train Loss: 0.6826, Val Loss: 0.6945, Test Accuracy: 0.5098 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8574442863464355\n",
      "Epoch 40, Train Loss: 0.6796, Val Loss: 0.6967, Test Accuracy: 0.5007 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8614151477813721\n",
      "Epoch 41, Train Loss: 0.6814, Val Loss: 0.6954, Test Accuracy: 0.5007 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8573882579803467\n",
      "Epoch 42, Train Loss: 0.6798, Val Loss: 0.6940, Test Accuracy: 0.5046 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8607759475708008\n",
      "Epoch 43, Train Loss: 0.6771, Val Loss: 0.6977, Test Accuracy: 0.5020 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8588523864746094\n",
      "Epoch 44, Train Loss: 0.6793, Val Loss: 0.6984, Test Accuracy: 0.5046 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8568556308746338\n",
      "Epoch 45, Train Loss: 0.6785, Val Loss: 0.6939, Test Accuracy: 0.5151 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8589327335357666\n",
      "Epoch 46, Train Loss: 0.6778, Val Loss: 0.6958, Test Accuracy: 0.5059 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8578159809112549\n",
      "Epoch 47, Train Loss: 0.6765, Val Loss: 0.6973, Test Accuracy: 0.5046 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.856135368347168\n",
      "Epoch 48, Train Loss: 0.6783, Val Loss: 0.6954, Test Accuracy: 0.5098 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8559541702270508\n",
      "Epoch 49, Train Loss: 0.6768, Val Loss: 0.6955, Test Accuracy: 0.5085 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8612957000732422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:00:57,066] Trial 26 finished with value: 0.5543905635648755 and parameters: {'HIDDEN_DIMENSION': 110, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'DROP_OUT': 0.16039482873209734, 'LEARNING_RATE': 9.755580592761627e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6761, Val Loss: 0.6970, Test Accuracy: 0.5072 ,Learning Rate: 9.755580592761627e-05 , Time Taken : 0.8429453372955322\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 89, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.18465365932638478, 'LEARNING_RATE': 5.97886952237634e-05}\n",
      "Epoch 1, Train Loss: 0.7322, Val Loss: 0.7125, Test Accuracy: 0.4941 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.079500675201416\n",
      "Epoch 2, Train Loss: 0.7223, Val Loss: 0.7078, Test Accuracy: 0.4941 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0754635334014893\n",
      "Epoch 3, Train Loss: 0.7247, Val Loss: 0.7060, Test Accuracy: 0.4928 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.073791742324829\n",
      "Epoch 4, Train Loss: 0.7254, Val Loss: 0.7033, Test Accuracy: 0.5020 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0772438049316406\n",
      "Epoch 5, Train Loss: 0.7203, Val Loss: 0.7008, Test Accuracy: 0.5046 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0709540843963623\n",
      "Epoch 6, Train Loss: 0.7251, Val Loss: 0.6987, Test Accuracy: 0.5138 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0747706890106201\n",
      "Epoch 7, Train Loss: 0.7209, Val Loss: 0.6976, Test Accuracy: 0.5242 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0798861980438232\n",
      "Epoch 8, Train Loss: 0.7195, Val Loss: 0.6962, Test Accuracy: 0.5269 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0657284259796143\n",
      "Epoch 9, Train Loss: 0.7137, Val Loss: 0.6959, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0746862888336182\n",
      "Epoch 10, Train Loss: 0.7177, Val Loss: 0.6952, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.076615571975708\n",
      "Epoch 11, Train Loss: 0.7192, Val Loss: 0.6954, Test Accuracy: 0.5295 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0706422328948975\n",
      "Epoch 12, Train Loss: 0.7105, Val Loss: 0.6951, Test Accuracy: 0.5295 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0722765922546387\n",
      "Epoch 13, Train Loss: 0.7151, Val Loss: 0.6955, Test Accuracy: 0.5269 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.066845417022705\n",
      "Epoch 14, Train Loss: 0.7137, Val Loss: 0.6941, Test Accuracy: 0.5374 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0708913803100586\n",
      "Epoch 15, Train Loss: 0.7115, Val Loss: 0.6938, Test Accuracy: 0.5334 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0636918544769287\n",
      "Epoch 16, Train Loss: 0.7106, Val Loss: 0.6935, Test Accuracy: 0.5374 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.074352741241455\n",
      "Epoch 17, Train Loss: 0.7048, Val Loss: 0.6940, Test Accuracy: 0.5295 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0645034313201904\n",
      "Epoch 18, Train Loss: 0.7088, Val Loss: 0.6935, Test Accuracy: 0.5347 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0650944709777832\n",
      "Epoch 19, Train Loss: 0.7103, Val Loss: 0.6923, Test Accuracy: 0.5426 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0698566436767578\n",
      "Epoch 20, Train Loss: 0.7093, Val Loss: 0.6924, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0689215660095215\n",
      "Epoch 21, Train Loss: 0.7042, Val Loss: 0.6927, Test Accuracy: 0.5347 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0708482265472412\n",
      "Epoch 22, Train Loss: 0.7058, Val Loss: 0.6932, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.069762945175171\n",
      "Epoch 23, Train Loss: 0.7041, Val Loss: 0.6939, Test Accuracy: 0.5256 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.073042631149292\n",
      "Epoch 24, Train Loss: 0.7032, Val Loss: 0.6937, Test Accuracy: 0.5229 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0722167491912842\n",
      "Epoch 25, Train Loss: 0.7022, Val Loss: 0.6929, Test Accuracy: 0.5242 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.2437829971313477\n",
      "Epoch 26, Train Loss: 0.7035, Val Loss: 0.6932, Test Accuracy: 0.5229 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0668103694915771\n",
      "Epoch 27, Train Loss: 0.7046, Val Loss: 0.6932, Test Accuracy: 0.5242 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0627622604370117\n",
      "Epoch 28, Train Loss: 0.7029, Val Loss: 0.6928, Test Accuracy: 0.5269 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.076650619506836\n",
      "Epoch 29, Train Loss: 0.7019, Val Loss: 0.6927, Test Accuracy: 0.5269 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0704140663146973\n",
      "Epoch 30, Train Loss: 0.6981, Val Loss: 0.6929, Test Accuracy: 0.5256 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0729172229766846\n",
      "Epoch 31, Train Loss: 0.7016, Val Loss: 0.6934, Test Accuracy: 0.5229 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0681161880493164\n",
      "Epoch 32, Train Loss: 0.6994, Val Loss: 0.6926, Test Accuracy: 0.5269 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0712244510650635\n",
      "Epoch 33, Train Loss: 0.7019, Val Loss: 0.6926, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.083733081817627\n",
      "Epoch 34, Train Loss: 0.7014, Val Loss: 0.6925, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0708720684051514\n",
      "Epoch 35, Train Loss: 0.6975, Val Loss: 0.6925, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.06392502784729\n",
      "Epoch 36, Train Loss: 0.6981, Val Loss: 0.6926, Test Accuracy: 0.5242 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0770316123962402\n",
      "Epoch 37, Train Loss: 0.7000, Val Loss: 0.6931, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0788674354553223\n",
      "Epoch 38, Train Loss: 0.6988, Val Loss: 0.6926, Test Accuracy: 0.5256 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0757293701171875\n",
      "Epoch 39, Train Loss: 0.6988, Val Loss: 0.6924, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.057344913482666\n",
      "Epoch 40, Train Loss: 0.6967, Val Loss: 0.6923, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0693519115447998\n",
      "Epoch 41, Train Loss: 0.6951, Val Loss: 0.6925, Test Accuracy: 0.5295 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0735907554626465\n",
      "Epoch 42, Train Loss: 0.6987, Val Loss: 0.6925, Test Accuracy: 0.5308 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0703370571136475\n",
      "Epoch 43, Train Loss: 0.6962, Val Loss: 0.6924, Test Accuracy: 0.5360 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0711135864257812\n",
      "Epoch 44, Train Loss: 0.6986, Val Loss: 0.6919, Test Accuracy: 0.5374 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0682365894317627\n",
      "Epoch 45, Train Loss: 0.6963, Val Loss: 0.6921, Test Accuracy: 0.5400 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0630877017974854\n",
      "Epoch 46, Train Loss: 0.6986, Val Loss: 0.6919, Test Accuracy: 0.5400 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0767595767974854\n",
      "Epoch 47, Train Loss: 0.6943, Val Loss: 0.6923, Test Accuracy: 0.5413 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0741450786590576\n",
      "Epoch 48, Train Loss: 0.6955, Val Loss: 0.6933, Test Accuracy: 0.5282 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0744495391845703\n",
      "Epoch 49, Train Loss: 0.6963, Val Loss: 0.6922, Test Accuracy: 0.5400 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0718848705291748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:01:50,940] Trial 27 finished with value: 0.5674967234600262 and parameters: {'HIDDEN_DIMENSION': 89, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.18465365932638478, 'LEARNING_RATE': 5.97886952237634e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6988, Val Loss: 0.6918, Test Accuracy: 0.5413 ,Learning Rate: 5.97886952237634e-05 , Time Taken : 1.0738139152526855\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 87, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.231052536609148, 'LEARNING_RATE': 3.624453181349348e-05}\n",
      "Epoch 1, Train Loss: 0.7974, Val Loss: 0.8320, Test Accuracy: 0.4050 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8140149116516113\n",
      "Epoch 2, Train Loss: 0.7908, Val Loss: 0.8190, Test Accuracy: 0.4063 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8175449371337891\n",
      "Epoch 3, Train Loss: 0.7769, Val Loss: 0.8074, Test Accuracy: 0.4024 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8229284286499023\n",
      "Epoch 4, Train Loss: 0.7755, Val Loss: 0.7973, Test Accuracy: 0.4050 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8194241523742676\n",
      "Epoch 5, Train Loss: 0.7730, Val Loss: 0.7882, Test Accuracy: 0.4076 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8098592758178711\n",
      "Epoch 6, Train Loss: 0.7711, Val Loss: 0.7799, Test Accuracy: 0.4220 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8126645088195801\n",
      "Epoch 7, Train Loss: 0.7575, Val Loss: 0.7732, Test Accuracy: 0.4233 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8175082206726074\n",
      "Epoch 8, Train Loss: 0.7582, Val Loss: 0.7671, Test Accuracy: 0.4312 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8234987258911133\n",
      "Epoch 9, Train Loss: 0.7574, Val Loss: 0.7623, Test Accuracy: 0.4325 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8155286312103271\n",
      "Epoch 10, Train Loss: 0.7524, Val Loss: 0.7578, Test Accuracy: 0.4299 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8236441612243652\n",
      "Epoch 11, Train Loss: 0.7512, Val Loss: 0.7536, Test Accuracy: 0.4391 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8192541599273682\n",
      "Epoch 12, Train Loss: 0.7484, Val Loss: 0.7500, Test Accuracy: 0.4404 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8159863948822021\n",
      "Epoch 13, Train Loss: 0.7545, Val Loss: 0.7469, Test Accuracy: 0.4364 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8287091255187988\n",
      "Epoch 14, Train Loss: 0.7474, Val Loss: 0.7442, Test Accuracy: 0.4351 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8223319053649902\n",
      "Epoch 15, Train Loss: 0.7459, Val Loss: 0.7417, Test Accuracy: 0.4417 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8196744918823242\n",
      "Epoch 16, Train Loss: 0.7417, Val Loss: 0.7395, Test Accuracy: 0.4430 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8113577365875244\n",
      "Epoch 17, Train Loss: 0.7421, Val Loss: 0.7375, Test Accuracy: 0.4430 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8187854290008545\n",
      "Epoch 18, Train Loss: 0.7391, Val Loss: 0.7354, Test Accuracy: 0.4417 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8131020069122314\n",
      "Epoch 19, Train Loss: 0.7319, Val Loss: 0.7336, Test Accuracy: 0.4417 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8142714500427246\n",
      "Epoch 20, Train Loss: 0.7379, Val Loss: 0.7323, Test Accuracy: 0.4443 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8175528049468994\n",
      "Epoch 21, Train Loss: 0.7350, Val Loss: 0.7307, Test Accuracy: 0.4443 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8191978931427002\n",
      "Epoch 22, Train Loss: 0.7356, Val Loss: 0.7289, Test Accuracy: 0.4469 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.816077470779419\n",
      "Epoch 23, Train Loss: 0.7306, Val Loss: 0.7276, Test Accuracy: 0.4469 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8169200420379639\n",
      "Epoch 24, Train Loss: 0.7367, Val Loss: 0.7263, Test Accuracy: 0.4456 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8222947120666504\n",
      "Epoch 25, Train Loss: 0.7269, Val Loss: 0.7254, Test Accuracy: 0.4430 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8101904392242432\n",
      "Epoch 26, Train Loss: 0.7237, Val Loss: 0.7243, Test Accuracy: 0.4456 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8215177059173584\n",
      "Epoch 27, Train Loss: 0.7291, Val Loss: 0.7233, Test Accuracy: 0.4456 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8235964775085449\n",
      "Epoch 28, Train Loss: 0.7309, Val Loss: 0.7224, Test Accuracy: 0.4417 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8123860359191895\n",
      "Epoch 29, Train Loss: 0.7249, Val Loss: 0.7215, Test Accuracy: 0.4404 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8151705265045166\n",
      "Epoch 30, Train Loss: 0.7257, Val Loss: 0.7204, Test Accuracy: 0.4391 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8180716037750244\n",
      "Epoch 31, Train Loss: 0.7252, Val Loss: 0.7196, Test Accuracy: 0.4404 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8204727172851562\n",
      "Epoch 32, Train Loss: 0.7269, Val Loss: 0.7187, Test Accuracy: 0.4430 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8141000270843506\n",
      "Epoch 33, Train Loss: 0.7212, Val Loss: 0.7180, Test Accuracy: 0.4430 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8176982402801514\n",
      "Epoch 34, Train Loss: 0.7212, Val Loss: 0.7171, Test Accuracy: 0.4417 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8225789070129395\n",
      "Epoch 35, Train Loss: 0.7157, Val Loss: 0.7162, Test Accuracy: 0.4404 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8183257579803467\n",
      "Epoch 36, Train Loss: 0.7208, Val Loss: 0.7155, Test Accuracy: 0.4417 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8180444240570068\n",
      "Epoch 37, Train Loss: 0.7214, Val Loss: 0.7147, Test Accuracy: 0.4443 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8151013851165771\n",
      "Epoch 38, Train Loss: 0.7178, Val Loss: 0.7139, Test Accuracy: 0.4430 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8159589767456055\n",
      "Epoch 39, Train Loss: 0.7176, Val Loss: 0.7136, Test Accuracy: 0.4443 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8232486248016357\n",
      "Epoch 40, Train Loss: 0.7191, Val Loss: 0.7133, Test Accuracy: 0.4430 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8193840980529785\n",
      "Epoch 41, Train Loss: 0.7156, Val Loss: 0.7131, Test Accuracy: 0.4417 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8118658065795898\n",
      "Epoch 42, Train Loss: 0.7179, Val Loss: 0.7123, Test Accuracy: 0.4404 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.820101261138916\n",
      "Epoch 43, Train Loss: 0.7131, Val Loss: 0.7118, Test Accuracy: 0.4377 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8115003108978271\n",
      "Epoch 44, Train Loss: 0.7135, Val Loss: 0.7113, Test Accuracy: 0.4391 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8238561153411865\n",
      "Epoch 45, Train Loss: 0.7172, Val Loss: 0.7108, Test Accuracy: 0.4377 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8194916248321533\n",
      "Epoch 46, Train Loss: 0.7126, Val Loss: 0.7104, Test Accuracy: 0.4404 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8153502941131592\n",
      "Epoch 47, Train Loss: 0.7131, Val Loss: 0.7101, Test Accuracy: 0.4404 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8199236392974854\n",
      "Epoch 48, Train Loss: 0.7111, Val Loss: 0.7095, Test Accuracy: 0.4417 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8197433948516846\n",
      "Epoch 49, Train Loss: 0.7114, Val Loss: 0.7092, Test Accuracy: 0.4469 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8156487941741943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:02:31,936] Trial 28 finished with value: 0.4836173001310616 and parameters: {'HIDDEN_DIMENSION': 87, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 512, 'DROP_OUT': 0.231052536609148, 'LEARNING_RATE': 3.624453181349348e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7121, Val Loss: 0.7089, Test Accuracy: 0.4482 ,Learning Rate: 3.624453181349348e-05 , Time Taken : 0.8117194175720215\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 64, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.19643557747970367, 'LEARNING_RATE': 2.6892677558168727e-05}\n",
      "Epoch 1, Train Loss: 0.8070, Val Loss: 0.8421, Test Accuracy: 0.4548 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8478951454162598\n",
      "Epoch 2, Train Loss: 0.7925, Val Loss: 0.8159, Test Accuracy: 0.4587 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8472929000854492\n",
      "Epoch 3, Train Loss: 0.7751, Val Loss: 0.7942, Test Accuracy: 0.4600 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8495285511016846\n",
      "Epoch 4, Train Loss: 0.7634, Val Loss: 0.7785, Test Accuracy: 0.4718 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8517303466796875\n",
      "Epoch 5, Train Loss: 0.7584, Val Loss: 0.7660, Test Accuracy: 0.4771 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8495998382568359\n",
      "Epoch 6, Train Loss: 0.7504, Val Loss: 0.7555, Test Accuracy: 0.4849 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8528296947479248\n",
      "Epoch 7, Train Loss: 0.7450, Val Loss: 0.7488, Test Accuracy: 0.4836 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8505527973175049\n",
      "Epoch 8, Train Loss: 0.7390, Val Loss: 0.7411, Test Accuracy: 0.4849 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8642339706420898\n",
      "Epoch 9, Train Loss: 0.7312, Val Loss: 0.7352, Test Accuracy: 0.4875 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8533957004547119\n",
      "Epoch 10, Train Loss: 0.7313, Val Loss: 0.7318, Test Accuracy: 0.4915 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8502099514007568\n",
      "Epoch 11, Train Loss: 0.7314, Val Loss: 0.7276, Test Accuracy: 0.4928 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8550541400909424\n",
      "Epoch 12, Train Loss: 0.7298, Val Loss: 0.7252, Test Accuracy: 0.4902 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8564028739929199\n",
      "Epoch 13, Train Loss: 0.7226, Val Loss: 0.7226, Test Accuracy: 0.4928 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8497698307037354\n",
      "Epoch 14, Train Loss: 0.7235, Val Loss: 0.7192, Test Accuracy: 0.4941 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8475480079650879\n",
      "Epoch 15, Train Loss: 0.7171, Val Loss: 0.7174, Test Accuracy: 0.4967 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8484370708465576\n",
      "Epoch 16, Train Loss: 0.7171, Val Loss: 0.7157, Test Accuracy: 0.4980 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8461954593658447\n",
      "Epoch 17, Train Loss: 0.7176, Val Loss: 0.7143, Test Accuracy: 0.4993 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8517169952392578\n",
      "Epoch 18, Train Loss: 0.7135, Val Loss: 0.7120, Test Accuracy: 0.5046 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8490869998931885\n",
      "Epoch 19, Train Loss: 0.7116, Val Loss: 0.7107, Test Accuracy: 0.5072 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8489453792572021\n",
      "Epoch 20, Train Loss: 0.7093, Val Loss: 0.7095, Test Accuracy: 0.5033 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8519642353057861\n",
      "Epoch 21, Train Loss: 0.7068, Val Loss: 0.7084, Test Accuracy: 0.5059 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8510663509368896\n",
      "Epoch 22, Train Loss: 0.7087, Val Loss: 0.7070, Test Accuracy: 0.5007 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8548839092254639\n",
      "Epoch 23, Train Loss: 0.7062, Val Loss: 0.7066, Test Accuracy: 0.4980 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8589367866516113\n",
      "Epoch 24, Train Loss: 0.7118, Val Loss: 0.7055, Test Accuracy: 0.4967 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8528962135314941\n",
      "Epoch 25, Train Loss: 0.7055, Val Loss: 0.7054, Test Accuracy: 0.4967 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8552412986755371\n",
      "Epoch 26, Train Loss: 0.7024, Val Loss: 0.7041, Test Accuracy: 0.4993 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.851792573928833\n",
      "Epoch 27, Train Loss: 0.7066, Val Loss: 0.7033, Test Accuracy: 0.4993 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8506243228912354\n",
      "Epoch 28, Train Loss: 0.7004, Val Loss: 0.7017, Test Accuracy: 0.5007 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8556077480316162\n",
      "Epoch 29, Train Loss: 0.7010, Val Loss: 0.7020, Test Accuracy: 0.5007 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8566620349884033\n",
      "Epoch 30, Train Loss: 0.7034, Val Loss: 0.7017, Test Accuracy: 0.4941 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8511738777160645\n",
      "Epoch 31, Train Loss: 0.7019, Val Loss: 0.7008, Test Accuracy: 0.4993 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8544468879699707\n",
      "Epoch 32, Train Loss: 0.7000, Val Loss: 0.7002, Test Accuracy: 0.4993 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8522958755493164\n",
      "Epoch 33, Train Loss: 0.7038, Val Loss: 0.6999, Test Accuracy: 0.5020 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8579857349395752\n",
      "Epoch 34, Train Loss: 0.7011, Val Loss: 0.7003, Test Accuracy: 0.4980 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8556830883026123\n",
      "Epoch 35, Train Loss: 0.7003, Val Loss: 0.6994, Test Accuracy: 0.5020 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8257012367248535\n",
      "Epoch 36, Train Loss: 0.6976, Val Loss: 0.6996, Test Accuracy: 0.5020 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.882239818572998\n",
      "Epoch 37, Train Loss: 0.6993, Val Loss: 0.7001, Test Accuracy: 0.5020 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.9013209342956543\n",
      "Epoch 38, Train Loss: 0.6985, Val Loss: 0.6992, Test Accuracy: 0.5033 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8889296054840088\n",
      "Epoch 39, Train Loss: 0.6971, Val Loss: 0.6995, Test Accuracy: 0.5072 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8979666233062744\n",
      "Epoch 40, Train Loss: 0.6914, Val Loss: 0.6988, Test Accuracy: 0.5111 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.9013655185699463\n",
      "Epoch 41, Train Loss: 0.6963, Val Loss: 0.6985, Test Accuracy: 0.5059 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.9061856269836426\n",
      "Epoch 42, Train Loss: 0.6949, Val Loss: 0.6985, Test Accuracy: 0.5046 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8804941177368164\n",
      "Epoch 43, Train Loss: 0.6933, Val Loss: 0.6980, Test Accuracy: 0.5046 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8558642864227295\n",
      "Epoch 44, Train Loss: 0.6978, Val Loss: 0.6984, Test Accuracy: 0.5046 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8601858615875244\n",
      "Epoch 45, Train Loss: 0.6963, Val Loss: 0.6972, Test Accuracy: 0.5098 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8480069637298584\n",
      "Epoch 46, Train Loss: 0.6938, Val Loss: 0.6970, Test Accuracy: 0.5098 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8487648963928223\n",
      "Epoch 47, Train Loss: 0.6969, Val Loss: 0.6967, Test Accuracy: 0.5125 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8490359783172607\n",
      "Epoch 48, Train Loss: 0.6926, Val Loss: 0.6961, Test Accuracy: 0.5177 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8454701900482178\n",
      "Epoch 49, Train Loss: 0.6943, Val Loss: 0.6962, Test Accuracy: 0.5203 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8451149463653564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:03:14,901] Trial 29 finished with value: 0.4954128440366973 and parameters: {'HIDDEN_DIMENSION': 64, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'DROP_OUT': 0.19643557747970367, 'LEARNING_RATE': 2.6892677558168727e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6943, Val Loss: 0.6959, Test Accuracy: 0.5229 ,Learning Rate: 2.6892677558168727e-05 , Time Taken : 0.8488845825195312\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 125, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.2568334096306507, 'LEARNING_RATE': 6.881694923903533e-05}\n",
      "Epoch 1, Train Loss: 0.8230, Val Loss: 0.7408, Test Accuracy: 0.5295 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0814599990844727\n",
      "Epoch 2, Train Loss: 0.8045, Val Loss: 0.7399, Test Accuracy: 0.5164 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0951354503631592\n",
      "Epoch 3, Train Loss: 0.7836, Val Loss: 0.7382, Test Accuracy: 0.5033 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.2732253074645996\n",
      "Epoch 4, Train Loss: 0.7664, Val Loss: 0.7342, Test Accuracy: 0.5007 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0845792293548584\n",
      "Epoch 5, Train Loss: 0.7523, Val Loss: 0.7284, Test Accuracy: 0.4993 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0867135524749756\n",
      "Epoch 6, Train Loss: 0.7461, Val Loss: 0.7221, Test Accuracy: 0.5020 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.081428050994873\n",
      "Epoch 7, Train Loss: 0.7467, Val Loss: 0.7177, Test Accuracy: 0.5007 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0858097076416016\n",
      "Epoch 8, Train Loss: 0.7298, Val Loss: 0.7147, Test Accuracy: 0.5059 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0795137882232666\n",
      "Epoch 9, Train Loss: 0.7313, Val Loss: 0.7123, Test Accuracy: 0.5059 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.07918381690979\n",
      "Epoch 10, Train Loss: 0.7274, Val Loss: 0.7100, Test Accuracy: 0.5046 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0758962631225586\n",
      "Epoch 11, Train Loss: 0.7236, Val Loss: 0.7073, Test Accuracy: 0.5059 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.083176612854004\n",
      "Epoch 12, Train Loss: 0.7217, Val Loss: 0.7056, Test Accuracy: 0.5098 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0835950374603271\n",
      "Epoch 13, Train Loss: 0.7140, Val Loss: 0.7049, Test Accuracy: 0.5059 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.077690601348877\n",
      "Epoch 14, Train Loss: 0.7174, Val Loss: 0.7034, Test Accuracy: 0.5033 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0725948810577393\n",
      "Epoch 15, Train Loss: 0.7152, Val Loss: 0.7013, Test Accuracy: 0.5085 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0763323307037354\n",
      "Epoch 16, Train Loss: 0.7098, Val Loss: 0.6997, Test Accuracy: 0.5151 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0773119926452637\n",
      "Epoch 17, Train Loss: 0.7116, Val Loss: 0.7002, Test Accuracy: 0.5007 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0808722972869873\n",
      "Epoch 18, Train Loss: 0.7076, Val Loss: 0.7005, Test Accuracy: 0.4902 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0755720138549805\n",
      "Epoch 19, Train Loss: 0.7062, Val Loss: 0.7002, Test Accuracy: 0.4889 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.077399492263794\n",
      "Epoch 20, Train Loss: 0.7126, Val Loss: 0.6991, Test Accuracy: 0.4967 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.077730417251587\n",
      "Epoch 21, Train Loss: 0.7076, Val Loss: 0.6987, Test Accuracy: 0.4954 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0791380405426025\n",
      "Epoch 22, Train Loss: 0.7059, Val Loss: 0.6981, Test Accuracy: 0.4954 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0899784564971924\n",
      "Epoch 23, Train Loss: 0.7027, Val Loss: 0.6972, Test Accuracy: 0.5033 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0765836238861084\n",
      "Epoch 24, Train Loss: 0.7032, Val Loss: 0.6972, Test Accuracy: 0.5059 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0754165649414062\n",
      "Epoch 25, Train Loss: 0.7052, Val Loss: 0.6965, Test Accuracy: 0.5098 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.081024408340454\n",
      "Epoch 26, Train Loss: 0.7031, Val Loss: 0.6966, Test Accuracy: 0.5072 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0838208198547363\n",
      "Epoch 27, Train Loss: 0.7021, Val Loss: 0.6961, Test Accuracy: 0.5085 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.083075761795044\n",
      "Epoch 28, Train Loss: 0.7063, Val Loss: 0.6960, Test Accuracy: 0.5059 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.090775728225708\n",
      "Epoch 29, Train Loss: 0.7020, Val Loss: 0.6957, Test Accuracy: 0.5072 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0763747692108154\n",
      "Epoch 30, Train Loss: 0.7018, Val Loss: 0.6956, Test Accuracy: 0.5072 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0818285942077637\n",
      "Epoch 31, Train Loss: 0.7019, Val Loss: 0.6957, Test Accuracy: 0.5072 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0788638591766357\n",
      "Epoch 32, Train Loss: 0.7007, Val Loss: 0.6965, Test Accuracy: 0.4993 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.07841157913208\n",
      "Epoch 33, Train Loss: 0.6989, Val Loss: 0.6954, Test Accuracy: 0.5098 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0801846981048584\n",
      "Epoch 34, Train Loss: 0.6999, Val Loss: 0.6954, Test Accuracy: 0.5125 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0788280963897705\n",
      "Epoch 35, Train Loss: 0.6963, Val Loss: 0.6944, Test Accuracy: 0.5151 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.073974370956421\n",
      "Epoch 36, Train Loss: 0.6977, Val Loss: 0.6958, Test Accuracy: 0.5059 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0862491130828857\n",
      "Epoch 37, Train Loss: 0.6951, Val Loss: 0.6961, Test Accuracy: 0.5059 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0936753749847412\n",
      "Epoch 38, Train Loss: 0.6990, Val Loss: 0.6962, Test Accuracy: 0.5020 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0752038955688477\n",
      "Epoch 39, Train Loss: 0.6991, Val Loss: 0.6949, Test Accuracy: 0.5098 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0837996006011963\n",
      "Epoch 40, Train Loss: 0.6980, Val Loss: 0.6945, Test Accuracy: 0.5164 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.079308271408081\n",
      "Epoch 41, Train Loss: 0.6923, Val Loss: 0.6935, Test Accuracy: 0.5190 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0838203430175781\n",
      "Epoch 42, Train Loss: 0.6959, Val Loss: 0.6937, Test Accuracy: 0.5125 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0763180255889893\n",
      "Epoch 43, Train Loss: 0.6931, Val Loss: 0.6943, Test Accuracy: 0.5138 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0789744853973389\n",
      "Epoch 44, Train Loss: 0.6954, Val Loss: 0.6948, Test Accuracy: 0.5151 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0879390239715576\n",
      "Epoch 45, Train Loss: 0.6951, Val Loss: 0.6956, Test Accuracy: 0.5072 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0835449695587158\n",
      "Epoch 46, Train Loss: 0.6939, Val Loss: 0.6949, Test Accuracy: 0.5138 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0831735134124756\n",
      "Epoch 47, Train Loss: 0.6935, Val Loss: 0.6945, Test Accuracy: 0.5125 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0821220874786377\n",
      "Epoch 48, Train Loss: 0.6985, Val Loss: 0.6934, Test Accuracy: 0.5098 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0806756019592285\n",
      "Epoch 49, Train Loss: 0.6932, Val Loss: 0.6935, Test Accuracy: 0.5111 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.2522778511047363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:04:09,449] Trial 30 finished with value: 0.5190039318479686 and parameters: {'HIDDEN_DIMENSION': 125, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.2568334096306507, 'LEARNING_RATE': 6.881694923903533e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6945, Val Loss: 0.6939, Test Accuracy: 0.5138 ,Learning Rate: 6.881694923903533e-05 , Time Taken : 1.0818495750427246\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 120, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1369143442476713, 'LEARNING_RATE': 5.331946234132421e-05}\n",
      "Epoch 1, Train Loss: 0.7712, Val Loss: 0.7163, Test Accuracy: 0.5439 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0876729488372803\n",
      "Epoch 2, Train Loss: 0.7583, Val Loss: 0.7165, Test Accuracy: 0.5360 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0879149436950684\n",
      "Epoch 3, Train Loss: 0.7518, Val Loss: 0.7177, Test Accuracy: 0.5216 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0788226127624512\n",
      "Epoch 4, Train Loss: 0.7420, Val Loss: 0.7179, Test Accuracy: 0.5177 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.090414047241211\n",
      "Epoch 5, Train Loss: 0.7347, Val Loss: 0.7164, Test Accuracy: 0.5177 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0964915752410889\n",
      "Epoch 6, Train Loss: 0.7269, Val Loss: 0.7143, Test Accuracy: 0.5190 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0966198444366455\n",
      "Epoch 7, Train Loss: 0.7287, Val Loss: 0.7114, Test Accuracy: 0.5216 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0863854885101318\n",
      "Epoch 8, Train Loss: 0.7257, Val Loss: 0.7092, Test Accuracy: 0.5203 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0879716873168945\n",
      "Epoch 9, Train Loss: 0.7196, Val Loss: 0.7068, Test Accuracy: 0.5203 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0972819328308105\n",
      "Epoch 10, Train Loss: 0.7199, Val Loss: 0.7048, Test Accuracy: 0.5216 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0880160331726074\n",
      "Epoch 11, Train Loss: 0.7133, Val Loss: 0.7032, Test Accuracy: 0.5203 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0898385047912598\n",
      "Epoch 12, Train Loss: 0.7163, Val Loss: 0.7017, Test Accuracy: 0.5203 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0838634967803955\n",
      "Epoch 13, Train Loss: 0.7116, Val Loss: 0.7002, Test Accuracy: 0.5216 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.094752550125122\n",
      "Epoch 14, Train Loss: 0.7121, Val Loss: 0.6994, Test Accuracy: 0.5164 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0900051593780518\n",
      "Epoch 15, Train Loss: 0.7096, Val Loss: 0.6991, Test Accuracy: 0.5190 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0810093879699707\n",
      "Epoch 16, Train Loss: 0.7065, Val Loss: 0.6989, Test Accuracy: 0.5177 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0862891674041748\n",
      "Epoch 17, Train Loss: 0.7037, Val Loss: 0.6980, Test Accuracy: 0.5177 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0854239463806152\n",
      "Epoch 18, Train Loss: 0.7083, Val Loss: 0.6973, Test Accuracy: 0.5151 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0859739780426025\n",
      "Epoch 19, Train Loss: 0.7046, Val Loss: 0.6972, Test Accuracy: 0.5138 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0914251804351807\n",
      "Epoch 20, Train Loss: 0.7051, Val Loss: 0.6963, Test Accuracy: 0.5177 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0886738300323486\n",
      "Epoch 21, Train Loss: 0.7015, Val Loss: 0.6961, Test Accuracy: 0.5138 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0766119956970215\n",
      "Epoch 22, Train Loss: 0.7013, Val Loss: 0.6956, Test Accuracy: 0.5151 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0879027843475342\n",
      "Epoch 23, Train Loss: 0.7046, Val Loss: 0.6949, Test Accuracy: 0.5190 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0903916358947754\n",
      "Epoch 24, Train Loss: 0.7046, Val Loss: 0.6942, Test Accuracy: 0.5216 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0896384716033936\n",
      "Epoch 25, Train Loss: 0.7009, Val Loss: 0.6944, Test Accuracy: 0.5203 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0796010494232178\n",
      "Epoch 26, Train Loss: 0.7056, Val Loss: 0.6947, Test Accuracy: 0.5138 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0924668312072754\n",
      "Epoch 27, Train Loss: 0.7013, Val Loss: 0.6943, Test Accuracy: 0.5177 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0888144969940186\n",
      "Epoch 28, Train Loss: 0.6996, Val Loss: 0.6937, Test Accuracy: 0.5164 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0900564193725586\n",
      "Epoch 29, Train Loss: 0.6987, Val Loss: 0.6939, Test Accuracy: 0.5138 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0847301483154297\n",
      "Epoch 30, Train Loss: 0.6960, Val Loss: 0.6932, Test Accuracy: 0.5151 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0961036682128906\n",
      "Epoch 31, Train Loss: 0.6992, Val Loss: 0.6931, Test Accuracy: 0.5138 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0812151432037354\n",
      "Epoch 32, Train Loss: 0.6975, Val Loss: 0.6932, Test Accuracy: 0.5111 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0909245014190674\n",
      "Epoch 33, Train Loss: 0.6979, Val Loss: 0.6942, Test Accuracy: 0.5046 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.105480432510376\n",
      "Epoch 34, Train Loss: 0.6981, Val Loss: 0.6938, Test Accuracy: 0.5020 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0918006896972656\n",
      "Epoch 35, Train Loss: 0.6985, Val Loss: 0.6938, Test Accuracy: 0.5033 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0877954959869385\n",
      "Epoch 36, Train Loss: 0.7002, Val Loss: 0.6931, Test Accuracy: 0.5072 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0844066143035889\n",
      "Epoch 37, Train Loss: 0.7019, Val Loss: 0.6925, Test Accuracy: 0.5125 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0954556465148926\n",
      "Epoch 38, Train Loss: 0.6991, Val Loss: 0.6923, Test Accuracy: 0.5138 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0868175029754639\n",
      "Epoch 39, Train Loss: 0.6980, Val Loss: 0.6930, Test Accuracy: 0.5033 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.08864426612854\n",
      "Epoch 40, Train Loss: 0.6959, Val Loss: 0.6927, Test Accuracy: 0.5072 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0848891735076904\n",
      "Epoch 41, Train Loss: 0.6939, Val Loss: 0.6924, Test Accuracy: 0.5125 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0885820388793945\n",
      "Epoch 42, Train Loss: 0.6949, Val Loss: 0.6920, Test Accuracy: 0.5190 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0850982666015625\n",
      "Epoch 43, Train Loss: 0.6969, Val Loss: 0.6921, Test Accuracy: 0.5190 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0893094539642334\n",
      "Epoch 44, Train Loss: 0.6968, Val Loss: 0.6916, Test Accuracy: 0.5190 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0819454193115234\n",
      "Epoch 45, Train Loss: 0.6954, Val Loss: 0.6915, Test Accuracy: 0.5216 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0862905979156494\n",
      "Epoch 46, Train Loss: 0.6947, Val Loss: 0.6926, Test Accuracy: 0.5111 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.087738275527954\n",
      "Epoch 47, Train Loss: 0.6983, Val Loss: 0.6921, Test Accuracy: 0.5164 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0906038284301758\n",
      "Epoch 48, Train Loss: 0.6988, Val Loss: 0.6919, Test Accuracy: 0.5151 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0929081439971924\n",
      "Epoch 49, Train Loss: 0.6964, Val Loss: 0.6916, Test Accuracy: 0.5190 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0849673748016357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:05:04,011] Trial 31 finished with value: 0.5530799475753604 and parameters: {'HIDDEN_DIMENSION': 120, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.1369143442476713, 'LEARNING_RATE': 5.331946234132421e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6975, Val Loss: 0.6920, Test Accuracy: 0.5098 ,Learning Rate: 5.331946234132421e-05 , Time Taken : 1.0981853008270264\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 101, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.17679876425826668, 'LEARNING_RATE': 8.01625762083029e-05}\n",
      "Epoch 1, Train Loss: 0.7800, Val Loss: 0.8065, Test Accuracy: 0.4771 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0716683864593506\n",
      "Epoch 2, Train Loss: 0.7663, Val Loss: 0.7746, Test Accuracy: 0.4941 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0753886699676514\n",
      "Epoch 3, Train Loss: 0.7502, Val Loss: 0.7519, Test Accuracy: 0.5033 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.081068754196167\n",
      "Epoch 4, Train Loss: 0.7421, Val Loss: 0.7381, Test Accuracy: 0.5125 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.080451250076294\n",
      "Epoch 5, Train Loss: 0.7350, Val Loss: 0.7305, Test Accuracy: 0.5151 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0724327564239502\n",
      "Epoch 6, Train Loss: 0.7306, Val Loss: 0.7256, Test Accuracy: 0.5098 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0850510597229004\n",
      "Epoch 7, Train Loss: 0.7251, Val Loss: 0.7225, Test Accuracy: 0.5138 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.081167221069336\n",
      "Epoch 8, Train Loss: 0.7148, Val Loss: 0.7203, Test Accuracy: 0.5164 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0811805725097656\n",
      "Epoch 9, Train Loss: 0.7186, Val Loss: 0.7166, Test Accuracy: 0.5229 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0789811611175537\n",
      "Epoch 10, Train Loss: 0.7121, Val Loss: 0.7148, Test Accuracy: 0.5190 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0806877613067627\n",
      "Epoch 11, Train Loss: 0.7094, Val Loss: 0.7122, Test Accuracy: 0.5203 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0910298824310303\n",
      "Epoch 12, Train Loss: 0.7113, Val Loss: 0.7106, Test Accuracy: 0.5216 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0745642185211182\n",
      "Epoch 13, Train Loss: 0.7091, Val Loss: 0.7089, Test Accuracy: 0.5242 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0866460800170898\n",
      "Epoch 14, Train Loss: 0.7051, Val Loss: 0.7092, Test Accuracy: 0.5203 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.08353590965271\n",
      "Epoch 15, Train Loss: 0.7040, Val Loss: 0.7074, Test Accuracy: 0.5256 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.07682204246521\n",
      "Epoch 16, Train Loss: 0.7035, Val Loss: 0.7066, Test Accuracy: 0.5242 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0690836906433105\n",
      "Epoch 17, Train Loss: 0.7028, Val Loss: 0.7052, Test Accuracy: 0.5242 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.078329086303711\n",
      "Epoch 18, Train Loss: 0.7014, Val Loss: 0.7039, Test Accuracy: 0.5242 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0718750953674316\n",
      "Epoch 19, Train Loss: 0.6992, Val Loss: 0.7037, Test Accuracy: 0.5216 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0790514945983887\n",
      "Epoch 20, Train Loss: 0.6972, Val Loss: 0.7019, Test Accuracy: 0.5151 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0813684463500977\n",
      "Epoch 21, Train Loss: 0.6999, Val Loss: 0.7017, Test Accuracy: 0.5111 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0718741416931152\n",
      "Epoch 22, Train Loss: 0.6970, Val Loss: 0.7016, Test Accuracy: 0.5138 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.086923599243164\n",
      "Epoch 23, Train Loss: 0.6964, Val Loss: 0.7008, Test Accuracy: 0.5138 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.071479082107544\n",
      "Epoch 24, Train Loss: 0.6983, Val Loss: 0.7000, Test Accuracy: 0.5177 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.077967882156372\n",
      "Epoch 25, Train Loss: 0.6948, Val Loss: 0.7002, Test Accuracy: 0.5125 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0711805820465088\n",
      "Epoch 26, Train Loss: 0.6939, Val Loss: 0.6990, Test Accuracy: 0.5111 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.082897424697876\n",
      "Epoch 27, Train Loss: 0.6943, Val Loss: 0.6995, Test Accuracy: 0.5072 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0854861736297607\n",
      "Epoch 28, Train Loss: 0.6951, Val Loss: 0.6992, Test Accuracy: 0.5111 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0770018100738525\n",
      "Epoch 29, Train Loss: 0.6933, Val Loss: 0.6983, Test Accuracy: 0.5111 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0745704174041748\n",
      "Epoch 30, Train Loss: 0.6912, Val Loss: 0.6976, Test Accuracy: 0.5085 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0785772800445557\n",
      "Epoch 31, Train Loss: 0.6902, Val Loss: 0.6980, Test Accuracy: 0.5125 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.2749755382537842\n",
      "Epoch 32, Train Loss: 0.6904, Val Loss: 0.6975, Test Accuracy: 0.5111 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0802874565124512\n",
      "Epoch 33, Train Loss: 0.6891, Val Loss: 0.6970, Test Accuracy: 0.5111 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0772392749786377\n",
      "Epoch 34, Train Loss: 0.6925, Val Loss: 0.6979, Test Accuracy: 0.5138 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0870366096496582\n",
      "Epoch 35, Train Loss: 0.6947, Val Loss: 0.6964, Test Accuracy: 0.5125 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.084946632385254\n",
      "Epoch 36, Train Loss: 0.6937, Val Loss: 0.6962, Test Accuracy: 0.5138 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0700182914733887\n",
      "Epoch 37, Train Loss: 0.6897, Val Loss: 0.6958, Test Accuracy: 0.5111 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.092684268951416\n",
      "Epoch 38, Train Loss: 0.6890, Val Loss: 0.6964, Test Accuracy: 0.5138 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0725386142730713\n",
      "Epoch 39, Train Loss: 0.6898, Val Loss: 0.6974, Test Accuracy: 0.5190 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0854268074035645\n",
      "Epoch 40, Train Loss: 0.6914, Val Loss: 0.6971, Test Accuracy: 0.5151 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0826776027679443\n",
      "Epoch 41, Train Loss: 0.6890, Val Loss: 0.6954, Test Accuracy: 0.5177 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0858941078186035\n",
      "Epoch 42, Train Loss: 0.6940, Val Loss: 0.6961, Test Accuracy: 0.5203 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0793085098266602\n",
      "Epoch 43, Train Loss: 0.6896, Val Loss: 0.6955, Test Accuracy: 0.5203 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0782928466796875\n",
      "Epoch 44, Train Loss: 0.6896, Val Loss: 0.6955, Test Accuracy: 0.5203 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0787858963012695\n",
      "Epoch 45, Train Loss: 0.6942, Val Loss: 0.6953, Test Accuracy: 0.5216 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0781912803649902\n",
      "Epoch 46, Train Loss: 0.6880, Val Loss: 0.6949, Test Accuracy: 0.5229 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.082005262374878\n",
      "Epoch 47, Train Loss: 0.6876, Val Loss: 0.6952, Test Accuracy: 0.5190 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0807709693908691\n",
      "Epoch 48, Train Loss: 0.6874, Val Loss: 0.6952, Test Accuracy: 0.5177 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0848634243011475\n",
      "Epoch 49, Train Loss: 0.6892, Val Loss: 0.6962, Test Accuracy: 0.5111 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.0780932903289795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:05:58,306] Trial 32 finished with value: 0.528178243774574 and parameters: {'HIDDEN_DIMENSION': 101, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.17679876425826668, 'LEARNING_RATE': 8.01625762083029e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6897, Val Loss: 0.6952, Test Accuracy: 0.5164 ,Learning Rate: 8.01625762083029e-05 , Time Taken : 1.07627272605896\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 93, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.12445396350379553, 'LEARNING_RATE': 0.00010751703922804336}\n",
      "Epoch 1, Train Loss: 0.7224, Val Loss: 0.6963, Test Accuracy: 0.5400 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0713915824890137\n",
      "Epoch 2, Train Loss: 0.7145, Val Loss: 0.6937, Test Accuracy: 0.5308 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0697171688079834\n",
      "Epoch 3, Train Loss: 0.7107, Val Loss: 0.6924, Test Accuracy: 0.5190 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0752067565917969\n",
      "Epoch 4, Train Loss: 0.7109, Val Loss: 0.6903, Test Accuracy: 0.5190 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0727589130401611\n",
      "Epoch 5, Train Loss: 0.7045, Val Loss: 0.6893, Test Accuracy: 0.5282 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.072331428527832\n",
      "Epoch 6, Train Loss: 0.7008, Val Loss: 0.6878, Test Accuracy: 0.5360 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0843446254730225\n",
      "Epoch 7, Train Loss: 0.7009, Val Loss: 0.6874, Test Accuracy: 0.5334 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.076162576675415\n",
      "Epoch 8, Train Loss: 0.7029, Val Loss: 0.6870, Test Accuracy: 0.5439 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.075697660446167\n",
      "Epoch 9, Train Loss: 0.6988, Val Loss: 0.6879, Test Accuracy: 0.5400 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.074084758758545\n",
      "Epoch 10, Train Loss: 0.6950, Val Loss: 0.6885, Test Accuracy: 0.5413 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0645859241485596\n",
      "Epoch 11, Train Loss: 0.6956, Val Loss: 0.6887, Test Accuracy: 0.5400 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0777924060821533\n",
      "Epoch 12, Train Loss: 0.6985, Val Loss: 0.6876, Test Accuracy: 0.5531 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0786573886871338\n",
      "Epoch 13, Train Loss: 0.6981, Val Loss: 0.6882, Test Accuracy: 0.5518 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0811011791229248\n",
      "Epoch 14, Train Loss: 0.6961, Val Loss: 0.6878, Test Accuracy: 0.5557 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0725715160369873\n",
      "Epoch 15, Train Loss: 0.6957, Val Loss: 0.6873, Test Accuracy: 0.5596 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0683376789093018\n",
      "Epoch 16, Train Loss: 0.6944, Val Loss: 0.6868, Test Accuracy: 0.5649 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0680160522460938\n",
      "Epoch 17, Train Loss: 0.6964, Val Loss: 0.6879, Test Accuracy: 0.5505 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0752732753753662\n",
      "Epoch 18, Train Loss: 0.6956, Val Loss: 0.6877, Test Accuracy: 0.5544 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.072340726852417\n",
      "Epoch 19, Train Loss: 0.6920, Val Loss: 0.6876, Test Accuracy: 0.5570 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.063767433166504\n",
      "Epoch 20, Train Loss: 0.6939, Val Loss: 0.6886, Test Accuracy: 0.5478 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0795202255249023\n",
      "Epoch 21, Train Loss: 0.6909, Val Loss: 0.6881, Test Accuracy: 0.5478 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0755090713500977\n",
      "Epoch 22, Train Loss: 0.6922, Val Loss: 0.6885, Test Accuracy: 0.5400 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0839991569519043\n",
      "Epoch 23, Train Loss: 0.6908, Val Loss: 0.6893, Test Accuracy: 0.5321 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0693249702453613\n",
      "Epoch 24, Train Loss: 0.6901, Val Loss: 0.6884, Test Accuracy: 0.5426 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.072711706161499\n",
      "Epoch 25, Train Loss: 0.6911, Val Loss: 0.6872, Test Accuracy: 0.5478 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0707674026489258\n",
      "Epoch 26, Train Loss: 0.6908, Val Loss: 0.6866, Test Accuracy: 0.5557 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.079167127609253\n",
      "Epoch 27, Train Loss: 0.6891, Val Loss: 0.6864, Test Accuracy: 0.5662 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0809204578399658\n",
      "Epoch 28, Train Loss: 0.6897, Val Loss: 0.6900, Test Accuracy: 0.5387 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0717551708221436\n",
      "Epoch 29, Train Loss: 0.6884, Val Loss: 0.6898, Test Accuracy: 0.5413 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.2722206115722656\n",
      "Epoch 30, Train Loss: 0.6886, Val Loss: 0.6895, Test Accuracy: 0.5478 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0742175579071045\n",
      "Epoch 31, Train Loss: 0.6880, Val Loss: 0.6883, Test Accuracy: 0.5544 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0702297687530518\n",
      "Epoch 32, Train Loss: 0.6911, Val Loss: 0.6886, Test Accuracy: 0.5544 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.071638822555542\n",
      "Epoch 33, Train Loss: 0.6870, Val Loss: 0.6890, Test Accuracy: 0.5544 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0692055225372314\n",
      "Epoch 34, Train Loss: 0.6881, Val Loss: 0.6888, Test Accuracy: 0.5570 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0707805156707764\n",
      "Epoch 35, Train Loss: 0.6880, Val Loss: 0.6879, Test Accuracy: 0.5623 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0695459842681885\n",
      "Epoch 36, Train Loss: 0.6885, Val Loss: 0.6893, Test Accuracy: 0.5570 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0694630146026611\n",
      "Epoch 37, Train Loss: 0.6872, Val Loss: 0.6893, Test Accuracy: 0.5596 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0730781555175781\n",
      "Epoch 38, Train Loss: 0.6876, Val Loss: 0.6899, Test Accuracy: 0.5609 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0799651145935059\n",
      "Epoch 39, Train Loss: 0.6862, Val Loss: 0.6900, Test Accuracy: 0.5636 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.072049617767334\n",
      "Epoch 40, Train Loss: 0.6867, Val Loss: 0.6909, Test Accuracy: 0.5596 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0713379383087158\n",
      "Epoch 41, Train Loss: 0.6863, Val Loss: 0.6901, Test Accuracy: 0.5570 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0756165981292725\n",
      "Epoch 42, Train Loss: 0.6842, Val Loss: 0.6894, Test Accuracy: 0.5623 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0689101219177246\n",
      "Epoch 43, Train Loss: 0.6858, Val Loss: 0.6895, Test Accuracy: 0.5649 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0705606937408447\n",
      "Epoch 44, Train Loss: 0.6851, Val Loss: 0.6911, Test Accuracy: 0.5531 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0756933689117432\n",
      "Epoch 45, Train Loss: 0.6868, Val Loss: 0.6905, Test Accuracy: 0.5596 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0675837993621826\n",
      "Epoch 46, Train Loss: 0.6865, Val Loss: 0.6910, Test Accuracy: 0.5570 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0703239440917969\n",
      "Epoch 47, Train Loss: 0.6858, Val Loss: 0.6898, Test Accuracy: 0.5662 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0687425136566162\n",
      "Epoch 48, Train Loss: 0.6849, Val Loss: 0.6883, Test Accuracy: 0.5649 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.074429988861084\n",
      "Epoch 49, Train Loss: 0.6853, Val Loss: 0.6886, Test Accuracy: 0.5649 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0852456092834473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:06:52,300] Trial 33 finished with value: 0.5530799475753604 and parameters: {'HIDDEN_DIMENSION': 93, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.12445396350379553, 'LEARNING_RATE': 0.00010751703922804336}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6824, Val Loss: 0.6904, Test Accuracy: 0.5636 ,Learning Rate: 0.00010751703922804336 , Time Taken : 1.0660231113433838\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 105, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.14966247208926836, 'LEARNING_RATE': 4.166193656815446e-05}\n",
      "Epoch 1, Train Loss: 0.7974, Val Loss: 0.7453, Test Accuracy: 0.5544 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0842375755310059\n",
      "Epoch 2, Train Loss: 0.7754, Val Loss: 0.7433, Test Accuracy: 0.5426 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.078618049621582\n",
      "Epoch 3, Train Loss: 0.7722, Val Loss: 0.7429, Test Accuracy: 0.5256 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0808184146881104\n",
      "Epoch 4, Train Loss: 0.7615, Val Loss: 0.7430, Test Accuracy: 0.5282 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0822932720184326\n",
      "Epoch 5, Train Loss: 0.7535, Val Loss: 0.7412, Test Accuracy: 0.5269 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0807805061340332\n",
      "Epoch 6, Train Loss: 0.7461, Val Loss: 0.7390, Test Accuracy: 0.5269 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.086681842803955\n",
      "Epoch 7, Train Loss: 0.7461, Val Loss: 0.7363, Test Accuracy: 0.5256 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0767936706542969\n",
      "Epoch 8, Train Loss: 0.7374, Val Loss: 0.7338, Test Accuracy: 0.5203 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.07881760597229\n",
      "Epoch 9, Train Loss: 0.7433, Val Loss: 0.7303, Test Accuracy: 0.5216 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0894019603729248\n",
      "Epoch 10, Train Loss: 0.7343, Val Loss: 0.7272, Test Accuracy: 0.5242 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0740303993225098\n",
      "Epoch 11, Train Loss: 0.7284, Val Loss: 0.7244, Test Accuracy: 0.5203 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0910215377807617\n",
      "Epoch 12, Train Loss: 0.7255, Val Loss: 0.7219, Test Accuracy: 0.5190 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0807132720947266\n",
      "Epoch 13, Train Loss: 0.7279, Val Loss: 0.7192, Test Accuracy: 0.5190 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0835795402526855\n",
      "Epoch 14, Train Loss: 0.7242, Val Loss: 0.7172, Test Accuracy: 0.5177 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.080428123474121\n",
      "Epoch 15, Train Loss: 0.7202, Val Loss: 0.7161, Test Accuracy: 0.5151 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.080899953842163\n",
      "Epoch 16, Train Loss: 0.7263, Val Loss: 0.7139, Test Accuracy: 0.5151 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0839111804962158\n",
      "Epoch 17, Train Loss: 0.7192, Val Loss: 0.7120, Test Accuracy: 0.5242 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0873985290527344\n",
      "Epoch 18, Train Loss: 0.7203, Val Loss: 0.7109, Test Accuracy: 0.5256 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0879426002502441\n",
      "Epoch 19, Train Loss: 0.7211, Val Loss: 0.7097, Test Accuracy: 0.5282 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0732488632202148\n",
      "Epoch 20, Train Loss: 0.7114, Val Loss: 0.7083, Test Accuracy: 0.5321 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0797855854034424\n",
      "Epoch 21, Train Loss: 0.7130, Val Loss: 0.7077, Test Accuracy: 0.5321 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.08455228805542\n",
      "Epoch 22, Train Loss: 0.7149, Val Loss: 0.7067, Test Accuracy: 0.5334 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.084414005279541\n",
      "Epoch 23, Train Loss: 0.7076, Val Loss: 0.7057, Test Accuracy: 0.5321 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0798571109771729\n",
      "Epoch 24, Train Loss: 0.7113, Val Loss: 0.7052, Test Accuracy: 0.5334 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0862720012664795\n",
      "Epoch 25, Train Loss: 0.7078, Val Loss: 0.7046, Test Accuracy: 0.5308 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0763916969299316\n",
      "Epoch 26, Train Loss: 0.7077, Val Loss: 0.7032, Test Accuracy: 0.5400 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0827867984771729\n",
      "Epoch 27, Train Loss: 0.7070, Val Loss: 0.7027, Test Accuracy: 0.5387 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0750484466552734\n",
      "Epoch 28, Train Loss: 0.7086, Val Loss: 0.7018, Test Accuracy: 0.5439 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.078841209411621\n",
      "Epoch 29, Train Loss: 0.7092, Val Loss: 0.7016, Test Accuracy: 0.5400 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.089257001876831\n",
      "Epoch 30, Train Loss: 0.7032, Val Loss: 0.7009, Test Accuracy: 0.5360 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0782496929168701\n",
      "Epoch 31, Train Loss: 0.7048, Val Loss: 0.7009, Test Accuracy: 0.5387 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0871713161468506\n",
      "Epoch 32, Train Loss: 0.7040, Val Loss: 0.7013, Test Accuracy: 0.5347 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0890061855316162\n",
      "Epoch 33, Train Loss: 0.6995, Val Loss: 0.7006, Test Accuracy: 0.5360 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0803496837615967\n",
      "Epoch 34, Train Loss: 0.7032, Val Loss: 0.7002, Test Accuracy: 0.5360 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0755345821380615\n",
      "Epoch 35, Train Loss: 0.7029, Val Loss: 0.6992, Test Accuracy: 0.5374 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0832881927490234\n",
      "Epoch 36, Train Loss: 0.7067, Val Loss: 0.6987, Test Accuracy: 0.5360 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0829088687896729\n",
      "Epoch 37, Train Loss: 0.7011, Val Loss: 0.6981, Test Accuracy: 0.5387 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0799119472503662\n",
      "Epoch 38, Train Loss: 0.7035, Val Loss: 0.6976, Test Accuracy: 0.5374 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0832173824310303\n",
      "Epoch 39, Train Loss: 0.6968, Val Loss: 0.6974, Test Accuracy: 0.5387 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0781629085540771\n",
      "Epoch 40, Train Loss: 0.6995, Val Loss: 0.6975, Test Accuracy: 0.5413 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0836372375488281\n",
      "Epoch 41, Train Loss: 0.7007, Val Loss: 0.6973, Test Accuracy: 0.5465 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0813848972320557\n",
      "Epoch 42, Train Loss: 0.6976, Val Loss: 0.6970, Test Accuracy: 0.5413 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.075005292892456\n",
      "Epoch 43, Train Loss: 0.6980, Val Loss: 0.6964, Test Accuracy: 0.5452 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.080169439315796\n",
      "Epoch 44, Train Loss: 0.6953, Val Loss: 0.6965, Test Accuracy: 0.5465 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0793726444244385\n",
      "Epoch 45, Train Loss: 0.6992, Val Loss: 0.6963, Test Accuracy: 0.5491 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0806012153625488\n",
      "Epoch 46, Train Loss: 0.6972, Val Loss: 0.6965, Test Accuracy: 0.5439 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.085432529449463\n",
      "Epoch 47, Train Loss: 0.6949, Val Loss: 0.6967, Test Accuracy: 0.5426 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0815832614898682\n",
      "Epoch 48, Train Loss: 0.6971, Val Loss: 0.6967, Test Accuracy: 0.5387 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0824062824249268\n",
      "Epoch 49, Train Loss: 0.6989, Val Loss: 0.6965, Test Accuracy: 0.5426 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0794012546539307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:07:46,519] Trial 34 finished with value: 0.5491480996068152 and parameters: {'HIDDEN_DIMENSION': 105, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.14966247208926836, 'LEARNING_RATE': 4.166193656815446e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6977, Val Loss: 0.6967, Test Accuracy: 0.5400 ,Learning Rate: 4.166193656815446e-05 , Time Taken : 1.0856962203979492\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 115, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1809658406516671, 'LEARNING_RATE': 5.323609269291836e-05}\n",
      "Epoch 1, Train Loss: 0.7892, Val Loss: 0.7372, Test Accuracy: 0.5426 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.31991147994995117\n",
      "Epoch 2, Train Loss: 0.7840, Val Loss: 0.7363, Test Accuracy: 0.5347 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32100796699523926\n",
      "Epoch 3, Train Loss: 0.7786, Val Loss: 0.7354, Test Accuracy: 0.5282 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.33553361892700195\n",
      "Epoch 4, Train Loss: 0.7809, Val Loss: 0.7346, Test Accuracy: 0.5269 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32142114639282227\n",
      "Epoch 5, Train Loss: 0.7797, Val Loss: 0.7337, Test Accuracy: 0.5151 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32054781913757324\n",
      "Epoch 6, Train Loss: 0.7740, Val Loss: 0.7328, Test Accuracy: 0.5072 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.332078218460083\n",
      "Epoch 7, Train Loss: 0.7692, Val Loss: 0.7320, Test Accuracy: 0.5046 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.327716588973999\n",
      "Epoch 8, Train Loss: 0.7609, Val Loss: 0.7312, Test Accuracy: 0.4967 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3206753730773926\n",
      "Epoch 9, Train Loss: 0.7657, Val Loss: 0.7304, Test Accuracy: 0.4915 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3182206153869629\n",
      "Epoch 10, Train Loss: 0.7595, Val Loss: 0.7297, Test Accuracy: 0.4902 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.5010256767272949\n",
      "Epoch 11, Train Loss: 0.7588, Val Loss: 0.7289, Test Accuracy: 0.4902 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3200075626373291\n",
      "Epoch 12, Train Loss: 0.7572, Val Loss: 0.7280, Test Accuracy: 0.4889 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3183767795562744\n",
      "Epoch 13, Train Loss: 0.7548, Val Loss: 0.7274, Test Accuracy: 0.4889 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3203561305999756\n",
      "Epoch 14, Train Loss: 0.7538, Val Loss: 0.7266, Test Accuracy: 0.4902 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32158517837524414\n",
      "Epoch 15, Train Loss: 0.7523, Val Loss: 0.7258, Test Accuracy: 0.4902 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32060980796813965\n",
      "Epoch 16, Train Loss: 0.7476, Val Loss: 0.7249, Test Accuracy: 0.4915 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.322052001953125\n",
      "Epoch 17, Train Loss: 0.7419, Val Loss: 0.7239, Test Accuracy: 0.4928 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3235297203063965\n",
      "Epoch 18, Train Loss: 0.7481, Val Loss: 0.7233, Test Accuracy: 0.4915 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3192474842071533\n",
      "Epoch 19, Train Loss: 0.7420, Val Loss: 0.7225, Test Accuracy: 0.4915 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32442235946655273\n",
      "Epoch 20, Train Loss: 0.7452, Val Loss: 0.7217, Test Accuracy: 0.4902 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3324592113494873\n",
      "Epoch 21, Train Loss: 0.7353, Val Loss: 0.7209, Test Accuracy: 0.4928 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.31799888610839844\n",
      "Epoch 22, Train Loss: 0.7370, Val Loss: 0.7202, Test Accuracy: 0.4941 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3326094150543213\n",
      "Epoch 23, Train Loss: 0.7366, Val Loss: 0.7195, Test Accuracy: 0.4967 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3200225830078125\n",
      "Epoch 24, Train Loss: 0.7378, Val Loss: 0.7187, Test Accuracy: 0.4980 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32559823989868164\n",
      "Epoch 25, Train Loss: 0.7306, Val Loss: 0.7181, Test Accuracy: 0.4941 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3232731819152832\n",
      "Epoch 26, Train Loss: 0.7319, Val Loss: 0.7174, Test Accuracy: 0.4954 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32601308822631836\n",
      "Epoch 27, Train Loss: 0.7304, Val Loss: 0.7166, Test Accuracy: 0.4954 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32347631454467773\n",
      "Epoch 28, Train Loss: 0.7324, Val Loss: 0.7159, Test Accuracy: 0.4941 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3204817771911621\n",
      "Epoch 29, Train Loss: 0.7231, Val Loss: 0.7154, Test Accuracy: 0.4980 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3180258274078369\n",
      "Epoch 30, Train Loss: 0.7259, Val Loss: 0.7147, Test Accuracy: 0.4967 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3222842216491699\n",
      "Epoch 31, Train Loss: 0.7252, Val Loss: 0.7140, Test Accuracy: 0.4993 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32267212867736816\n",
      "Epoch 32, Train Loss: 0.7243, Val Loss: 0.7135, Test Accuracy: 0.5020 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32393980026245117\n",
      "Epoch 33, Train Loss: 0.7222, Val Loss: 0.7126, Test Accuracy: 0.5085 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3270707130432129\n",
      "Epoch 34, Train Loss: 0.7207, Val Loss: 0.7121, Test Accuracy: 0.5085 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32325291633605957\n",
      "Epoch 35, Train Loss: 0.7227, Val Loss: 0.7114, Test Accuracy: 0.5072 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3245992660522461\n",
      "Epoch 36, Train Loss: 0.7239, Val Loss: 0.7109, Test Accuracy: 0.5059 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3328733444213867\n",
      "Epoch 37, Train Loss: 0.7201, Val Loss: 0.7103, Test Accuracy: 0.5059 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3228776454925537\n",
      "Epoch 38, Train Loss: 0.7175, Val Loss: 0.7099, Test Accuracy: 0.5046 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32299017906188965\n",
      "Epoch 39, Train Loss: 0.7221, Val Loss: 0.7095, Test Accuracy: 0.5046 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3220517635345459\n",
      "Epoch 40, Train Loss: 0.7184, Val Loss: 0.7090, Test Accuracy: 0.5046 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.323486328125\n",
      "Epoch 41, Train Loss: 0.7164, Val Loss: 0.7086, Test Accuracy: 0.5020 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32673168182373047\n",
      "Epoch 42, Train Loss: 0.7161, Val Loss: 0.7080, Test Accuracy: 0.5020 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3210790157318115\n",
      "Epoch 43, Train Loss: 0.7146, Val Loss: 0.7075, Test Accuracy: 0.5033 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3222827911376953\n",
      "Epoch 44, Train Loss: 0.7152, Val Loss: 0.7073, Test Accuracy: 0.4993 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32875537872314453\n",
      "Epoch 45, Train Loss: 0.7178, Val Loss: 0.7068, Test Accuracy: 0.4993 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.324815034866333\n",
      "Epoch 46, Train Loss: 0.7144, Val Loss: 0.7063, Test Accuracy: 0.4993 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3204333782196045\n",
      "Epoch 47, Train Loss: 0.7134, Val Loss: 0.7059, Test Accuracy: 0.5020 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32039618492126465\n",
      "Epoch 48, Train Loss: 0.7130, Val Loss: 0.7055, Test Accuracy: 0.5020 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3223724365234375\n",
      "Epoch 49, Train Loss: 0.7108, Val Loss: 0.7050, Test Accuracy: 0.5007 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.3234975337982178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:08:02,946] Trial 35 finished with value: 0.4744429882044561 and parameters: {'HIDDEN_DIMENSION': 115, 'NO_OF_LAYERS': 1, 'BATCH_SIZE': 512, 'DROP_OUT': 0.1809658406516671, 'LEARNING_RATE': 5.323609269291836e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.7092, Val Loss: 0.7046, Test Accuracy: 0.4980 ,Learning Rate: 5.323609269291836e-05 , Time Taken : 0.32146358489990234\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 123, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 1024, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.15542408521463152, 'LEARNING_RATE': 0.0001559222732976138}\n",
      "Epoch 1, Train Loss: 0.7608, Val Loss: 0.7558, Test Accuracy: 0.4915 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8301513195037842\n",
      "Epoch 2, Train Loss: 0.7471, Val Loss: 0.7436, Test Accuracy: 0.4967 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8182761669158936\n",
      "Epoch 3, Train Loss: 0.7398, Val Loss: 0.7332, Test Accuracy: 0.4967 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.9928367137908936\n",
      "Epoch 4, Train Loss: 0.7268, Val Loss: 0.7253, Test Accuracy: 0.5059 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8137326240539551\n",
      "Epoch 5, Train Loss: 0.7198, Val Loss: 0.7206, Test Accuracy: 0.5085 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8154518604278564\n",
      "Epoch 6, Train Loss: 0.7194, Val Loss: 0.7158, Test Accuracy: 0.5072 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8097748756408691\n",
      "Epoch 7, Train Loss: 0.7161, Val Loss: 0.7120, Test Accuracy: 0.5072 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8092663288116455\n",
      "Epoch 8, Train Loss: 0.7141, Val Loss: 0.7088, Test Accuracy: 0.5085 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8173158168792725\n",
      "Epoch 9, Train Loss: 0.7146, Val Loss: 0.7058, Test Accuracy: 0.5138 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8159456253051758\n",
      "Epoch 10, Train Loss: 0.7078, Val Loss: 0.7042, Test Accuracy: 0.5190 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8160016536712646\n",
      "Epoch 11, Train Loss: 0.7053, Val Loss: 0.7022, Test Accuracy: 0.5203 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8090405464172363\n",
      "Epoch 12, Train Loss: 0.7061, Val Loss: 0.7008, Test Accuracy: 0.5151 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8157331943511963\n",
      "Epoch 13, Train Loss: 0.7017, Val Loss: 0.6987, Test Accuracy: 0.5190 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8113634586334229\n",
      "Epoch 14, Train Loss: 0.7042, Val Loss: 0.6987, Test Accuracy: 0.5190 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8156442642211914\n",
      "Epoch 15, Train Loss: 0.7035, Val Loss: 0.6981, Test Accuracy: 0.5164 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8180506229400635\n",
      "Epoch 16, Train Loss: 0.7034, Val Loss: 0.6971, Test Accuracy: 0.5216 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8082230091094971\n",
      "Epoch 17, Train Loss: 0.7001, Val Loss: 0.6961, Test Accuracy: 0.5203 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8184754848480225\n",
      "Epoch 18, Train Loss: 0.7011, Val Loss: 0.6952, Test Accuracy: 0.5229 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8171687126159668\n",
      "Epoch 19, Train Loss: 0.6993, Val Loss: 0.6948, Test Accuracy: 0.5190 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8162784576416016\n",
      "Epoch 20, Train Loss: 0.6942, Val Loss: 0.6947, Test Accuracy: 0.5177 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8262951374053955\n",
      "Epoch 21, Train Loss: 0.6993, Val Loss: 0.6953, Test Accuracy: 0.5125 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8192589282989502\n",
      "Epoch 22, Train Loss: 0.6978, Val Loss: 0.6934, Test Accuracy: 0.5138 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8249356746673584\n",
      "Epoch 23, Train Loss: 0.6959, Val Loss: 0.6919, Test Accuracy: 0.5138 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8120110034942627\n",
      "Epoch 24, Train Loss: 0.6967, Val Loss: 0.6915, Test Accuracy: 0.5177 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8177411556243896\n",
      "Epoch 25, Train Loss: 0.6959, Val Loss: 0.6921, Test Accuracy: 0.5151 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8145380020141602\n",
      "Epoch 26, Train Loss: 0.6975, Val Loss: 0.6933, Test Accuracy: 0.5177 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8245794773101807\n",
      "Epoch 27, Train Loss: 0.6963, Val Loss: 0.6938, Test Accuracy: 0.5177 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8177318572998047\n",
      "Epoch 28, Train Loss: 0.6963, Val Loss: 0.6921, Test Accuracy: 0.5164 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8144474029541016\n",
      "Epoch 29, Train Loss: 0.6911, Val Loss: 0.6913, Test Accuracy: 0.5190 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8254103660583496\n",
      "Epoch 30, Train Loss: 0.6937, Val Loss: 0.6912, Test Accuracy: 0.5203 ,Learning Rate: 0.0001559222732976138 , Time Taken : 1.0276520252227783\n",
      "Epoch 31, Train Loss: 0.6961, Val Loss: 0.6917, Test Accuracy: 0.5190 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8138442039489746\n",
      "Epoch 32, Train Loss: 0.6917, Val Loss: 0.6920, Test Accuracy: 0.5164 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8132171630859375\n",
      "Epoch 33, Train Loss: 0.6919, Val Loss: 0.6923, Test Accuracy: 0.5111 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8189835548400879\n",
      "Epoch 34, Train Loss: 0.6943, Val Loss: 0.6919, Test Accuracy: 0.5164 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8197810649871826\n",
      "Epoch 35, Train Loss: 0.6904, Val Loss: 0.6918, Test Accuracy: 0.5177 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8173635005950928\n",
      "Epoch 36, Train Loss: 0.6933, Val Loss: 0.6909, Test Accuracy: 0.5216 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8182673454284668\n",
      "Epoch 37, Train Loss: 0.6915, Val Loss: 0.6911, Test Accuracy: 0.5216 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8193082809448242\n",
      "Epoch 38, Train Loss: 0.6898, Val Loss: 0.6908, Test Accuracy: 0.5190 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.818789005279541\n",
      "Epoch 39, Train Loss: 0.6917, Val Loss: 0.6905, Test Accuracy: 0.5229 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.814887523651123\n",
      "Epoch 40, Train Loss: 0.6919, Val Loss: 0.6891, Test Accuracy: 0.5334 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8256440162658691\n",
      "Epoch 41, Train Loss: 0.6908, Val Loss: 0.6885, Test Accuracy: 0.5374 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8147943019866943\n",
      "Epoch 42, Train Loss: 0.6915, Val Loss: 0.6888, Test Accuracy: 0.5360 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8120660781860352\n",
      "Epoch 43, Train Loss: 0.6925, Val Loss: 0.6897, Test Accuracy: 0.5334 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8168795108795166\n",
      "Epoch 44, Train Loss: 0.6940, Val Loss: 0.6900, Test Accuracy: 0.5295 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.81974196434021\n",
      "Epoch 45, Train Loss: 0.6889, Val Loss: 0.6887, Test Accuracy: 0.5413 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8137571811676025\n",
      "Epoch 46, Train Loss: 0.6914, Val Loss: 0.6888, Test Accuracy: 0.5387 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8106534481048584\n",
      "Epoch 47, Train Loss: 0.6935, Val Loss: 0.6896, Test Accuracy: 0.5374 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8180932998657227\n",
      "Epoch 48, Train Loss: 0.6886, Val Loss: 0.6895, Test Accuracy: 0.5374 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.809537410736084\n",
      "Epoch 49, Train Loss: 0.6910, Val Loss: 0.6897, Test Accuracy: 0.5374 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8122386932373047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:08:44,274] Trial 36 finished with value: 0.5137614678899083 and parameters: {'HIDDEN_DIMENSION': 123, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 1024, 'DROP_OUT': 0.15542408521463152, 'LEARNING_RATE': 0.0001559222732976138}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6867, Val Loss: 0.6899, Test Accuracy: 0.5374 ,Learning Rate: 0.0001559222732976138 , Time Taken : 0.8156008720397949\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 81, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.12911828783119172, 'LEARNING_RATE': 7.315116998505808e-05}\n",
      "Epoch 1, Train Loss: 0.7997, Val Loss: 0.8118, Test Accuracy: 0.4561 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0615599155426025\n",
      "Epoch 2, Train Loss: 0.7830, Val Loss: 0.7816, Test Accuracy: 0.4731 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0664887428283691\n",
      "Epoch 3, Train Loss: 0.7682, Val Loss: 0.7596, Test Accuracy: 0.4875 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0597727298736572\n",
      "Epoch 4, Train Loss: 0.7565, Val Loss: 0.7469, Test Accuracy: 0.5020 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0667893886566162\n",
      "Epoch 5, Train Loss: 0.7526, Val Loss: 0.7380, Test Accuracy: 0.5085 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0682027339935303\n",
      "Epoch 6, Train Loss: 0.7538, Val Loss: 0.7320, Test Accuracy: 0.5098 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0661580562591553\n",
      "Epoch 7, Train Loss: 0.7363, Val Loss: 0.7270, Test Accuracy: 0.5059 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0587034225463867\n",
      "Epoch 8, Train Loss: 0.7339, Val Loss: 0.7238, Test Accuracy: 0.5046 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0722177028656006\n",
      "Epoch 9, Train Loss: 0.7318, Val Loss: 0.7205, Test Accuracy: 0.5085 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0593736171722412\n",
      "Epoch 10, Train Loss: 0.7269, Val Loss: 0.7178, Test Accuracy: 0.5059 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0708558559417725\n",
      "Epoch 11, Train Loss: 0.7274, Val Loss: 0.7145, Test Accuracy: 0.5072 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0794966220855713\n",
      "Epoch 12, Train Loss: 0.7207, Val Loss: 0.7109, Test Accuracy: 0.5085 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0764784812927246\n",
      "Epoch 13, Train Loss: 0.7182, Val Loss: 0.7092, Test Accuracy: 0.5046 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0652296543121338\n",
      "Epoch 14, Train Loss: 0.7125, Val Loss: 0.7090, Test Accuracy: 0.5111 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0660371780395508\n",
      "Epoch 15, Train Loss: 0.7129, Val Loss: 0.7065, Test Accuracy: 0.5033 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0720527172088623\n",
      "Epoch 16, Train Loss: 0.7108, Val Loss: 0.7061, Test Accuracy: 0.5059 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0670623779296875\n",
      "Epoch 17, Train Loss: 0.7101, Val Loss: 0.7046, Test Accuracy: 0.5111 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.062220573425293\n",
      "Epoch 18, Train Loss: 0.7075, Val Loss: 0.7037, Test Accuracy: 0.5085 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0701327323913574\n",
      "Epoch 19, Train Loss: 0.7112, Val Loss: 0.7026, Test Accuracy: 0.5085 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0799267292022705\n",
      "Epoch 20, Train Loss: 0.7092, Val Loss: 0.7016, Test Accuracy: 0.5098 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.2489588260650635\n",
      "Epoch 21, Train Loss: 0.7069, Val Loss: 0.7011, Test Accuracy: 0.5111 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0648772716522217\n",
      "Epoch 22, Train Loss: 0.7042, Val Loss: 0.7004, Test Accuracy: 0.5085 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0652005672454834\n",
      "Epoch 23, Train Loss: 0.7045, Val Loss: 0.6991, Test Accuracy: 0.5151 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.065260648727417\n",
      "Epoch 24, Train Loss: 0.7007, Val Loss: 0.6986, Test Accuracy: 0.5138 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0694756507873535\n",
      "Epoch 25, Train Loss: 0.7050, Val Loss: 0.6984, Test Accuracy: 0.5125 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0577483177185059\n",
      "Epoch 26, Train Loss: 0.7024, Val Loss: 0.6976, Test Accuracy: 0.5190 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0828075408935547\n",
      "Epoch 27, Train Loss: 0.6998, Val Loss: 0.6976, Test Accuracy: 0.5164 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0700805187225342\n",
      "Epoch 28, Train Loss: 0.6996, Val Loss: 0.6969, Test Accuracy: 0.5177 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0718839168548584\n",
      "Epoch 29, Train Loss: 0.7012, Val Loss: 0.6968, Test Accuracy: 0.5138 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0595109462738037\n",
      "Epoch 30, Train Loss: 0.7035, Val Loss: 0.6970, Test Accuracy: 0.5151 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0677845478057861\n",
      "Epoch 31, Train Loss: 0.7016, Val Loss: 0.6966, Test Accuracy: 0.5190 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0660874843597412\n",
      "Epoch 32, Train Loss: 0.6984, Val Loss: 0.6959, Test Accuracy: 0.5164 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0676343441009521\n",
      "Epoch 33, Train Loss: 0.6970, Val Loss: 0.6955, Test Accuracy: 0.5190 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0735340118408203\n",
      "Epoch 34, Train Loss: 0.6985, Val Loss: 0.6953, Test Accuracy: 0.5229 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0756659507751465\n",
      "Epoch 35, Train Loss: 0.6992, Val Loss: 0.6957, Test Accuracy: 0.5190 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0754175186157227\n",
      "Epoch 36, Train Loss: 0.6970, Val Loss: 0.6958, Test Accuracy: 0.5216 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0592575073242188\n",
      "Epoch 37, Train Loss: 0.6987, Val Loss: 0.6954, Test Accuracy: 0.5242 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.065760612487793\n",
      "Epoch 38, Train Loss: 0.6996, Val Loss: 0.6952, Test Accuracy: 0.5242 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.060044288635254\n",
      "Epoch 39, Train Loss: 0.6994, Val Loss: 0.6949, Test Accuracy: 0.5282 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0719096660614014\n",
      "Epoch 40, Train Loss: 0.6978, Val Loss: 0.6944, Test Accuracy: 0.5321 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0706939697265625\n",
      "Epoch 41, Train Loss: 0.6970, Val Loss: 0.6943, Test Accuracy: 0.5321 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0772171020507812\n",
      "Epoch 42, Train Loss: 0.6957, Val Loss: 0.6949, Test Accuracy: 0.5282 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0722324848175049\n",
      "Epoch 43, Train Loss: 0.6950, Val Loss: 0.6947, Test Accuracy: 0.5308 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0653858184814453\n",
      "Epoch 44, Train Loss: 0.6952, Val Loss: 0.6949, Test Accuracy: 0.5256 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0618455410003662\n",
      "Epoch 45, Train Loss: 0.6944, Val Loss: 0.6949, Test Accuracy: 0.5242 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0685796737670898\n",
      "Epoch 46, Train Loss: 0.6956, Val Loss: 0.6943, Test Accuracy: 0.5295 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.066847562789917\n",
      "Epoch 47, Train Loss: 0.6948, Val Loss: 0.6939, Test Accuracy: 0.5321 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0656137466430664\n",
      "Epoch 48, Train Loss: 0.6959, Val Loss: 0.6933, Test Accuracy: 0.5282 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0724492073059082\n",
      "Epoch 49, Train Loss: 0.6954, Val Loss: 0.6942, Test Accuracy: 0.5295 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.073549747467041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:09:37,997] Trial 37 finished with value: 0.5137614678899083 and parameters: {'HIDDEN_DIMENSION': 81, 'NO_OF_LAYERS': 4, 'BATCH_SIZE': 512, 'DROP_OUT': 0.12911828783119172, 'LEARNING_RATE': 7.315116998505808e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6949, Val Loss: 0.6948, Test Accuracy: 0.5242 ,Learning Rate: 7.315116998505808e-05 , Time Taken : 1.0734615325927734\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 111, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 1024, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.20322226034280463, 'LEARNING_RATE': 0.0007091918897461489}\n",
      "Epoch 1, Train Loss: 0.7848, Val Loss: 0.7385, Test Accuracy: 0.4980 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.556424617767334\n",
      "Epoch 2, Train Loss: 0.7432, Val Loss: 0.7272, Test Accuracy: 0.4718 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5559473037719727\n",
      "Epoch 3, Train Loss: 0.7277, Val Loss: 0.7124, Test Accuracy: 0.4692 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.555349588394165\n",
      "Epoch 4, Train Loss: 0.7147, Val Loss: 0.7004, Test Accuracy: 0.5007 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5555503368377686\n",
      "Epoch 5, Train Loss: 0.7149, Val Loss: 0.6954, Test Accuracy: 0.5125 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5634329319000244\n",
      "Epoch 6, Train Loss: 0.7026, Val Loss: 0.6973, Test Accuracy: 0.5046 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5633158683776855\n",
      "Epoch 7, Train Loss: 0.7036, Val Loss: 0.7009, Test Accuracy: 0.4849 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5533308982849121\n",
      "Epoch 8, Train Loss: 0.7023, Val Loss: 0.6984, Test Accuracy: 0.4928 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5636587142944336\n",
      "Epoch 9, Train Loss: 0.6989, Val Loss: 0.6928, Test Accuracy: 0.5426 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5553081035614014\n",
      "Epoch 10, Train Loss: 0.6968, Val Loss: 0.6908, Test Accuracy: 0.5439 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5516822338104248\n",
      "Epoch 11, Train Loss: 0.6972, Val Loss: 0.6920, Test Accuracy: 0.5321 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5571322441101074\n",
      "Epoch 12, Train Loss: 0.6938, Val Loss: 0.6930, Test Accuracy: 0.5308 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5588173866271973\n",
      "Epoch 13, Train Loss: 0.6941, Val Loss: 0.6930, Test Accuracy: 0.5308 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5629363059997559\n",
      "Epoch 14, Train Loss: 0.6973, Val Loss: 0.6911, Test Accuracy: 0.5269 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5537927150726318\n",
      "Epoch 15, Train Loss: 0.6918, Val Loss: 0.6920, Test Accuracy: 0.5334 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5610446929931641\n",
      "Epoch 16, Train Loss: 0.6926, Val Loss: 0.6918, Test Accuracy: 0.5321 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5589926242828369\n",
      "Epoch 17, Train Loss: 0.6889, Val Loss: 0.6923, Test Accuracy: 0.5295 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.560610294342041\n",
      "Epoch 18, Train Loss: 0.6925, Val Loss: 0.6916, Test Accuracy: 0.5308 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5569882392883301\n",
      "Epoch 19, Train Loss: 0.6920, Val Loss: 0.6903, Test Accuracy: 0.5321 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5585870742797852\n",
      "Epoch 20, Train Loss: 0.6898, Val Loss: 0.6904, Test Accuracy: 0.5360 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5644032955169678\n",
      "Epoch 21, Train Loss: 0.6923, Val Loss: 0.6907, Test Accuracy: 0.5347 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5606241226196289\n",
      "Epoch 22, Train Loss: 0.6896, Val Loss: 0.6922, Test Accuracy: 0.5177 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.553478479385376\n",
      "Epoch 23, Train Loss: 0.6879, Val Loss: 0.6917, Test Accuracy: 0.5229 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5568718910217285\n",
      "Epoch 24, Train Loss: 0.6903, Val Loss: 0.6901, Test Accuracy: 0.5282 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5676083564758301\n",
      "Epoch 25, Train Loss: 0.6862, Val Loss: 0.6897, Test Accuracy: 0.5295 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5591638088226318\n",
      "Epoch 26, Train Loss: 0.6857, Val Loss: 0.6899, Test Accuracy: 0.5295 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5546789169311523\n",
      "Epoch 27, Train Loss: 0.6897, Val Loss: 0.6910, Test Accuracy: 0.5256 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5621588230133057\n",
      "Epoch 28, Train Loss: 0.6891, Val Loss: 0.6934, Test Accuracy: 0.5203 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5603044033050537\n",
      "Epoch 29, Train Loss: 0.6863, Val Loss: 0.6938, Test Accuracy: 0.5190 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5545191764831543\n",
      "Epoch 30, Train Loss: 0.6857, Val Loss: 0.6925, Test Accuracy: 0.5229 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.7353651523590088\n",
      "Epoch 31, Train Loss: 0.6871, Val Loss: 0.6916, Test Accuracy: 0.5321 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.553093433380127\n",
      "Epoch 32, Train Loss: 0.6863, Val Loss: 0.6915, Test Accuracy: 0.5282 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.561518669128418\n",
      "Epoch 33, Train Loss: 0.6853, Val Loss: 0.6915, Test Accuracy: 0.5295 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5652422904968262\n",
      "Epoch 34, Train Loss: 0.6847, Val Loss: 0.6924, Test Accuracy: 0.5269 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5553054809570312\n",
      "Epoch 35, Train Loss: 0.6845, Val Loss: 0.6929, Test Accuracy: 0.5216 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.554450273513794\n",
      "Epoch 36, Train Loss: 0.6849, Val Loss: 0.6927, Test Accuracy: 0.5242 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.556286096572876\n",
      "Epoch 37, Train Loss: 0.6836, Val Loss: 0.6908, Test Accuracy: 0.5360 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5571048259735107\n",
      "Epoch 38, Train Loss: 0.6831, Val Loss: 0.6936, Test Accuracy: 0.5164 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5578792095184326\n",
      "Epoch 39, Train Loss: 0.6837, Val Loss: 0.6940, Test Accuracy: 0.5125 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5546786785125732\n",
      "Epoch 40, Train Loss: 0.6818, Val Loss: 0.6956, Test Accuracy: 0.5085 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5517048835754395\n",
      "Epoch 41, Train Loss: 0.6853, Val Loss: 0.6951, Test Accuracy: 0.5125 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5641665458679199\n",
      "Epoch 42, Train Loss: 0.6858, Val Loss: 0.6918, Test Accuracy: 0.5256 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5673737525939941\n",
      "Epoch 43, Train Loss: 0.6828, Val Loss: 0.6954, Test Accuracy: 0.5190 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5548198223114014\n",
      "Epoch 44, Train Loss: 0.6802, Val Loss: 0.6951, Test Accuracy: 0.5269 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5570383071899414\n",
      "Epoch 45, Train Loss: 0.6803, Val Loss: 0.6944, Test Accuracy: 0.5203 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5634462833404541\n",
      "Epoch 46, Train Loss: 0.6805, Val Loss: 0.6969, Test Accuracy: 0.5177 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5617256164550781\n",
      "Epoch 47, Train Loss: 0.6762, Val Loss: 0.6980, Test Accuracy: 0.5229 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5650680065155029\n",
      "Epoch 48, Train Loss: 0.6788, Val Loss: 0.6933, Test Accuracy: 0.5256 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5559823513031006\n",
      "Epoch 49, Train Loss: 0.6785, Val Loss: 0.6929, Test Accuracy: 0.5256 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5624628067016602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:10:06,200] Trial 38 finished with value: 0.5307994757536042 and parameters: {'HIDDEN_DIMENSION': 111, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 1024, 'DROP_OUT': 0.20322226034280463, 'LEARNING_RATE': 0.0007091918897461489}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6786, Val Loss: 0.6990, Test Accuracy: 0.5347 ,Learning Rate: 0.0007091918897461489 , Time Taken : 0.5573711395263672\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 105, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.11734031618354018, 'LEARNING_RATE': 9.206264103337276e-05}\n",
      "Epoch 1, Train Loss: 0.7384, Val Loss: 0.7189, Test Accuracy: 0.5046 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1602411270141602\n",
      "Epoch 2, Train Loss: 0.7171, Val Loss: 0.7075, Test Accuracy: 0.5007 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1710684299468994\n",
      "Epoch 3, Train Loss: 0.7080, Val Loss: 0.7045, Test Accuracy: 0.4980 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.174119234085083\n",
      "Epoch 4, Train Loss: 0.7082, Val Loss: 0.6976, Test Accuracy: 0.4967 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.177121639251709\n",
      "Epoch 5, Train Loss: 0.7032, Val Loss: 0.6997, Test Accuracy: 0.4941 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.172877550125122\n",
      "Epoch 6, Train Loss: 0.6992, Val Loss: 0.6959, Test Accuracy: 0.4954 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.173405647277832\n",
      "Epoch 7, Train Loss: 0.7014, Val Loss: 0.6962, Test Accuracy: 0.5007 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1834936141967773\n",
      "Epoch 8, Train Loss: 0.7012, Val Loss: 0.6928, Test Accuracy: 0.5085 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1759586334228516\n",
      "Epoch 9, Train Loss: 0.6966, Val Loss: 0.6951, Test Accuracy: 0.5059 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1672618389129639\n",
      "Epoch 10, Train Loss: 0.6954, Val Loss: 0.6956, Test Accuracy: 0.5059 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.179208755493164\n",
      "Epoch 11, Train Loss: 0.6955, Val Loss: 0.6944, Test Accuracy: 0.5125 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.173675775527954\n",
      "Epoch 12, Train Loss: 0.6943, Val Loss: 0.6937, Test Accuracy: 0.5059 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1739935874938965\n",
      "Epoch 13, Train Loss: 0.6921, Val Loss: 0.6945, Test Accuracy: 0.5072 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1768298149108887\n",
      "Epoch 14, Train Loss: 0.6942, Val Loss: 0.6924, Test Accuracy: 0.5177 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1673648357391357\n",
      "Epoch 15, Train Loss: 0.6933, Val Loss: 0.6928, Test Accuracy: 0.5085 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1710751056671143\n",
      "Epoch 16, Train Loss: 0.6928, Val Loss: 0.6936, Test Accuracy: 0.5059 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.173759937286377\n",
      "Epoch 17, Train Loss: 0.6950, Val Loss: 0.6939, Test Accuracy: 0.5033 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1689224243164062\n",
      "Epoch 18, Train Loss: 0.6903, Val Loss: 0.6906, Test Accuracy: 0.5282 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1727592945098877\n",
      "Epoch 19, Train Loss: 0.6947, Val Loss: 0.6921, Test Accuracy: 0.4993 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1779279708862305\n",
      "Epoch 20, Train Loss: 0.6917, Val Loss: 0.6959, Test Accuracy: 0.4941 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1770715713500977\n",
      "Epoch 21, Train Loss: 0.6911, Val Loss: 0.6930, Test Accuracy: 0.4954 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1743106842041016\n",
      "Epoch 22, Train Loss: 0.6924, Val Loss: 0.6919, Test Accuracy: 0.4993 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1706042289733887\n",
      "Epoch 23, Train Loss: 0.6923, Val Loss: 0.6932, Test Accuracy: 0.4954 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.174077033996582\n",
      "Epoch 24, Train Loss: 0.6901, Val Loss: 0.6935, Test Accuracy: 0.4941 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1751818656921387\n",
      "Epoch 25, Train Loss: 0.6905, Val Loss: 0.6953, Test Accuracy: 0.4862 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1758770942687988\n",
      "Epoch 26, Train Loss: 0.6902, Val Loss: 0.6905, Test Accuracy: 0.5203 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.166940450668335\n",
      "Epoch 27, Train Loss: 0.6886, Val Loss: 0.6921, Test Accuracy: 0.5059 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.171156406402588\n",
      "Epoch 28, Train Loss: 0.6894, Val Loss: 0.6955, Test Accuracy: 0.4928 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1748616695404053\n",
      "Epoch 29, Train Loss: 0.6879, Val Loss: 0.6937, Test Accuracy: 0.5046 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1771776676177979\n",
      "Epoch 30, Train Loss: 0.6886, Val Loss: 0.6912, Test Accuracy: 0.5111 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1795494556427002\n",
      "Epoch 31, Train Loss: 0.6872, Val Loss: 0.6944, Test Accuracy: 0.5020 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.167292833328247\n",
      "Epoch 32, Train Loss: 0.6886, Val Loss: 0.6934, Test Accuracy: 0.5098 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1768221855163574\n",
      "Epoch 33, Train Loss: 0.6861, Val Loss: 0.6888, Test Accuracy: 0.5387 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1786372661590576\n",
      "Epoch 34, Train Loss: 0.6873, Val Loss: 0.6885, Test Accuracy: 0.5360 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1741070747375488\n",
      "Epoch 35, Train Loss: 0.6878, Val Loss: 0.6936, Test Accuracy: 0.5151 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1542320251464844\n",
      "Epoch 36, Train Loss: 0.6862, Val Loss: 0.6901, Test Accuracy: 0.5190 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1712307929992676\n",
      "Epoch 37, Train Loss: 0.6856, Val Loss: 0.6919, Test Accuracy: 0.5229 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1713039875030518\n",
      "Epoch 38, Train Loss: 0.6862, Val Loss: 0.6896, Test Accuracy: 0.5242 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1713228225708008\n",
      "Epoch 39, Train Loss: 0.6841, Val Loss: 0.6906, Test Accuracy: 0.5203 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.178734540939331\n",
      "Epoch 40, Train Loss: 0.6844, Val Loss: 0.6884, Test Accuracy: 0.5334 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1759605407714844\n",
      "Epoch 41, Train Loss: 0.6841, Val Loss: 0.6946, Test Accuracy: 0.5111 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1760387420654297\n",
      "Epoch 42, Train Loss: 0.6841, Val Loss: 0.6928, Test Accuracy: 0.5229 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1758019924163818\n",
      "Epoch 43, Train Loss: 0.6816, Val Loss: 0.6893, Test Accuracy: 0.5308 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1703221797943115\n",
      "Epoch 44, Train Loss: 0.6832, Val Loss: 0.6875, Test Accuracy: 0.5374 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1741225719451904\n",
      "Epoch 45, Train Loss: 0.6819, Val Loss: 0.6961, Test Accuracy: 0.5059 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.179349660873413\n",
      "Epoch 46, Train Loss: 0.6822, Val Loss: 0.6927, Test Accuracy: 0.5164 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1735124588012695\n",
      "Epoch 47, Train Loss: 0.6830, Val Loss: 0.6944, Test Accuracy: 0.5111 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1675610542297363\n",
      "Epoch 48, Train Loss: 0.6795, Val Loss: 0.6917, Test Accuracy: 0.5256 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.173591136932373\n",
      "Epoch 49, Train Loss: 0.6801, Val Loss: 0.6949, Test Accuracy: 0.5138 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1725716590881348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:11:04,999] Trial 39 finished with value: 0.5583224115334207 and parameters: {'HIDDEN_DIMENSION': 105, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.11734031618354018, 'LEARNING_RATE': 9.206264103337276e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6786, Val Loss: 0.6928, Test Accuracy: 0.5229 ,Learning Rate: 9.206264103337276e-05 , Time Taken : 1.1900913715362549\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 91, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.11525760804436458, 'LEARNING_RATE': 8.529474801455852e-05}\n",
      "Epoch 1, Train Loss: 0.7567, Val Loss: 0.7322, Test Accuracy: 0.5020 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1611549854278564\n",
      "Epoch 2, Train Loss: 0.7368, Val Loss: 0.7175, Test Accuracy: 0.5125 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1605126857757568\n",
      "Epoch 3, Train Loss: 0.7223, Val Loss: 0.7089, Test Accuracy: 0.5111 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1750624179840088\n",
      "Epoch 4, Train Loss: 0.7133, Val Loss: 0.7025, Test Accuracy: 0.5138 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.170781135559082\n",
      "Epoch 5, Train Loss: 0.7094, Val Loss: 0.7013, Test Accuracy: 0.5151 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1771588325500488\n",
      "Epoch 6, Train Loss: 0.7036, Val Loss: 0.7007, Test Accuracy: 0.5098 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1703627109527588\n",
      "Epoch 7, Train Loss: 0.6992, Val Loss: 0.6998, Test Accuracy: 0.5085 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1719348430633545\n",
      "Epoch 8, Train Loss: 0.7000, Val Loss: 0.6974, Test Accuracy: 0.5216 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1685121059417725\n",
      "Epoch 9, Train Loss: 0.7000, Val Loss: 0.6973, Test Accuracy: 0.5269 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1695549488067627\n",
      "Epoch 10, Train Loss: 0.6982, Val Loss: 0.6957, Test Accuracy: 0.5308 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1677672863006592\n",
      "Epoch 11, Train Loss: 0.6948, Val Loss: 0.6961, Test Accuracy: 0.5308 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.176265001296997\n",
      "Epoch 12, Train Loss: 0.6948, Val Loss: 0.6953, Test Accuracy: 0.5282 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.172088623046875\n",
      "Epoch 13, Train Loss: 0.6949, Val Loss: 0.6947, Test Accuracy: 0.5282 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1712286472320557\n",
      "Epoch 14, Train Loss: 0.6916, Val Loss: 0.6959, Test Accuracy: 0.5282 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1764285564422607\n",
      "Epoch 15, Train Loss: 0.6942, Val Loss: 0.6962, Test Accuracy: 0.5242 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.174987554550171\n",
      "Epoch 16, Train Loss: 0.6946, Val Loss: 0.6941, Test Accuracy: 0.5321 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1653220653533936\n",
      "Epoch 17, Train Loss: 0.6931, Val Loss: 0.6968, Test Accuracy: 0.5216 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.16534423828125\n",
      "Epoch 18, Train Loss: 0.6957, Val Loss: 0.6946, Test Accuracy: 0.5269 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.174447774887085\n",
      "Epoch 19, Train Loss: 0.6889, Val Loss: 0.6928, Test Accuracy: 0.5347 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.16568922996521\n",
      "Epoch 20, Train Loss: 0.6907, Val Loss: 0.6935, Test Accuracy: 0.5387 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1718814373016357\n",
      "Epoch 21, Train Loss: 0.6937, Val Loss: 0.6943, Test Accuracy: 0.5347 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.166259527206421\n",
      "Epoch 22, Train Loss: 0.6898, Val Loss: 0.6927, Test Accuracy: 0.5374 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1605637073516846\n",
      "Epoch 23, Train Loss: 0.6906, Val Loss: 0.6928, Test Accuracy: 0.5347 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.174710988998413\n",
      "Epoch 24, Train Loss: 0.6903, Val Loss: 0.6935, Test Accuracy: 0.5374 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1631653308868408\n",
      "Epoch 25, Train Loss: 0.6903, Val Loss: 0.6932, Test Accuracy: 0.5347 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1690890789031982\n",
      "Epoch 26, Train Loss: 0.6906, Val Loss: 0.6936, Test Accuracy: 0.5203 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1699702739715576\n",
      "Epoch 27, Train Loss: 0.6904, Val Loss: 0.6946, Test Accuracy: 0.5190 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1635785102844238\n",
      "Epoch 28, Train Loss: 0.6879, Val Loss: 0.6910, Test Accuracy: 0.5334 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.165038824081421\n",
      "Epoch 29, Train Loss: 0.6894, Val Loss: 0.6932, Test Accuracy: 0.5190 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1636157035827637\n",
      "Epoch 30, Train Loss: 0.6864, Val Loss: 0.6950, Test Accuracy: 0.5151 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1601855754852295\n",
      "Epoch 31, Train Loss: 0.6891, Val Loss: 0.6932, Test Accuracy: 0.5203 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1629538536071777\n",
      "Epoch 32, Train Loss: 0.6867, Val Loss: 0.6935, Test Accuracy: 0.5216 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1525003910064697\n",
      "Epoch 33, Train Loss: 0.6865, Val Loss: 0.6932, Test Accuracy: 0.5242 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1231293678283691\n",
      "Epoch 34, Train Loss: 0.6846, Val Loss: 0.6947, Test Accuracy: 0.5203 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1242473125457764\n",
      "Epoch 35, Train Loss: 0.6869, Val Loss: 0.6928, Test Accuracy: 0.5242 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1682796478271484\n",
      "Epoch 36, Train Loss: 0.6848, Val Loss: 0.6952, Test Accuracy: 0.5282 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1741175651550293\n",
      "Epoch 37, Train Loss: 0.6852, Val Loss: 0.6954, Test Accuracy: 0.5347 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1794712543487549\n",
      "Epoch 38, Train Loss: 0.6852, Val Loss: 0.6944, Test Accuracy: 0.5374 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1734178066253662\n",
      "Epoch 39, Train Loss: 0.6865, Val Loss: 0.6959, Test Accuracy: 0.5334 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1698224544525146\n",
      "Epoch 40, Train Loss: 0.6861, Val Loss: 0.6934, Test Accuracy: 0.5426 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1678650379180908\n",
      "Epoch 41, Train Loss: 0.6861, Val Loss: 0.6914, Test Accuracy: 0.5308 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1771774291992188\n",
      "Epoch 42, Train Loss: 0.6847, Val Loss: 0.6914, Test Accuracy: 0.5334 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1732239723205566\n",
      "Epoch 43, Train Loss: 0.6846, Val Loss: 0.6929, Test Accuracy: 0.5347 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1715202331542969\n",
      "Epoch 44, Train Loss: 0.6840, Val Loss: 0.6951, Test Accuracy: 0.5387 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1675336360931396\n",
      "Epoch 45, Train Loss: 0.6819, Val Loss: 0.6936, Test Accuracy: 0.5374 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1657226085662842\n",
      "Epoch 46, Train Loss: 0.6833, Val Loss: 0.6938, Test Accuracy: 0.5387 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1679317951202393\n",
      "Epoch 47, Train Loss: 0.6837, Val Loss: 0.6927, Test Accuracy: 0.5360 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1726109981536865\n",
      "Epoch 48, Train Loss: 0.6809, Val Loss: 0.6953, Test Accuracy: 0.5282 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1678166389465332\n",
      "Epoch 49, Train Loss: 0.6827, Val Loss: 0.6944, Test Accuracy: 0.5295 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1923043727874756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:12:03,497] Trial 40 finished with value: 0.5674967234600262 and parameters: {'HIDDEN_DIMENSION': 91, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.11525760804436458, 'LEARNING_RATE': 8.529474801455852e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6836, Val Loss: 0.6932, Test Accuracy: 0.5308 ,Learning Rate: 8.529474801455852e-05 , Time Taken : 1.1642193794250488\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 91, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.11652387655276188, 'LEARNING_RATE': 8.370355332160775e-05}\n",
      "Epoch 1, Train Loss: 0.7604, Val Loss: 0.7352, Test Accuracy: 0.4993 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.17409086227417\n",
      "Epoch 2, Train Loss: 0.7343, Val Loss: 0.7202, Test Accuracy: 0.5046 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1721837520599365\n",
      "Epoch 3, Train Loss: 0.7213, Val Loss: 0.7125, Test Accuracy: 0.4928 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1537458896636963\n",
      "Epoch 4, Train Loss: 0.7089, Val Loss: 0.7042, Test Accuracy: 0.5007 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1694440841674805\n",
      "Epoch 5, Train Loss: 0.7062, Val Loss: 0.7051, Test Accuracy: 0.4875 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1722586154937744\n",
      "Epoch 6, Train Loss: 0.6992, Val Loss: 0.7015, Test Accuracy: 0.4902 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1674396991729736\n",
      "Epoch 7, Train Loss: 0.6983, Val Loss: 0.7000, Test Accuracy: 0.4836 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1705663204193115\n",
      "Epoch 8, Train Loss: 0.6988, Val Loss: 0.7010, Test Accuracy: 0.4600 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1738574504852295\n",
      "Epoch 9, Train Loss: 0.6953, Val Loss: 0.6976, Test Accuracy: 0.4810 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1660575866699219\n",
      "Epoch 10, Train Loss: 0.6945, Val Loss: 0.6973, Test Accuracy: 0.4797 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1736972332000732\n",
      "Epoch 11, Train Loss: 0.6944, Val Loss: 0.6971, Test Accuracy: 0.4784 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1738123893737793\n",
      "Epoch 12, Train Loss: 0.6946, Val Loss: 0.6978, Test Accuracy: 0.4784 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1677298545837402\n",
      "Epoch 13, Train Loss: 0.6918, Val Loss: 0.6967, Test Accuracy: 0.4889 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1847176551818848\n",
      "Epoch 14, Train Loss: 0.6922, Val Loss: 0.6961, Test Accuracy: 0.5007 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.166511058807373\n",
      "Epoch 15, Train Loss: 0.6901, Val Loss: 0.6975, Test Accuracy: 0.4993 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1700677871704102\n",
      "Epoch 16, Train Loss: 0.6909, Val Loss: 0.6990, Test Accuracy: 0.4993 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1759109497070312\n",
      "Epoch 17, Train Loss: 0.6888, Val Loss: 0.6957, Test Accuracy: 0.5059 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.169642448425293\n",
      "Epoch 18, Train Loss: 0.6910, Val Loss: 0.6941, Test Accuracy: 0.5098 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1727018356323242\n",
      "Epoch 19, Train Loss: 0.6867, Val Loss: 0.6986, Test Accuracy: 0.5125 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1676478385925293\n",
      "Epoch 20, Train Loss: 0.6881, Val Loss: 0.6993, Test Accuracy: 0.5059 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.182302713394165\n",
      "Epoch 21, Train Loss: 0.6882, Val Loss: 0.6957, Test Accuracy: 0.5098 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.175774097442627\n",
      "Epoch 22, Train Loss: 0.6854, Val Loss: 0.6959, Test Accuracy: 0.5098 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1758289337158203\n",
      "Epoch 23, Train Loss: 0.6855, Val Loss: 0.7005, Test Accuracy: 0.4941 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.17923903465271\n",
      "Epoch 24, Train Loss: 0.6872, Val Loss: 0.6985, Test Accuracy: 0.5072 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1763300895690918\n",
      "Epoch 25, Train Loss: 0.6850, Val Loss: 0.6981, Test Accuracy: 0.5046 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.173734426498413\n",
      "Epoch 26, Train Loss: 0.6873, Val Loss: 0.6960, Test Accuracy: 0.5020 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1640310287475586\n",
      "Epoch 27, Train Loss: 0.6838, Val Loss: 0.6983, Test Accuracy: 0.5125 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1764698028564453\n",
      "Epoch 28, Train Loss: 0.6834, Val Loss: 0.6962, Test Accuracy: 0.5098 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1728625297546387\n",
      "Epoch 29, Train Loss: 0.6833, Val Loss: 0.6982, Test Accuracy: 0.5111 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1738612651824951\n",
      "Epoch 30, Train Loss: 0.6845, Val Loss: 0.6984, Test Accuracy: 0.5085 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.180408000946045\n",
      "Epoch 31, Train Loss: 0.6838, Val Loss: 0.6955, Test Accuracy: 0.5177 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1759107112884521\n",
      "Epoch 32, Train Loss: 0.6804, Val Loss: 0.7027, Test Accuracy: 0.5085 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1489644050598145\n",
      "Epoch 33, Train Loss: 0.6816, Val Loss: 0.7021, Test Accuracy: 0.5098 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1711373329162598\n",
      "Epoch 34, Train Loss: 0.6804, Val Loss: 0.6990, Test Accuracy: 0.5138 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.162898302078247\n",
      "Epoch 35, Train Loss: 0.6812, Val Loss: 0.7022, Test Accuracy: 0.5072 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1599946022033691\n",
      "Epoch 36, Train Loss: 0.6820, Val Loss: 0.6988, Test Accuracy: 0.5216 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.174952507019043\n",
      "Epoch 37, Train Loss: 0.6808, Val Loss: 0.6985, Test Accuracy: 0.5164 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1693189144134521\n",
      "Epoch 38, Train Loss: 0.6824, Val Loss: 0.6989, Test Accuracy: 0.5164 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1701579093933105\n",
      "Epoch 39, Train Loss: 0.6818, Val Loss: 0.7044, Test Accuracy: 0.5046 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1766464710235596\n",
      "Epoch 40, Train Loss: 0.6810, Val Loss: 0.7002, Test Accuracy: 0.5164 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1755590438842773\n",
      "Epoch 41, Train Loss: 0.6794, Val Loss: 0.6995, Test Accuracy: 0.5242 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1694538593292236\n",
      "Epoch 42, Train Loss: 0.6815, Val Loss: 0.6998, Test Accuracy: 0.5151 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1672837734222412\n",
      "Epoch 43, Train Loss: 0.6791, Val Loss: 0.6961, Test Accuracy: 0.5164 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1743335723876953\n",
      "Epoch 44, Train Loss: 0.6772, Val Loss: 0.6985, Test Accuracy: 0.5190 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1653945446014404\n",
      "Epoch 45, Train Loss: 0.6773, Val Loss: 0.6996, Test Accuracy: 0.5164 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1684317588806152\n",
      "Epoch 46, Train Loss: 0.6769, Val Loss: 0.6980, Test Accuracy: 0.5138 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1766836643218994\n",
      "Epoch 47, Train Loss: 0.6751, Val Loss: 0.6998, Test Accuracy: 0.5203 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1692485809326172\n",
      "Epoch 48, Train Loss: 0.6737, Val Loss: 0.7007, Test Accuracy: 0.5229 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1828157901763916\n",
      "Epoch 49, Train Loss: 0.6761, Val Loss: 0.6975, Test Accuracy: 0.5164 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1774346828460693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:13:02,196] Trial 41 finished with value: 0.5543905635648755 and parameters: {'HIDDEN_DIMENSION': 91, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.11652387655276188, 'LEARNING_RATE': 8.370355332160775e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6752, Val Loss: 0.6975, Test Accuracy: 0.5151 ,Learning Rate: 8.370355332160775e-05 , Time Taken : 1.1707334518432617\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 66, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.11943138667310785, 'LEARNING_RATE': 6.47587421599366e-05}\n",
      "Epoch 1, Train Loss: 0.7750, Val Loss: 0.7528, Test Accuracy: 0.5007 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.174056053161621\n",
      "Epoch 2, Train Loss: 0.7477, Val Loss: 0.7377, Test Accuracy: 0.5085 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1596035957336426\n",
      "Epoch 3, Train Loss: 0.7294, Val Loss: 0.7281, Test Accuracy: 0.5046 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1460330486297607\n",
      "Epoch 4, Train Loss: 0.7273, Val Loss: 0.7202, Test Accuracy: 0.4941 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.128915786743164\n",
      "Epoch 5, Train Loss: 0.7182, Val Loss: 0.7145, Test Accuracy: 0.4836 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.167513132095337\n",
      "Epoch 6, Train Loss: 0.7137, Val Loss: 0.7105, Test Accuracy: 0.4849 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.158329963684082\n",
      "Epoch 7, Train Loss: 0.7068, Val Loss: 0.7076, Test Accuracy: 0.4849 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1659572124481201\n",
      "Epoch 8, Train Loss: 0.7054, Val Loss: 0.7054, Test Accuracy: 0.4771 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1662342548370361\n",
      "Epoch 9, Train Loss: 0.7072, Val Loss: 0.7050, Test Accuracy: 0.4679 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1690523624420166\n",
      "Epoch 10, Train Loss: 0.6987, Val Loss: 0.7013, Test Accuracy: 0.4862 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1630711555480957\n",
      "Epoch 11, Train Loss: 0.6997, Val Loss: 0.6992, Test Accuracy: 0.4862 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1656990051269531\n",
      "Epoch 12, Train Loss: 0.6978, Val Loss: 0.6989, Test Accuracy: 0.4784 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1597306728363037\n",
      "Epoch 13, Train Loss: 0.6975, Val Loss: 0.6987, Test Accuracy: 0.4784 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.167297601699829\n",
      "Epoch 14, Train Loss: 0.6951, Val Loss: 0.6977, Test Accuracy: 0.4836 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1609773635864258\n",
      "Epoch 15, Train Loss: 0.6988, Val Loss: 0.6987, Test Accuracy: 0.4797 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.169015645980835\n",
      "Epoch 16, Train Loss: 0.6977, Val Loss: 0.6956, Test Accuracy: 0.4954 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1661429405212402\n",
      "Epoch 17, Train Loss: 0.6965, Val Loss: 0.6965, Test Accuracy: 0.4889 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.175673007965088\n",
      "Epoch 18, Train Loss: 0.6941, Val Loss: 0.6950, Test Accuracy: 0.5046 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.166719913482666\n",
      "Epoch 19, Train Loss: 0.6958, Val Loss: 0.6948, Test Accuracy: 0.5020 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1508855819702148\n",
      "Epoch 20, Train Loss: 0.6933, Val Loss: 0.6947, Test Accuracy: 0.5020 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1148908138275146\n",
      "Epoch 21, Train Loss: 0.6943, Val Loss: 0.6948, Test Accuracy: 0.5007 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1257896423339844\n",
      "Epoch 22, Train Loss: 0.6926, Val Loss: 0.6930, Test Accuracy: 0.5072 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1676576137542725\n",
      "Epoch 23, Train Loss: 0.6928, Val Loss: 0.6949, Test Accuracy: 0.5046 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1710567474365234\n",
      "Epoch 24, Train Loss: 0.6900, Val Loss: 0.6921, Test Accuracy: 0.5098 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1730380058288574\n",
      "Epoch 25, Train Loss: 0.6914, Val Loss: 0.6921, Test Accuracy: 0.5111 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1701366901397705\n",
      "Epoch 26, Train Loss: 0.6915, Val Loss: 0.6918, Test Accuracy: 0.5216 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1651198863983154\n",
      "Epoch 27, Train Loss: 0.6897, Val Loss: 0.6937, Test Accuracy: 0.5111 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1707265377044678\n",
      "Epoch 28, Train Loss: 0.6900, Val Loss: 0.6922, Test Accuracy: 0.5229 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1740269660949707\n",
      "Epoch 29, Train Loss: 0.6900, Val Loss: 0.6929, Test Accuracy: 0.5203 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1691670417785645\n",
      "Epoch 30, Train Loss: 0.6893, Val Loss: 0.6919, Test Accuracy: 0.5229 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1722683906555176\n",
      "Epoch 31, Train Loss: 0.6891, Val Loss: 0.6916, Test Accuracy: 0.5216 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1660778522491455\n",
      "Epoch 32, Train Loss: 0.6848, Val Loss: 0.6925, Test Accuracy: 0.5190 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1677041053771973\n",
      "Epoch 33, Train Loss: 0.6901, Val Loss: 0.6912, Test Accuracy: 0.5308 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1727728843688965\n",
      "Epoch 34, Train Loss: 0.6891, Val Loss: 0.6899, Test Accuracy: 0.5334 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.171661615371704\n",
      "Epoch 35, Train Loss: 0.6877, Val Loss: 0.6922, Test Accuracy: 0.5111 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1759278774261475\n",
      "Epoch 36, Train Loss: 0.6868, Val Loss: 0.6923, Test Accuracy: 0.5072 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1673874855041504\n",
      "Epoch 37, Train Loss: 0.6872, Val Loss: 0.6904, Test Accuracy: 0.5282 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1754915714263916\n",
      "Epoch 38, Train Loss: 0.6869, Val Loss: 0.6909, Test Accuracy: 0.5190 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1620407104492188\n",
      "Epoch 39, Train Loss: 0.6865, Val Loss: 0.6885, Test Accuracy: 0.5439 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1640563011169434\n",
      "Epoch 40, Train Loss: 0.6858, Val Loss: 0.6902, Test Accuracy: 0.5190 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1718254089355469\n",
      "Epoch 41, Train Loss: 0.6879, Val Loss: 0.6893, Test Accuracy: 0.5308 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1674602031707764\n",
      "Epoch 42, Train Loss: 0.6823, Val Loss: 0.6905, Test Accuracy: 0.5164 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.168870210647583\n",
      "Epoch 43, Train Loss: 0.6842, Val Loss: 0.6910, Test Accuracy: 0.5151 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1708648204803467\n",
      "Epoch 44, Train Loss: 0.6830, Val Loss: 0.6910, Test Accuracy: 0.5072 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1597418785095215\n",
      "Epoch 45, Train Loss: 0.6868, Val Loss: 0.6908, Test Accuracy: 0.5072 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1484930515289307\n",
      "Epoch 46, Train Loss: 0.6846, Val Loss: 0.6921, Test Accuracy: 0.5111 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1630089282989502\n",
      "Epoch 47, Train Loss: 0.6853, Val Loss: 0.6899, Test Accuracy: 0.5177 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.172412633895874\n",
      "Epoch 48, Train Loss: 0.6790, Val Loss: 0.6918, Test Accuracy: 0.5125 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1599512100219727\n",
      "Epoch 49, Train Loss: 0.6836, Val Loss: 0.6931, Test Accuracy: 0.5098 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.172861099243164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:14:00,507] Trial 42 finished with value: 0.5504587155963303 and parameters: {'HIDDEN_DIMENSION': 66, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.11943138667310785, 'LEARNING_RATE': 6.47587421599366e-05}. Best is trial 11 with value: 0.5674967234600262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6828, Val Loss: 0.6910, Test Accuracy: 0.5203 ,Learning Rate: 6.47587421599366e-05 , Time Taken : 1.1605486869812012\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 104, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.15915082424731344, 'LEARNING_RATE': 9.466052086234729e-05}\n",
      "Epoch 1, Train Loss: 0.7440, Val Loss: 0.7129, Test Accuracy: 0.5190 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1755783557891846\n",
      "Epoch 2, Train Loss: 0.7245, Val Loss: 0.7067, Test Accuracy: 0.5111 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.167271614074707\n",
      "Epoch 3, Train Loss: 0.7162, Val Loss: 0.7033, Test Accuracy: 0.5138 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1774189472198486\n",
      "Epoch 4, Train Loss: 0.7065, Val Loss: 0.6957, Test Accuracy: 0.5111 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1710867881774902\n",
      "Epoch 5, Train Loss: 0.7013, Val Loss: 0.6983, Test Accuracy: 0.5085 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1636104583740234\n",
      "Epoch 6, Train Loss: 0.6989, Val Loss: 0.6946, Test Accuracy: 0.5256 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1652579307556152\n",
      "Epoch 7, Train Loss: 0.7004, Val Loss: 0.6960, Test Accuracy: 0.5125 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1776175498962402\n",
      "Epoch 8, Train Loss: 0.6966, Val Loss: 0.6950, Test Accuracy: 0.5164 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1695137023925781\n",
      "Epoch 9, Train Loss: 0.6972, Val Loss: 0.6993, Test Accuracy: 0.4836 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1782641410827637\n",
      "Epoch 10, Train Loss: 0.6954, Val Loss: 0.6945, Test Accuracy: 0.5151 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.168914794921875\n",
      "Epoch 11, Train Loss: 0.6937, Val Loss: 0.6956, Test Accuracy: 0.5033 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1673400402069092\n",
      "Epoch 12, Train Loss: 0.6900, Val Loss: 0.6950, Test Accuracy: 0.5072 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.168393611907959\n",
      "Epoch 13, Train Loss: 0.6924, Val Loss: 0.6948, Test Accuracy: 0.5072 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1621675491333008\n",
      "Epoch 14, Train Loss: 0.6905, Val Loss: 0.6984, Test Accuracy: 0.4902 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1451237201690674\n",
      "Epoch 15, Train Loss: 0.6905, Val Loss: 0.6924, Test Accuracy: 0.5387 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1727564334869385\n",
      "Epoch 16, Train Loss: 0.6909, Val Loss: 0.6968, Test Accuracy: 0.4954 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1713409423828125\n",
      "Epoch 17, Train Loss: 0.6888, Val Loss: 0.6941, Test Accuracy: 0.5151 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.173983097076416\n",
      "Epoch 18, Train Loss: 0.6906, Val Loss: 0.6961, Test Accuracy: 0.5072 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.181835651397705\n",
      "Epoch 19, Train Loss: 0.6873, Val Loss: 0.6939, Test Accuracy: 0.5242 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1654744148254395\n",
      "Epoch 20, Train Loss: 0.6897, Val Loss: 0.6956, Test Accuracy: 0.5072 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1723530292510986\n",
      "Epoch 21, Train Loss: 0.6868, Val Loss: 0.6932, Test Accuracy: 0.5242 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1745386123657227\n",
      "Epoch 22, Train Loss: 0.6883, Val Loss: 0.7020, Test Accuracy: 0.4823 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1832635402679443\n",
      "Epoch 23, Train Loss: 0.6880, Val Loss: 0.6955, Test Accuracy: 0.5164 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1798017024993896\n",
      "Epoch 24, Train Loss: 0.6866, Val Loss: 0.6958, Test Accuracy: 0.5138 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1759753227233887\n",
      "Epoch 25, Train Loss: 0.6835, Val Loss: 0.6986, Test Accuracy: 0.5007 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1729280948638916\n",
      "Epoch 26, Train Loss: 0.6854, Val Loss: 0.6952, Test Accuracy: 0.5229 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.17061448097229\n",
      "Epoch 27, Train Loss: 0.6847, Val Loss: 0.6992, Test Accuracy: 0.4993 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1648032665252686\n",
      "Epoch 28, Train Loss: 0.6875, Val Loss: 0.6924, Test Accuracy: 0.5216 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1588852405548096\n",
      "Epoch 29, Train Loss: 0.6849, Val Loss: 0.6955, Test Accuracy: 0.5229 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1645262241363525\n",
      "Epoch 30, Train Loss: 0.6833, Val Loss: 0.6959, Test Accuracy: 0.5190 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.171759843826294\n",
      "Epoch 31, Train Loss: 0.6841, Val Loss: 0.6970, Test Accuracy: 0.5138 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1643710136413574\n",
      "Epoch 32, Train Loss: 0.6852, Val Loss: 0.6964, Test Accuracy: 0.5190 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1732323169708252\n",
      "Epoch 33, Train Loss: 0.6841, Val Loss: 0.7000, Test Accuracy: 0.5059 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1684238910675049\n",
      "Epoch 34, Train Loss: 0.6832, Val Loss: 0.7027, Test Accuracy: 0.4889 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.167428731918335\n",
      "Epoch 35, Train Loss: 0.6832, Val Loss: 0.6985, Test Accuracy: 0.5098 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.167402982711792\n",
      "Epoch 36, Train Loss: 0.6825, Val Loss: 0.6940, Test Accuracy: 0.5177 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1618986129760742\n",
      "Epoch 37, Train Loss: 0.6816, Val Loss: 0.6982, Test Accuracy: 0.4980 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1628549098968506\n",
      "Epoch 38, Train Loss: 0.6803, Val Loss: 0.6967, Test Accuracy: 0.5125 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.166595220565796\n",
      "Epoch 39, Train Loss: 0.6807, Val Loss: 0.6993, Test Accuracy: 0.4967 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1694042682647705\n",
      "Epoch 40, Train Loss: 0.6788, Val Loss: 0.6981, Test Accuracy: 0.5059 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1757874488830566\n",
      "Epoch 41, Train Loss: 0.6799, Val Loss: 0.6988, Test Accuracy: 0.5059 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1571428775787354\n",
      "Epoch 42, Train Loss: 0.6814, Val Loss: 0.6977, Test Accuracy: 0.5111 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1478748321533203\n",
      "Epoch 43, Train Loss: 0.6815, Val Loss: 0.7015, Test Accuracy: 0.5020 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1115400791168213\n",
      "Epoch 44, Train Loss: 0.6824, Val Loss: 0.6954, Test Accuracy: 0.5138 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1437273025512695\n",
      "Epoch 45, Train Loss: 0.6811, Val Loss: 0.7022, Test Accuracy: 0.5059 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1697921752929688\n",
      "Epoch 46, Train Loss: 0.6790, Val Loss: 0.6985, Test Accuracy: 0.5098 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1742172241210938\n",
      "Epoch 47, Train Loss: 0.6781, Val Loss: 0.7022, Test Accuracy: 0.5033 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1746914386749268\n",
      "Epoch 48, Train Loss: 0.6809, Val Loss: 0.6968, Test Accuracy: 0.5138 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1700515747070312\n",
      "Epoch 49, Train Loss: 0.6786, Val Loss: 0.7022, Test Accuracy: 0.5059 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.171386480331421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:14:59,004] Trial 43 finished with value: 0.5714285714285714 and parameters: {'HIDDEN_DIMENSION': 104, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.15915082424731344, 'LEARNING_RATE': 9.466052086234729e-05}. Best is trial 43 with value: 0.5714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6773, Val Loss: 0.6935, Test Accuracy: 0.5387 ,Learning Rate: 9.466052086234729e-05 , Time Taken : 1.1686923503875732\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 77, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1659269812255357, 'LEARNING_RATE': 0.00012981474565615795}\n",
      "Epoch 1, Train Loss: 0.7376, Val Loss: 0.7221, Test Accuracy: 0.4771 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1606571674346924\n",
      "Epoch 2, Train Loss: 0.7179, Val Loss: 0.7096, Test Accuracy: 0.4758 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1574232578277588\n",
      "Epoch 3, Train Loss: 0.7091, Val Loss: 0.6990, Test Accuracy: 0.4849 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1584653854370117\n",
      "Epoch 4, Train Loss: 0.7029, Val Loss: 0.6969, Test Accuracy: 0.4941 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1512398719787598\n",
      "Epoch 5, Train Loss: 0.7008, Val Loss: 0.6949, Test Accuracy: 0.5046 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1443636417388916\n",
      "Epoch 6, Train Loss: 0.6970, Val Loss: 0.6929, Test Accuracy: 0.5111 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.161388635635376\n",
      "Epoch 7, Train Loss: 0.6949, Val Loss: 0.6933, Test Accuracy: 0.5138 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1373951435089111\n",
      "Epoch 8, Train Loss: 0.6949, Val Loss: 0.6939, Test Accuracy: 0.5020 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1510629653930664\n",
      "Epoch 9, Train Loss: 0.6914, Val Loss: 0.6931, Test Accuracy: 0.5033 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1546907424926758\n",
      "Epoch 10, Train Loss: 0.6916, Val Loss: 0.6927, Test Accuracy: 0.5098 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.154247522354126\n",
      "Epoch 11, Train Loss: 0.6920, Val Loss: 0.6925, Test Accuracy: 0.5151 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1540095806121826\n",
      "Epoch 12, Train Loss: 0.6931, Val Loss: 0.6878, Test Accuracy: 0.5413 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1637096405029297\n",
      "Epoch 13, Train Loss: 0.6932, Val Loss: 0.6927, Test Accuracy: 0.5164 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1546690464019775\n",
      "Epoch 14, Train Loss: 0.6904, Val Loss: 0.6943, Test Accuracy: 0.5151 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.163163661956787\n",
      "Epoch 15, Train Loss: 0.6893, Val Loss: 0.6942, Test Accuracy: 0.5111 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1754176616668701\n",
      "Epoch 16, Train Loss: 0.6883, Val Loss: 0.6939, Test Accuracy: 0.5151 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1805107593536377\n",
      "Epoch 17, Train Loss: 0.6892, Val Loss: 0.6911, Test Accuracy: 0.5360 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1632106304168701\n",
      "Epoch 18, Train Loss: 0.6883, Val Loss: 0.6910, Test Accuracy: 0.5374 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1614205837249756\n",
      "Epoch 19, Train Loss: 0.6885, Val Loss: 0.6923, Test Accuracy: 0.5400 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.160001516342163\n",
      "Epoch 20, Train Loss: 0.6883, Val Loss: 0.6957, Test Accuracy: 0.5138 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1606979370117188\n",
      "Epoch 21, Train Loss: 0.6867, Val Loss: 0.6946, Test Accuracy: 0.5321 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1760427951812744\n",
      "Epoch 22, Train Loss: 0.6863, Val Loss: 0.6939, Test Accuracy: 0.5347 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.167787790298462\n",
      "Epoch 23, Train Loss: 0.6853, Val Loss: 0.6943, Test Accuracy: 0.5321 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.167881965637207\n",
      "Epoch 24, Train Loss: 0.6856, Val Loss: 0.6920, Test Accuracy: 0.5452 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1624541282653809\n",
      "Epoch 25, Train Loss: 0.6850, Val Loss: 0.6997, Test Accuracy: 0.5125 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1540334224700928\n",
      "Epoch 26, Train Loss: 0.6840, Val Loss: 0.6938, Test Accuracy: 0.5387 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1548011302947998\n",
      "Epoch 27, Train Loss: 0.6870, Val Loss: 0.6920, Test Accuracy: 0.5452 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1706395149230957\n",
      "Epoch 28, Train Loss: 0.6836, Val Loss: 0.7006, Test Accuracy: 0.5190 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1680843830108643\n",
      "Epoch 29, Train Loss: 0.6835, Val Loss: 0.6945, Test Accuracy: 0.5400 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1766738891601562\n",
      "Epoch 30, Train Loss: 0.6802, Val Loss: 0.6918, Test Accuracy: 0.5465 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1591746807098389\n",
      "Epoch 31, Train Loss: 0.6813, Val Loss: 0.7025, Test Accuracy: 0.5085 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1690857410430908\n",
      "Epoch 32, Train Loss: 0.6808, Val Loss: 0.6988, Test Accuracy: 0.5321 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.168480396270752\n",
      "Epoch 33, Train Loss: 0.6807, Val Loss: 0.6984, Test Accuracy: 0.5282 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1717848777770996\n",
      "Epoch 34, Train Loss: 0.6799, Val Loss: 0.6980, Test Accuracy: 0.5334 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1845922470092773\n",
      "Epoch 35, Train Loss: 0.6817, Val Loss: 0.6990, Test Accuracy: 0.5269 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.181896448135376\n",
      "Epoch 36, Train Loss: 0.6806, Val Loss: 0.6986, Test Accuracy: 0.5321 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1651334762573242\n",
      "Epoch 37, Train Loss: 0.6803, Val Loss: 0.6927, Test Accuracy: 0.5400 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1604316234588623\n",
      "Epoch 38, Train Loss: 0.6801, Val Loss: 0.7002, Test Accuracy: 0.5334 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1542332172393799\n",
      "Epoch 39, Train Loss: 0.6810, Val Loss: 0.7002, Test Accuracy: 0.5308 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.165616750717163\n",
      "Epoch 40, Train Loss: 0.6784, Val Loss: 0.6982, Test Accuracy: 0.5374 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1628289222717285\n",
      "Epoch 41, Train Loss: 0.6812, Val Loss: 0.6948, Test Accuracy: 0.5400 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.178802251815796\n",
      "Epoch 42, Train Loss: 0.6809, Val Loss: 0.6969, Test Accuracy: 0.5360 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1791069507598877\n",
      "Epoch 43, Train Loss: 0.6788, Val Loss: 0.6978, Test Accuracy: 0.5321 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1915664672851562\n",
      "Epoch 44, Train Loss: 0.6786, Val Loss: 0.6964, Test Accuracy: 0.5400 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1730608940124512\n",
      "Epoch 45, Train Loss: 0.6770, Val Loss: 0.6948, Test Accuracy: 0.5400 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1676568984985352\n",
      "Epoch 46, Train Loss: 0.6784, Val Loss: 0.6979, Test Accuracy: 0.5321 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.170536756515503\n",
      "Epoch 47, Train Loss: 0.6791, Val Loss: 0.7058, Test Accuracy: 0.5190 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1736793518066406\n",
      "Epoch 48, Train Loss: 0.6786, Val Loss: 0.7050, Test Accuracy: 0.5190 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.1691596508026123\n",
      "Epoch 49, Train Loss: 0.6779, Val Loss: 0.6977, Test Accuracy: 0.5334 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.174332857131958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:15:57,376] Trial 44 finished with value: 0.5583224115334207 and parameters: {'HIDDEN_DIMENSION': 77, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.1659269812255357, 'LEARNING_RATE': 0.00012981474565615795}. Best is trial 43 with value: 0.5714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6756, Val Loss: 0.7050, Test Accuracy: 0.5125 ,Learning Rate: 0.00012981474565615795 , Time Taken : 1.166370153427124\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 92, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.22202377124336686, 'LEARNING_RATE': 0.00017820789041162483}\n",
      "Epoch 1, Train Loss: 0.7962, Val Loss: 0.7240, Test Accuracy: 0.5098 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.174340009689331\n",
      "Epoch 2, Train Loss: 0.7363, Val Loss: 0.7055, Test Accuracy: 0.5190 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1766269207000732\n",
      "Epoch 3, Train Loss: 0.7168, Val Loss: 0.6963, Test Accuracy: 0.5138 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1777446269989014\n",
      "Epoch 4, Train Loss: 0.7114, Val Loss: 0.6950, Test Accuracy: 0.5098 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1791467666625977\n",
      "Epoch 5, Train Loss: 0.7048, Val Loss: 0.6907, Test Accuracy: 0.5242 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1730897426605225\n",
      "Epoch 6, Train Loss: 0.6979, Val Loss: 0.6915, Test Accuracy: 0.5269 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1725051403045654\n",
      "Epoch 7, Train Loss: 0.6980, Val Loss: 0.6915, Test Accuracy: 0.5216 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1719391345977783\n",
      "Epoch 8, Train Loss: 0.6937, Val Loss: 0.6957, Test Accuracy: 0.5007 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1484770774841309\n",
      "Epoch 9, Train Loss: 0.6970, Val Loss: 0.6876, Test Accuracy: 0.5387 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1741530895233154\n",
      "Epoch 10, Train Loss: 0.6915, Val Loss: 0.6904, Test Accuracy: 0.5033 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1759963035583496\n",
      "Epoch 11, Train Loss: 0.6960, Val Loss: 0.6939, Test Accuracy: 0.5177 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1806354522705078\n",
      "Epoch 12, Train Loss: 0.6905, Val Loss: 0.6889, Test Accuracy: 0.5085 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.177887201309204\n",
      "Epoch 13, Train Loss: 0.6905, Val Loss: 0.6891, Test Accuracy: 0.5164 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1778442859649658\n",
      "Epoch 14, Train Loss: 0.6870, Val Loss: 0.6924, Test Accuracy: 0.5229 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1800603866577148\n",
      "Epoch 15, Train Loss: 0.6884, Val Loss: 0.6905, Test Accuracy: 0.5203 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1702449321746826\n",
      "Epoch 16, Train Loss: 0.6877, Val Loss: 0.6942, Test Accuracy: 0.5085 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1839637756347656\n",
      "Epoch 17, Train Loss: 0.6892, Val Loss: 0.6920, Test Accuracy: 0.5177 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1785683631896973\n",
      "Epoch 18, Train Loss: 0.6856, Val Loss: 0.6957, Test Accuracy: 0.5085 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1733508110046387\n",
      "Epoch 19, Train Loss: 0.6867, Val Loss: 0.6865, Test Accuracy: 0.5203 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.193964958190918\n",
      "Epoch 20, Train Loss: 0.6862, Val Loss: 0.6898, Test Accuracy: 0.5256 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1670408248901367\n",
      "Epoch 21, Train Loss: 0.6861, Val Loss: 0.6919, Test Accuracy: 0.5242 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1778240203857422\n",
      "Epoch 22, Train Loss: 0.6856, Val Loss: 0.6953, Test Accuracy: 0.4993 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1655523777008057\n",
      "Epoch 23, Train Loss: 0.6844, Val Loss: 0.6937, Test Accuracy: 0.5138 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1670167446136475\n",
      "Epoch 24, Train Loss: 0.6810, Val Loss: 0.6934, Test Accuracy: 0.5256 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.172896385192871\n",
      "Epoch 25, Train Loss: 0.6823, Val Loss: 0.6929, Test Accuracy: 0.5190 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1413030624389648\n",
      "Epoch 26, Train Loss: 0.6807, Val Loss: 0.6978, Test Accuracy: 0.5033 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.114997148513794\n",
      "Epoch 27, Train Loss: 0.6802, Val Loss: 0.6945, Test Accuracy: 0.5098 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1210458278656006\n",
      "Epoch 28, Train Loss: 0.6836, Val Loss: 0.6921, Test Accuracy: 0.5190 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1720964908599854\n",
      "Epoch 29, Train Loss: 0.6806, Val Loss: 0.6987, Test Accuracy: 0.4980 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.166719913482666\n",
      "Epoch 30, Train Loss: 0.6807, Val Loss: 0.6974, Test Accuracy: 0.5072 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1632020473480225\n",
      "Epoch 31, Train Loss: 0.6781, Val Loss: 0.6981, Test Accuracy: 0.5072 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1674690246582031\n",
      "Epoch 32, Train Loss: 0.6811, Val Loss: 0.6998, Test Accuracy: 0.5098 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.179577350616455\n",
      "Epoch 33, Train Loss: 0.6809, Val Loss: 0.6967, Test Accuracy: 0.5125 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1683926582336426\n",
      "Epoch 34, Train Loss: 0.6775, Val Loss: 0.6947, Test Accuracy: 0.5085 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1715989112854004\n",
      "Epoch 35, Train Loss: 0.6773, Val Loss: 0.6997, Test Accuracy: 0.5125 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.170276165008545\n",
      "Epoch 36, Train Loss: 0.6775, Val Loss: 0.7014, Test Accuracy: 0.5098 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1734764575958252\n",
      "Epoch 37, Train Loss: 0.6767, Val Loss: 0.7019, Test Accuracy: 0.5151 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1709833145141602\n",
      "Epoch 38, Train Loss: 0.6767, Val Loss: 0.6935, Test Accuracy: 0.5256 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1751413345336914\n",
      "Epoch 39, Train Loss: 0.6758, Val Loss: 0.6913, Test Accuracy: 0.5360 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.164149522781372\n",
      "Epoch 40, Train Loss: 0.6753, Val Loss: 0.6986, Test Accuracy: 0.5164 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1746084690093994\n",
      "Epoch 41, Train Loss: 0.6756, Val Loss: 0.6943, Test Accuracy: 0.5164 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1771223545074463\n",
      "Epoch 42, Train Loss: 0.6755, Val Loss: 0.6961, Test Accuracy: 0.5242 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1703298091888428\n",
      "Epoch 43, Train Loss: 0.6717, Val Loss: 0.7000, Test Accuracy: 0.5190 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1642515659332275\n",
      "Epoch 44, Train Loss: 0.6720, Val Loss: 0.6987, Test Accuracy: 0.5216 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1588773727416992\n",
      "Epoch 45, Train Loss: 0.6751, Val Loss: 0.6954, Test Accuracy: 0.5308 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1616952419281006\n",
      "Epoch 46, Train Loss: 0.6736, Val Loss: 0.6979, Test Accuracy: 0.5256 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.168358325958252\n",
      "Epoch 47, Train Loss: 0.6736, Val Loss: 0.7022, Test Accuracy: 0.5151 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1713650226593018\n",
      "Epoch 48, Train Loss: 0.6744, Val Loss: 0.6990, Test Accuracy: 0.5295 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1617143154144287\n",
      "Epoch 49, Train Loss: 0.6731, Val Loss: 0.7021, Test Accuracy: 0.5098 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1581242084503174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:16:55,935] Trial 45 finished with value: 0.5570117955439057 and parameters: {'HIDDEN_DIMENSION': 92, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.22202377124336686, 'LEARNING_RATE': 0.00017820789041162483}. Best is trial 43 with value: 0.5714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6729, Val Loss: 0.6982, Test Accuracy: 0.5334 ,Learning Rate: 0.00017820789041162483 , Time Taken : 1.1613996028900146\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 88, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.18612418176703444, 'LEARNING_RATE': 0.00010164966155256074}\n",
      "Epoch 1, Train Loss: 0.7538, Val Loss: 0.7097, Test Accuracy: 0.5531 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8473777770996094\n",
      "Epoch 2, Train Loss: 0.7382, Val Loss: 0.7031, Test Accuracy: 0.5321 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8507852554321289\n",
      "Epoch 3, Train Loss: 0.7219, Val Loss: 0.6981, Test Accuracy: 0.5203 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8508195877075195\n",
      "Epoch 4, Train Loss: 0.7141, Val Loss: 0.6938, Test Accuracy: 0.5203 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8523299694061279\n",
      "Epoch 5, Train Loss: 0.7076, Val Loss: 0.6936, Test Accuracy: 0.5125 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8528249263763428\n",
      "Epoch 6, Train Loss: 0.7079, Val Loss: 0.6913, Test Accuracy: 0.5229 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8519608974456787\n",
      "Epoch 7, Train Loss: 0.7022, Val Loss: 0.6936, Test Accuracy: 0.5125 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8515660762786865\n",
      "Epoch 8, Train Loss: 0.6959, Val Loss: 0.6930, Test Accuracy: 0.5125 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8529653549194336\n",
      "Epoch 9, Train Loss: 0.7007, Val Loss: 0.6935, Test Accuracy: 0.5111 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8535032272338867\n",
      "Epoch 10, Train Loss: 0.6970, Val Loss: 0.6921, Test Accuracy: 0.5151 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8549048900604248\n",
      "Epoch 11, Train Loss: 0.6957, Val Loss: 0.6913, Test Accuracy: 0.5151 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8523528575897217\n",
      "Epoch 12, Train Loss: 0.6942, Val Loss: 0.6928, Test Accuracy: 0.5151 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.853137731552124\n",
      "Epoch 13, Train Loss: 0.6966, Val Loss: 0.6919, Test Accuracy: 0.5203 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.838630199432373\n",
      "Epoch 14, Train Loss: 0.6954, Val Loss: 0.6915, Test Accuracy: 0.5190 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8541693687438965\n",
      "Epoch 15, Train Loss: 0.6937, Val Loss: 0.6933, Test Accuracy: 0.5190 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8554117679595947\n",
      "Epoch 16, Train Loss: 0.6930, Val Loss: 0.6912, Test Accuracy: 0.5282 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8540396690368652\n",
      "Epoch 17, Train Loss: 0.6914, Val Loss: 0.6918, Test Accuracy: 0.5216 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8509783744812012\n",
      "Epoch 18, Train Loss: 0.6912, Val Loss: 0.6924, Test Accuracy: 0.5164 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8548543453216553\n",
      "Epoch 19, Train Loss: 0.6911, Val Loss: 0.6895, Test Accuracy: 0.5229 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8532571792602539\n",
      "Epoch 20, Train Loss: 0.6915, Val Loss: 0.6918, Test Accuracy: 0.5256 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8548166751861572\n",
      "Epoch 21, Train Loss: 0.6897, Val Loss: 0.6904, Test Accuracy: 0.5295 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8553268909454346\n",
      "Epoch 22, Train Loss: 0.6901, Val Loss: 0.6910, Test Accuracy: 0.5295 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8544833660125732\n",
      "Epoch 23, Train Loss: 0.6892, Val Loss: 0.6931, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8536820411682129\n",
      "Epoch 24, Train Loss: 0.6885, Val Loss: 0.6914, Test Accuracy: 0.5295 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8503708839416504\n",
      "Epoch 25, Train Loss: 0.6911, Val Loss: 0.6913, Test Accuracy: 0.5387 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8500361442565918\n",
      "Epoch 26, Train Loss: 0.6878, Val Loss: 0.6930, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8575398921966553\n",
      "Epoch 27, Train Loss: 0.6881, Val Loss: 0.6930, Test Accuracy: 0.5256 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8605256080627441\n",
      "Epoch 28, Train Loss: 0.6880, Val Loss: 0.6918, Test Accuracy: 0.5334 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8470923900604248\n",
      "Epoch 29, Train Loss: 0.6888, Val Loss: 0.6912, Test Accuracy: 0.5413 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8454217910766602\n",
      "Epoch 30, Train Loss: 0.6883, Val Loss: 0.6927, Test Accuracy: 0.5282 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8620214462280273\n",
      "Epoch 31, Train Loss: 0.6887, Val Loss: 0.6943, Test Accuracy: 0.5242 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.851024866104126\n",
      "Epoch 32, Train Loss: 0.6857, Val Loss: 0.6916, Test Accuracy: 0.5400 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8534293174743652\n",
      "Epoch 33, Train Loss: 0.6847, Val Loss: 0.6936, Test Accuracy: 0.5308 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8532602787017822\n",
      "Epoch 34, Train Loss: 0.6840, Val Loss: 0.6938, Test Accuracy: 0.5308 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8484706878662109\n",
      "Epoch 35, Train Loss: 0.6868, Val Loss: 0.6941, Test Accuracy: 0.5347 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.841702938079834\n",
      "Epoch 36, Train Loss: 0.6852, Val Loss: 0.6925, Test Accuracy: 0.5426 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8524360656738281\n",
      "Epoch 37, Train Loss: 0.6853, Val Loss: 0.6936, Test Accuracy: 0.5400 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8532955646514893\n",
      "Epoch 38, Train Loss: 0.6828, Val Loss: 0.6943, Test Accuracy: 0.5413 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8481669425964355\n",
      "Epoch 39, Train Loss: 0.6814, Val Loss: 0.6962, Test Accuracy: 0.5308 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8543999195098877\n",
      "Epoch 40, Train Loss: 0.6850, Val Loss: 0.6945, Test Accuracy: 0.5374 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8536322116851807\n",
      "Epoch 41, Train Loss: 0.6829, Val Loss: 0.6963, Test Accuracy: 0.5400 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.854346513748169\n",
      "Epoch 42, Train Loss: 0.6824, Val Loss: 0.6942, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8514456748962402\n",
      "Epoch 43, Train Loss: 0.6809, Val Loss: 0.6928, Test Accuracy: 0.5478 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8546338081359863\n",
      "Epoch 44, Train Loss: 0.6827, Val Loss: 0.6955, Test Accuracy: 0.5374 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8519070148468018\n",
      "Epoch 45, Train Loss: 0.6819, Val Loss: 0.6958, Test Accuracy: 0.5374 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8530633449554443\n",
      "Epoch 46, Train Loss: 0.6809, Val Loss: 0.6969, Test Accuracy: 0.5360 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8515684604644775\n",
      "Epoch 47, Train Loss: 0.6822, Val Loss: 0.6957, Test Accuracy: 0.5452 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8517630100250244\n",
      "Epoch 48, Train Loss: 0.6815, Val Loss: 0.6935, Test Accuracy: 0.5413 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8560965061187744\n",
      "Epoch 49, Train Loss: 0.6791, Val Loss: 0.6967, Test Accuracy: 0.5400 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8555676937103271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:17:38,657] Trial 46 finished with value: 0.5740498034076016 and parameters: {'HIDDEN_DIMENSION': 88, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'DROP_OUT': 0.18612418176703444, 'LEARNING_RATE': 0.00010164966155256074}. Best is trial 46 with value: 0.5740498034076016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6816, Val Loss: 0.6944, Test Accuracy: 0.5452 ,Learning Rate: 0.00010164966155256074 , Time Taken : 0.8523619174957275\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 87, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.18197985258795718, 'LEARNING_RATE': 0.00010849169451041247}\n",
      "Epoch 1, Train Loss: 0.7455, Val Loss: 0.7258, Test Accuracy: 0.5072 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8553738594055176\n",
      "Epoch 2, Train Loss: 0.7267, Val Loss: 0.7104, Test Accuracy: 0.5138 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8627274036407471\n",
      "Epoch 3, Train Loss: 0.7160, Val Loss: 0.7049, Test Accuracy: 0.5229 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8558444976806641\n",
      "Epoch 4, Train Loss: 0.7093, Val Loss: 0.6996, Test Accuracy: 0.5229 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8582746982574463\n",
      "Epoch 5, Train Loss: 0.7046, Val Loss: 0.6969, Test Accuracy: 0.5085 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8587751388549805\n",
      "Epoch 6, Train Loss: 0.7069, Val Loss: 0.6958, Test Accuracy: 0.5072 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8549385070800781\n",
      "Epoch 7, Train Loss: 0.7005, Val Loss: 0.6925, Test Accuracy: 0.5085 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8561997413635254\n",
      "Epoch 8, Train Loss: 0.7003, Val Loss: 0.6952, Test Accuracy: 0.4980 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8545680046081543\n",
      "Epoch 9, Train Loss: 0.6987, Val Loss: 0.6933, Test Accuracy: 0.5151 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8517942428588867\n",
      "Epoch 10, Train Loss: 0.6969, Val Loss: 0.6919, Test Accuracy: 0.5308 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8560655117034912\n",
      "Epoch 11, Train Loss: 0.6981, Val Loss: 0.6919, Test Accuracy: 0.5216 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8550844192504883\n",
      "Epoch 12, Train Loss: 0.6943, Val Loss: 0.6915, Test Accuracy: 0.5229 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8554692268371582\n",
      "Epoch 13, Train Loss: 0.6935, Val Loss: 0.6916, Test Accuracy: 0.5203 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8570778369903564\n",
      "Epoch 14, Train Loss: 0.6961, Val Loss: 0.6908, Test Accuracy: 0.5190 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8587503433227539\n",
      "Epoch 15, Train Loss: 0.6924, Val Loss: 0.6913, Test Accuracy: 0.5164 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8673663139343262\n",
      "Epoch 16, Train Loss: 0.6955, Val Loss: 0.6905, Test Accuracy: 0.5216 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8656837940216064\n",
      "Epoch 17, Train Loss: 0.6938, Val Loss: 0.6908, Test Accuracy: 0.5190 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8607947826385498\n",
      "Epoch 18, Train Loss: 0.6922, Val Loss: 0.6914, Test Accuracy: 0.5216 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.864375114440918\n",
      "Epoch 19, Train Loss: 0.6925, Val Loss: 0.6895, Test Accuracy: 0.5242 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8630890846252441\n",
      "Epoch 20, Train Loss: 0.6900, Val Loss: 0.6899, Test Accuracy: 0.5229 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8647568225860596\n",
      "Epoch 21, Train Loss: 0.6915, Val Loss: 0.6894, Test Accuracy: 0.5242 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8780052661895752\n",
      "Epoch 22, Train Loss: 0.6895, Val Loss: 0.6901, Test Accuracy: 0.5308 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8721957206726074\n",
      "Epoch 23, Train Loss: 0.6898, Val Loss: 0.6906, Test Accuracy: 0.5321 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.867687463760376\n",
      "Epoch 24, Train Loss: 0.6886, Val Loss: 0.6908, Test Accuracy: 0.5308 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8601884841918945\n",
      "Epoch 25, Train Loss: 0.6890, Val Loss: 0.6905, Test Accuracy: 0.5295 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8573892116546631\n",
      "Epoch 26, Train Loss: 0.6868, Val Loss: 0.6905, Test Accuracy: 0.5282 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8622870445251465\n",
      "Epoch 27, Train Loss: 0.6870, Val Loss: 0.6906, Test Accuracy: 0.5308 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8602278232574463\n",
      "Epoch 28, Train Loss: 0.6871, Val Loss: 0.6900, Test Accuracy: 0.5282 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8563368320465088\n",
      "Epoch 29, Train Loss: 0.6882, Val Loss: 0.6893, Test Accuracy: 0.5426 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8634872436523438\n",
      "Epoch 30, Train Loss: 0.6870, Val Loss: 0.6895, Test Accuracy: 0.5374 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8591804504394531\n",
      "Epoch 31, Train Loss: 0.6868, Val Loss: 0.6902, Test Accuracy: 0.5360 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.863692045211792\n",
      "Epoch 32, Train Loss: 0.6875, Val Loss: 0.6899, Test Accuracy: 0.5413 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8624382019042969\n",
      "Epoch 33, Train Loss: 0.6888, Val Loss: 0.6925, Test Accuracy: 0.5151 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8450000286102295\n",
      "Epoch 34, Train Loss: 0.6861, Val Loss: 0.6912, Test Accuracy: 0.5269 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8642637729644775\n",
      "Epoch 35, Train Loss: 0.6859, Val Loss: 0.6916, Test Accuracy: 0.5269 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8607029914855957\n",
      "Epoch 36, Train Loss: 0.6871, Val Loss: 0.6906, Test Accuracy: 0.5413 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8604104518890381\n",
      "Epoch 37, Train Loss: 0.6843, Val Loss: 0.6912, Test Accuracy: 0.5334 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.823096513748169\n",
      "Epoch 38, Train Loss: 0.6856, Val Loss: 0.6904, Test Accuracy: 0.5426 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8194024562835693\n",
      "Epoch 39, Train Loss: 0.6838, Val Loss: 0.6886, Test Accuracy: 0.5491 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8200111389160156\n",
      "Epoch 40, Train Loss: 0.6858, Val Loss: 0.6921, Test Accuracy: 0.5256 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8502013683319092\n",
      "Epoch 41, Train Loss: 0.6853, Val Loss: 0.6907, Test Accuracy: 0.5347 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8552119731903076\n",
      "Epoch 42, Train Loss: 0.6835, Val Loss: 0.6917, Test Accuracy: 0.5295 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8632252216339111\n",
      "Epoch 43, Train Loss: 0.6838, Val Loss: 0.6926, Test Accuracy: 0.5374 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8504083156585693\n",
      "Epoch 44, Train Loss: 0.6842, Val Loss: 0.6925, Test Accuracy: 0.5269 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8529088497161865\n",
      "Epoch 45, Train Loss: 0.6814, Val Loss: 0.6901, Test Accuracy: 0.5400 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8592596054077148\n",
      "Epoch 46, Train Loss: 0.6840, Val Loss: 0.6914, Test Accuracy: 0.5282 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8636155128479004\n",
      "Epoch 47, Train Loss: 0.6820, Val Loss: 0.6921, Test Accuracy: 0.5269 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8554401397705078\n",
      "Epoch 48, Train Loss: 0.6808, Val Loss: 0.6927, Test Accuracy: 0.5308 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8599295616149902\n",
      "Epoch 49, Train Loss: 0.6826, Val Loss: 0.6897, Test Accuracy: 0.5400 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8593142032623291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:18:21,623] Trial 47 finished with value: 0.5596330275229358 and parameters: {'HIDDEN_DIMENSION': 87, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'DROP_OUT': 0.18197985258795718, 'LEARNING_RATE': 0.00010849169451041247}. Best is trial 46 with value: 0.5740498034076016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6808, Val Loss: 0.6923, Test Accuracy: 0.5452 ,Learning Rate: 0.00010849169451041247 , Time Taken : 0.8606357574462891\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 83, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.15053527056263136, 'LEARNING_RATE': 5.986282659838811e-05}\n",
      "Epoch 1, Train Loss: 0.7295, Val Loss: 0.7266, Test Accuracy: 0.4679 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8602097034454346\n",
      "Epoch 2, Train Loss: 0.7223, Val Loss: 0.7161, Test Accuracy: 0.4679 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8622763156890869\n",
      "Epoch 3, Train Loss: 0.7184, Val Loss: 0.7100, Test Accuracy: 0.4823 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8573951721191406\n",
      "Epoch 4, Train Loss: 0.7101, Val Loss: 0.7080, Test Accuracy: 0.4862 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8577179908752441\n",
      "Epoch 5, Train Loss: 0.7081, Val Loss: 0.7049, Test Accuracy: 0.4849 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8562295436859131\n",
      "Epoch 6, Train Loss: 0.7041, Val Loss: 0.7034, Test Accuracy: 0.4849 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8622207641601562\n",
      "Epoch 7, Train Loss: 0.7047, Val Loss: 0.7012, Test Accuracy: 0.4836 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8565356731414795\n",
      "Epoch 8, Train Loss: 0.7009, Val Loss: 0.7015, Test Accuracy: 0.4875 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8578910827636719\n",
      "Epoch 9, Train Loss: 0.6995, Val Loss: 0.7008, Test Accuracy: 0.4862 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8606431484222412\n",
      "Epoch 10, Train Loss: 0.6996, Val Loss: 0.6996, Test Accuracy: 0.4875 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8603575229644775\n",
      "Epoch 11, Train Loss: 0.6980, Val Loss: 0.6987, Test Accuracy: 0.4849 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8605272769927979\n",
      "Epoch 12, Train Loss: 0.6996, Val Loss: 0.6980, Test Accuracy: 0.4810 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8594107627868652\n",
      "Epoch 13, Train Loss: 0.6935, Val Loss: 0.6979, Test Accuracy: 0.4758 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8547577857971191\n",
      "Epoch 14, Train Loss: 0.6944, Val Loss: 0.6984, Test Accuracy: 0.4731 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8551421165466309\n",
      "Epoch 15, Train Loss: 0.6961, Val Loss: 0.6974, Test Accuracy: 0.4784 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8605351448059082\n",
      "Epoch 16, Train Loss: 0.6955, Val Loss: 0.6965, Test Accuracy: 0.4823 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8437926769256592\n",
      "Epoch 17, Train Loss: 0.6961, Val Loss: 0.6974, Test Accuracy: 0.4823 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8541929721832275\n",
      "Epoch 18, Train Loss: 0.6932, Val Loss: 0.6971, Test Accuracy: 0.4849 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8592197895050049\n",
      "Epoch 19, Train Loss: 0.6908, Val Loss: 0.6973, Test Accuracy: 0.4797 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8570983409881592\n",
      "Epoch 20, Train Loss: 0.6926, Val Loss: 0.6963, Test Accuracy: 0.4731 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8577368259429932\n",
      "Epoch 21, Train Loss: 0.6934, Val Loss: 0.6963, Test Accuracy: 0.4771 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8613910675048828\n",
      "Epoch 22, Train Loss: 0.6924, Val Loss: 0.6959, Test Accuracy: 0.4797 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8578231334686279\n",
      "Epoch 23, Train Loss: 0.6916, Val Loss: 0.6957, Test Accuracy: 0.4967 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8605334758758545\n",
      "Epoch 24, Train Loss: 0.6909, Val Loss: 0.6947, Test Accuracy: 0.5033 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8585145473480225\n",
      "Epoch 25, Train Loss: 0.6896, Val Loss: 0.6952, Test Accuracy: 0.5125 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8604326248168945\n",
      "Epoch 26, Train Loss: 0.6923, Val Loss: 0.6958, Test Accuracy: 0.5125 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8561220169067383\n",
      "Epoch 27, Train Loss: 0.6914, Val Loss: 0.6956, Test Accuracy: 0.5059 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8578870296478271\n",
      "Epoch 28, Train Loss: 0.6924, Val Loss: 0.6943, Test Accuracy: 0.5059 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8540194034576416\n",
      "Epoch 29, Train Loss: 0.6912, Val Loss: 0.6954, Test Accuracy: 0.5059 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8588862419128418\n",
      "Epoch 30, Train Loss: 0.6887, Val Loss: 0.6948, Test Accuracy: 0.5111 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8553929328918457\n",
      "Epoch 31, Train Loss: 0.6910, Val Loss: 0.6947, Test Accuracy: 0.5177 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.857663631439209\n",
      "Epoch 32, Train Loss: 0.6906, Val Loss: 0.6950, Test Accuracy: 0.5125 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8611392974853516\n",
      "Epoch 33, Train Loss: 0.6884, Val Loss: 0.6946, Test Accuracy: 0.5164 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8557655811309814\n",
      "Epoch 34, Train Loss: 0.6886, Val Loss: 0.6950, Test Accuracy: 0.5164 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8573184013366699\n",
      "Epoch 35, Train Loss: 0.6900, Val Loss: 0.6946, Test Accuracy: 0.5151 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8548417091369629\n",
      "Epoch 36, Train Loss: 0.6907, Val Loss: 0.6940, Test Accuracy: 0.5164 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8550889492034912\n",
      "Epoch 37, Train Loss: 0.6898, Val Loss: 0.6948, Test Accuracy: 0.5177 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8561925888061523\n",
      "Epoch 38, Train Loss: 0.6878, Val Loss: 0.6950, Test Accuracy: 0.5138 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8516583442687988\n",
      "Epoch 39, Train Loss: 0.6893, Val Loss: 0.6951, Test Accuracy: 0.5138 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8602855205535889\n",
      "Epoch 40, Train Loss: 0.6877, Val Loss: 0.6943, Test Accuracy: 0.5190 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8577320575714111\n",
      "Epoch 41, Train Loss: 0.6876, Val Loss: 0.6949, Test Accuracy: 0.5138 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8570749759674072\n",
      "Epoch 42, Train Loss: 0.6905, Val Loss: 0.6947, Test Accuracy: 0.5164 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.858292818069458\n",
      "Epoch 43, Train Loss: 0.6868, Val Loss: 0.6949, Test Accuracy: 0.5138 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8570120334625244\n",
      "Epoch 44, Train Loss: 0.6868, Val Loss: 0.6949, Test Accuracy: 0.5111 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8584601879119873\n",
      "Epoch 45, Train Loss: 0.6865, Val Loss: 0.6946, Test Accuracy: 0.5111 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8583700656890869\n",
      "Epoch 46, Train Loss: 0.6881, Val Loss: 0.6946, Test Accuracy: 0.5111 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8627102375030518\n",
      "Epoch 47, Train Loss: 0.6872, Val Loss: 0.6958, Test Accuracy: 0.5046 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8599843978881836\n",
      "Epoch 48, Train Loss: 0.6866, Val Loss: 0.6940, Test Accuracy: 0.5125 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.86063551902771\n",
      "Epoch 49, Train Loss: 0.6875, Val Loss: 0.6943, Test Accuracy: 0.5177 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8582069873809814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:19:04,617] Trial 48 finished with value: 0.5150720838794234 and parameters: {'HIDDEN_DIMENSION': 83, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'DROP_OUT': 0.15053527056263136, 'LEARNING_RATE': 5.986282659838811e-05}. Best is trial 46 with value: 0.5740498034076016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6871, Val Loss: 0.6947, Test Accuracy: 0.5138 ,Learning Rate: 5.986282659838811e-05 , Time Taken : 0.8573322296142578\n",
      "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 71, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.19245716833704454, 'LEARNING_RATE': 8.189452784892711e-05}\n",
      "Epoch 1, Train Loss: 0.7675, Val Loss: 0.7249, Test Accuracy: 0.5190 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1665122509002686\n",
      "Epoch 2, Train Loss: 0.7388, Val Loss: 0.7151, Test Accuracy: 0.5111 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1607317924499512\n",
      "Epoch 3, Train Loss: 0.7303, Val Loss: 0.7045, Test Accuracy: 0.5138 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1563081741333008\n",
      "Epoch 4, Train Loss: 0.7117, Val Loss: 0.6974, Test Accuracy: 0.5033 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1702661514282227\n",
      "Epoch 5, Train Loss: 0.7034, Val Loss: 0.6965, Test Accuracy: 0.5046 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.177037239074707\n",
      "Epoch 6, Train Loss: 0.7013, Val Loss: 0.6948, Test Accuracy: 0.5033 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1477611064910889\n",
      "Epoch 7, Train Loss: 0.6988, Val Loss: 0.6939, Test Accuracy: 0.5085 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1768105030059814\n",
      "Epoch 8, Train Loss: 0.6968, Val Loss: 0.6942, Test Accuracy: 0.5072 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.170701026916504\n",
      "Epoch 9, Train Loss: 0.6940, Val Loss: 0.6918, Test Accuracy: 0.5256 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1766209602355957\n",
      "Epoch 10, Train Loss: 0.6958, Val Loss: 0.6926, Test Accuracy: 0.5242 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.17274808883667\n",
      "Epoch 11, Train Loss: 0.6949, Val Loss: 0.6925, Test Accuracy: 0.5216 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.166945219039917\n",
      "Epoch 12, Train Loss: 0.6954, Val Loss: 0.6924, Test Accuracy: 0.5203 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1684043407440186\n",
      "Epoch 13, Train Loss: 0.6919, Val Loss: 0.6957, Test Accuracy: 0.4954 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1594417095184326\n",
      "Epoch 14, Train Loss: 0.6941, Val Loss: 0.6927, Test Accuracy: 0.5177 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1706032752990723\n",
      "Epoch 15, Train Loss: 0.6902, Val Loss: 0.6916, Test Accuracy: 0.5269 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1677477359771729\n",
      "Epoch 16, Train Loss: 0.6913, Val Loss: 0.6895, Test Accuracy: 0.5334 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1702592372894287\n",
      "Epoch 17, Train Loss: 0.6918, Val Loss: 0.6896, Test Accuracy: 0.5334 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1672775745391846\n",
      "Epoch 18, Train Loss: 0.6928, Val Loss: 0.6913, Test Accuracy: 0.5242 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1713573932647705\n",
      "Epoch 19, Train Loss: 0.6923, Val Loss: 0.6913, Test Accuracy: 0.5282 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1617035865783691\n",
      "Epoch 20, Train Loss: 0.6904, Val Loss: 0.6916, Test Accuracy: 0.5269 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.180464267730713\n",
      "Epoch 21, Train Loss: 0.6863, Val Loss: 0.6894, Test Accuracy: 0.5387 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1744933128356934\n",
      "Epoch 22, Train Loss: 0.6889, Val Loss: 0.6906, Test Accuracy: 0.5426 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1779720783233643\n",
      "Epoch 23, Train Loss: 0.6882, Val Loss: 0.6901, Test Accuracy: 0.5374 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1746623516082764\n",
      "Epoch 24, Train Loss: 0.6912, Val Loss: 0.6911, Test Accuracy: 0.5413 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1671903133392334\n",
      "Epoch 25, Train Loss: 0.6882, Val Loss: 0.6909, Test Accuracy: 0.5387 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1708331108093262\n",
      "Epoch 26, Train Loss: 0.6882, Val Loss: 0.6905, Test Accuracy: 0.5334 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1794242858886719\n",
      "Epoch 27, Train Loss: 0.6899, Val Loss: 0.6926, Test Accuracy: 0.5334 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1707324981689453\n",
      "Epoch 28, Train Loss: 0.6871, Val Loss: 0.6913, Test Accuracy: 0.5308 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1694552898406982\n",
      "Epoch 29, Train Loss: 0.6883, Val Loss: 0.6923, Test Accuracy: 0.5308 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1794631481170654\n",
      "Epoch 30, Train Loss: 0.6868, Val Loss: 0.6916, Test Accuracy: 0.5308 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1756746768951416\n",
      "Epoch 31, Train Loss: 0.6888, Val Loss: 0.6897, Test Accuracy: 0.5360 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1716115474700928\n",
      "Epoch 32, Train Loss: 0.6877, Val Loss: 0.6922, Test Accuracy: 0.5308 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1785917282104492\n",
      "Epoch 33, Train Loss: 0.6863, Val Loss: 0.6882, Test Accuracy: 0.5465 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1721680164337158\n",
      "Epoch 34, Train Loss: 0.6865, Val Loss: 0.6895, Test Accuracy: 0.5334 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1647875308990479\n",
      "Epoch 35, Train Loss: 0.6876, Val Loss: 0.6915, Test Accuracy: 0.5282 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.161935806274414\n",
      "Epoch 36, Train Loss: 0.6861, Val Loss: 0.6923, Test Accuracy: 0.5295 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.170375108718872\n",
      "Epoch 37, Train Loss: 0.6855, Val Loss: 0.6895, Test Accuracy: 0.5465 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1380090713500977\n",
      "Epoch 38, Train Loss: 0.6843, Val Loss: 0.6917, Test Accuracy: 0.5334 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.152618169784546\n",
      "Epoch 39, Train Loss: 0.6856, Val Loss: 0.6919, Test Accuracy: 0.5295 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1600451469421387\n",
      "Epoch 40, Train Loss: 0.6835, Val Loss: 0.6923, Test Accuracy: 0.5308 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1597132682800293\n",
      "Epoch 41, Train Loss: 0.6868, Val Loss: 0.6909, Test Accuracy: 0.5374 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1517767906188965\n",
      "Epoch 42, Train Loss: 0.6846, Val Loss: 0.6899, Test Accuracy: 0.5413 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1593132019042969\n",
      "Epoch 43, Train Loss: 0.6813, Val Loss: 0.6909, Test Accuracy: 0.5347 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1662585735321045\n",
      "Epoch 44, Train Loss: 0.6842, Val Loss: 0.6916, Test Accuracy: 0.5334 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1609644889831543\n",
      "Epoch 45, Train Loss: 0.6826, Val Loss: 0.6928, Test Accuracy: 0.5374 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1607475280761719\n",
      "Epoch 46, Train Loss: 0.6827, Val Loss: 0.6904, Test Accuracy: 0.5400 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1641430854797363\n",
      "Epoch 47, Train Loss: 0.6832, Val Loss: 0.6915, Test Accuracy: 0.5426 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1106534004211426\n",
      "Epoch 48, Train Loss: 0.6846, Val Loss: 0.6914, Test Accuracy: 0.5413 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.108104944229126\n",
      "Epoch 49, Train Loss: 0.6827, Val Loss: 0.6930, Test Accuracy: 0.5360 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.1306533813476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 07:20:02,923] Trial 49 finished with value: 0.5609436435124509 and parameters: {'HIDDEN_DIMENSION': 71, 'NO_OF_LAYERS': 3, 'BATCH_SIZE': 64, 'DROP_OUT': 0.19245716833704454, 'LEARNING_RATE': 8.189452784892711e-05}. Best is trial 46 with value: 0.5740498034076016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.6836, Val Loss: 0.6899, Test Accuracy: 0.5413 ,Learning Rate: 8.189452784892711e-05 , Time Taken : 1.144930362701416\n",
      "Accuracy: 0.5740498034076016\n",
      "Best hyperparameters: {'HIDDEN_DIMENSION': 88, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 64, 'DROP_OUT': 0.18612418176703444, 'LEARNING_RATE': 0.00010164966155256074}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    hyperparameter = {}\n",
    "    hyperparameter['INPUT_DIMENSION'] = len(kmer_dict)\n",
    "    hyperparameter['HIDDEN_DIMENSION'] = trial.suggest_int('HIDDEN_DIMENSION', 16, 128)\n",
    "    hyperparameter['NO_OF_LAYERS'] = trial.suggest_int('NO_OF_LAYERS', 1, 4)\n",
    "    hyperparameter['BATCH_SIZE'] = trial.suggest_categorical('BATCH_SIZE', [64, 512, 1024])\n",
    "    hyperparameter['OUTPUT_DIMENSION'] = len(eligible_class_list)\n",
    "    hyperparameter['EMBEDDING_DIMENSION'] = 16  # Adjust as needed\n",
    "    hyperparameter['DROP_OUT'] = trial.suggest_float('DROP_OUT', 0.1, 0.5)\n",
    "    hyperparameter['LEARNING_RATE'] = trial.suggest_loguniform('LEARNING_RATE', 1e-5, 1e-3)\n",
    "\n",
    "    model = RNATransformerModel(input_dim=hyperparameter['INPUT_DIMENSION'],\n",
    "                                embedding_dim=hyperparameter['EMBEDDING_DIMENSION'],\n",
    "                                hidden_dim=hyperparameter['HIDDEN_DIMENSION'],\n",
    "                                num_layers=hyperparameter['NO_OF_LAYERS'],\n",
    "                                output_dim=hyperparameter['OUTPUT_DIMENSION'],\n",
    "                                dropout=hyperparameter['DROP_OUT'])\n",
    "\n",
    "    model = DataParallel(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyperparameter['LEARNING_RATE'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "    num_epochs = 50\n",
    "    print(\"Model Parameters  : \" , hyperparameter)\n",
    "    \n",
    "    train_model(model, train_dataloader ,test_dataloader, device ,num_epochs,optimizer,loss_function)\n",
    "\n",
    "    _, final_accuracy, true_labels, predicted_labels = validate_model(model, valid_dataloader,device,loss_function)\n",
    "\n",
    "    return final_accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # Print the result\n",
    "trial = study.best_trial\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8rs97X-5BVS",
    "outputId": "26c46104-dafe-484d-85e8-8d51bb5c00ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.5714\n",
      "\n",
      " Classification Summary:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.64       484\n",
      "           1       0.43      0.53      0.48       279\n",
      "\n",
      "    accuracy                           0.57       763\n",
      "   macro avg       0.56      0.56      0.56       763\n",
      "weighted avg       0.59      0.57      0.58       763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "_, final_accuracy, true_labels, predicted_labels = validate_model(model, valid_dataloader,device,loss_function)\n",
    "\n",
    "# Print the final accuracy\n",
    "print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Print the classification summary\n",
    "print(\"\\n Classification Summary:\")\n",
    "print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"multi-class-type-C.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c230947687a8f3ffad2ce5baec6aac89e01c839661a42aacfb7c80a5442a49ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
