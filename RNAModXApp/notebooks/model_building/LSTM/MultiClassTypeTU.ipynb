{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkDJ1UJK69ON",
        "outputId": "c1eec5ea-65de-40a5-9c79-41a472c445ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/390.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install optuna  scikit-learn gensim imbalanced-learn xgboost torch pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ohWCGHSq5BVM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shashi.vish\\Python Environment\\RNA_ModX\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        " #Import All Libraries Here\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score ,  roc_curve, auc , classification_report\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import optuna\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import time\n",
        "from collections import Counter\n",
        "# PyTorch Import\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "WINDOW_SIZE = 50\n",
        "\n",
        "# 1 - One Hot Encoding with Pytorch in build Emnedding\n",
        "# 2 - 3-mer coding with number encoding\n",
        "ENCODING_METHOD = 2\n",
        "\n",
        "# 1- Random Over Sampling\n",
        "# 2 - Weighted Over Sampler\n",
        "SAMPLING_METHOD =1\n",
        "\n",
        "# 1 - LSTM with Cross Entropy\n",
        "MODEL = 1\n",
        "\n",
        "\n",
        "FRAMEWORK = \"PYTORCH\"\n",
        "\n",
        "# Startegy to Crop Sequene\n",
        "# MID - Modification is present at Mid of cropped Sequence\n",
        "# END - Modification is present at End of cropepd Sequence\n",
        "CROP_STRATEGY = 'MID'\n",
        "\n",
        "# Y Category Encoding Method\n",
        "# LABEL or ONE_HOT\n",
        "TARGET_ENCODING = 'LABEL'\n",
        "\n",
        "ENCODING_FILE = '3-mer-dictionary.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQvMm5lH5BVO",
        "outputId": "442f7e0b-129a-4add-f95e-c353acecda48"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# INPUT_TRAIN_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/train_in.csv\"\n",
        "# INPUT_TRAIN_OUT = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/train_out.csv\"\n",
        "# INPUT_TEST_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/test_in.csv\"\n",
        "# INPUT_TEST_OUT = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/test_out.csv\"\n",
        "# INPUT_VALIDATION_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/valid_in_nucleo.csv\"\n",
        "# INPUT_VALIDATION_OUT  = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/valid_out.csv\"\n",
        "\n",
        "# Record Constants\n",
        "# Record Constants\n",
        "INPUT_TRAIN_IN = \"../../../data/train_in.csv\"\n",
        "INPUT_TRAIN_OUT = \"../../../data/train_out.csv\"\n",
        "INPUT_TEST_IN = \"../../../data/test_in.csv\"\n",
        "INPUT_TEST_OUT = \"../../../data/test_out.csv\"\n",
        "INPUT_VALIDATION_IN = \"../../../data/valid_in_nucleo.csv\"\n",
        "INPUT_VALIDATION_OUT  = \"../../../data/valid_out.csv\"\n",
        "\n",
        "# TARGET_MODEL_PATH = '../../webapp/model_files'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcUOufcj5BVO",
        "outputId": "10cc65ec-1618-4a0f-dcc7-0727a3a71f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape of X : (304661, 1001) and Tranin Shape of Y : (304661, 1001)\n",
            "Test Shape of X : (1200, 1001) and Test Shape of Y : (1200, 12)\n",
            "Validation Shape of X : (3599, 1001) and Validation Shape of Y : (3599, 12)\n"
          ]
        }
      ],
      "source": [
        "#Read X Varaibles and Y Varaibles\n",
        "\n",
        "x_train_raw =  pd.read_csv(INPUT_TRAIN_IN, header=None , skiprows=1 )\n",
        "y_train_raw =  pd.read_csv(INPUT_TRAIN_OUT, header=None , skiprows=1 )\n",
        "\n",
        "x_test_raw =  pd.read_csv(INPUT_TEST_IN, header=None , skiprows=1 )\n",
        "y_test_raw =  pd.read_csv(INPUT_TEST_OUT, header=None , skiprows=1)\n",
        "\n",
        "x_valid_raw =  pd.read_csv(INPUT_VALIDATION_IN, header=None , skiprows=1 )\n",
        "y_valid_raw =  pd.read_csv(INPUT_VALIDATION_OUT, header=None , skiprows=1 )\n",
        "\n",
        "x_data = pd.concat([x_train_raw, x_test_raw, x_valid_raw], axis=0, ignore_index=True)\n",
        "y_data = pd.concat([y_train_raw, y_test_raw, y_valid_raw], axis=0, ignore_index=True)\n",
        "\n",
        "print(f\"Train Shape of X : {x_train_raw.shape} and Tranin Shape of Y : {x_train_raw.shape}\")\n",
        "print(f\"Test Shape of X : {x_test_raw.shape} and Test Shape of Y : {y_test_raw.shape}\")\n",
        "print(f\"Validation Shape of X : {x_valid_raw.shape} and Validation Shape of Y : {y_valid_raw.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwZ2AFCo5BVO"
      },
      "source": [
        "### Calculate Sequence Positions to extracted from Original Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uWqxeK7J5BVP"
      },
      "outputs": [],
      "source": [
        "middle_index = (x_train_raw.shape[1] // 2) + 1 # This is location for Modified Sequence . Use this as Y Target\n",
        "\n",
        "if CROP_STRATEGY == 'MID':\n",
        "    STRAT_INEDX =middle_index - WINDOW_SIZE -1\n",
        "    END_INDEX =middle_index + WINDOW_SIZE\n",
        "\n",
        "if CROP_STRATEGY == 'END':\n",
        "    STRAT_INEDX =middle_index - (WINDOW_SIZE*2) -1\n",
        "    END_INDEX =middle_index\n",
        "\n",
        "x_data_cropped =  x_data.iloc[:,STRAT_INEDX :END_INDEX]\n",
        "concatenated_column= x_data_cropped.apply(lambda row: ''.join(map(str, row)), axis=1)\n",
        "x_data_cropped = x_data_cropped.assign(Sequence=concatenated_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "jRDnwbiM5BVP",
        "outputId": "0d007b12-6da3-4cca-814a-57e8a3c5e5ba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>450</th>\n",
              "      <th>451</th>\n",
              "      <th>452</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "      <th>457</th>\n",
              "      <th>458</th>\n",
              "      <th>459</th>\n",
              "      <th>...</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>TTGCCACACTGCTGGACGCCTGCAAGGCCAAGGGTACGGAGGTCAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>TTTGAAAAAATATTAGCAATGTGAGGACACTTAAGCAGTTTTGTCA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>AGAAACATTCAACCTCCCTTCTTTTTATTCCAGTTGTCCTTTTCTC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>TTAGTTTTACTATGGAATCATAATAACCCACATAGAAGACTGATAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>CAACAGAAGTTTCTCATCTATAATCAGTAGCACTAAACTCTTGGTT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309455</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>CCAAACTCTTTATCTCTTGAGTTCTCAGCCAATAGGGCCATTGTAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309456</th>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>GATCCAGTTGAAAACGTATCCCTCTACTTTCTTCAGTTGTAGAAAA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309457</th>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>GCCAGGGCAAAGCTGGCTGATTTTACGTGTTTAAGGATGAAATATC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309458</th>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>CTGGGTGCGACAGGCCACTGGACAAGGGCTTGAGTGGATGGGATGG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309459</th>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>GGCTGCTAAGGCAATGTGCTCTCCTAATTTCCCTTTTTCCTTTGTG...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>309460 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       450 451 452 453 454 455 456 457 458 459  ... 542 543 544 545 546 547  \\\n",
              "0        T   T   G   C   C   A   C   A   C   T  ...   C   A   G   T   A   T   \n",
              "1        T   T   T   G   A   A   A   A   A   A  ...   T   C   A   T   C   G   \n",
              "2        A   G   A   A   A   C   A   T   T   C  ...   T   T   C   T   G   T   \n",
              "3        T   T   A   G   T   T   T   T   A   C  ...   A   A   A   A   A   T   \n",
              "4        C   A   A   C   A   G   A   A   G   T  ...   A   A   A   A   T   G   \n",
              "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
              "309455   C   C   A   A   A   C   T   C   T   T  ...   G   G   G   C   A   G   \n",
              "309456   G   A   T   C   C   A   G   T   T   G  ...   A   C   A   G   G   T   \n",
              "309457   G   C   C   A   G   G   G   C   A   A  ...   C   A   A   G   C   T   \n",
              "309458   C   T   G   G   G   T   G   C   G   A  ...   G   C   A   G   A   G   \n",
              "309459   G   G   C   T   G   C   T   A   A   G  ...   C   T   C   A   A   A   \n",
              "\n",
              "       548 549 550                                           Sequence  \n",
              "0        C   T   C  TTGCCACACTGCTGGACGCCTGCAAGGCCAAGGGTACGGAGGTCAT...  \n",
              "1        T   G   C  TTTGAAAAAATATTAGCAATGTGAGGACACTTAAGCAGTTTTGTCA...  \n",
              "2        T   C   A  AGAAACATTCAACCTCCCTTCTTTTTATTCCAGTTGTCCTTTTCTC...  \n",
              "3        T   T   C  TTAGTTTTACTATGGAATCATAATAACCCACATAGAAGACTGATAT...  \n",
              "4        T   A   C  CAACAGAAGTTTCTCATCTATAATCAGTAGCACTAAACTCTTGGTT...  \n",
              "...     ..  ..  ..                                                ...  \n",
              "309455   A   G   A  CCAAACTCTTTATCTCTTGAGTTCTCAGCCAATAGGGCCATTGTAG...  \n",
              "309456   A   A   T  GATCCAGTTGAAAACGTATCCCTCTACTTTCTTCAGTTGTAGAAAA...  \n",
              "309457   G   A   T  GCCAGGGCAAAGCTGGCTGATTTTACGTGTTTAAGGATGAAATATC...  \n",
              "309458   T   C   A  CTGGGTGCGACAGGCCACTGGACAAGGGCTTGAGTGGATGGGATGG...  \n",
              "309459   C   G   A  GGCTGCTAAGGCAATGTGCTCTCCTAATTTCCCTTTTTCCTTTGTG...  \n",
              "\n",
              "[309460 rows x 102 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_data_cropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KLuiCU2X5BVP"
      },
      "outputs": [],
      "source": [
        "x_train_raw = None\n",
        "y_train_raw = None\n",
        "x_test_raw = None\n",
        "y_test_raw = None\n",
        "x_valid_raw = None\n",
        "y_valid_raw = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIM49qM75BVP"
      },
      "source": [
        "### Apply One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tf17dHN95BVP"
      },
      "outputs": [],
      "source": [
        "number_of_unique_kmers = set()\n",
        "def encode_seq(kmer_token):\n",
        "\n",
        "    # A 1 0 0 0\n",
        "    # C 0 1 0 0\n",
        "    # T/U 0 0 0 1\n",
        "    # G 0 0 1 0\n",
        "    # N 0 0 0 0\n",
        "\n",
        "    encoding_dict = {\n",
        "        'A': [1, 0, 0, 0],\n",
        "        'C': [0, 1, 0, 0],\n",
        "        'G': [0, 0, 1, 0],\n",
        "        'T': [0, 0, 0, 1],\n",
        "        'U': [0, 0, 0, 1],\n",
        "        'N': [0, 0, 0, 0],\n",
        "    }\n",
        "\n",
        "    encoded_sequence = []\n",
        "    number_of_unique_kmers.add(kmer_token)\n",
        "    for  base in kmer_token:\n",
        "        encoded_sequence.append(encoding_dict[base])\n",
        "    return np.array(encoded_sequence).flatten()\n",
        "\n",
        "def applyOneHotEncoding(tokenized_sequences):\n",
        "    encoded_sequences = []\n",
        "    for seq in tokenized_sequences:\n",
        "        encoded_sequences.append(encode_seq(seq))\n",
        "\n",
        "    return np.array(encoded_sequences).flatten()\n",
        "\n",
        "def encode_with_one_hot_encoding(x_train_raw):\n",
        "    truncated_df =  x_train_raw.iloc[:,STRAT_INEDX :END_INDEX] # Window Starts from V501 with 50 window size\n",
        "    concatenated_column= truncated_df.apply(lambda row: ''.join(map(str, row)), axis=1)\n",
        "    df_result = truncated_df.assign(Sequence=concatenated_column)\n",
        "    tokenized_sequences =  df_result['Sequence'].apply(applyOneHotEncoding).tolist()\n",
        "\n",
        "    return tokenized_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk_WaSe35BVP"
      },
      "source": [
        "### 3 mer coding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JwIzW5gY5BVQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "kmer_dict = {}\n",
        "k = 3\n",
        "with open(ENCODING_FILE, 'rb') as f:\n",
        "    kmer_dict = pickle.load(f)\n",
        "\n",
        "\n",
        "def encode_with_k_mer_codon(sequence):\n",
        "    #print(sequence)\n",
        "    encoded_sequence = []\n",
        "    for i in range(len(sequence) - k + 1):\n",
        "        if sequence[i:i+k] not in kmer_dict:\n",
        "            print(\"Key Not Found\" , kmer_dict)\n",
        "        encoded_sequence.append(kmer_dict[sequence[i:i+k]] )\n",
        "    return np.array(encoded_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ds7NWJtl5BVQ"
      },
      "outputs": [],
      "source": [
        "## Filter Dataset to Keep only Target Binary Class\n",
        "\n",
        "RMs = ['hAm','hCm','hGm','hTm','hm1A','hm5C','hm5U','hm6A','hm6Am','hm7G','hPsi','Atol','NonMoD']\n",
        "RMEncoding = [12,1,2,3,4,5,6,7,8,9,10,11,0]\n",
        "\n",
        "eligible_class_list = ['hTm', 'hm5U', 'hPsi']\n",
        "ARMEncoding = [0,1,2]\n",
        "\n",
        "def convert_y_to_original_labels(row):\n",
        "    label = \"\"  \n",
        "    for index , n in enumerate(row.tolist()) :\n",
        "        if n == 1 :\n",
        "            label = RMs[index]\n",
        "    if label == '':\n",
        "        return 'NonMoD'\n",
        "    return label\n",
        "\n",
        "def get_original_y_lables( y_data ):\n",
        "    # Convert One Hot Encoded Y to to Original Labels\n",
        "    y_original_labels = y_data.apply(convert_y_to_original_labels,axis=1)\n",
        "    return y_original_labels\n",
        "\n",
        "\n",
        "\n",
        "def encode_target(y_data):\n",
        "    # Write Customer Lable Encoder . This is required since we have train and test alreday splitted. Always creating a new instanc of label encoder will change encoding.\n",
        "\n",
        "    y_encoded = []\n",
        "    for y in y_data:\n",
        "        index = eligible_class_list.index(y)\n",
        "        encoding =  ARMEncoding[index]\n",
        "        y_encoded.append(encoding)\n",
        "    return y_encoded\n",
        "\n",
        "def prepare_data_for_binary_classification(x_data , y_data , prediction_class):\n",
        "    # Convert One Hot Encoded Y to to Original Labels\n",
        "    y_original_labels = y_data.apply(convert_y_to_original_labels,axis=1)\n",
        "    x_data['Label'] = y_original_labels\n",
        "\n",
        "    selected_rna_data = x_data[x_data['Label'].isin(prediction_class)]\n",
        "\n",
        "    y_filtered = selected_rna_data['Label']\n",
        "    x_filtered = selected_rna_data.drop('Label', axis=1)\n",
        "\n",
        "    return x_filtered , y_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter Data For target Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zJEu1A4c5BVQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_data_filtered , y_data_filtered = prepare_data_for_binary_classification(x_data_cropped , y_data , eligible_class_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akLbxB6z5BVQ",
        "outputId": "faaf160a-ff4f-4f06-f16d-29667a37b997"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>450</th>\n",
              "      <th>451</th>\n",
              "      <th>452</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "      <th>457</th>\n",
              "      <th>458</th>\n",
              "      <th>459</th>\n",
              "      <th>...</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8680</th>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>CTTAAAAGAAGTGCTAAGATGGTGCTGAAGTTCATAATCCAAACGT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8681</th>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>TCATCTGTATTGTAGCATGTGTCAGGCCTTCATTTGTTTTTATGGC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8682</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>TTGTTTCCTGATGATACGGCTTCTCCAGAGTTTGGGGGGCCTGGAA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8683</th>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>AGAGTATAATTAGAAGACTCTTCTGAACAGAGAATTTTAAGTGGGA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8684</th>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>GCCCTGTGCCTGGTAACGATCGTTCTCACAGTCATGGCCGTAGGGA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309006</th>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>AATTAAAACAAGTGTTTTAAGATTTCACAGATATCTAAATACAGCA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309007</th>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>GAGATCTGCCCGCCTCAGCCTCCCAAAGTGCTCGGATTATAGGCGT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309008</th>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>TATACTAACAAGTGTGAGATGCTAACTCATGGTTTTATTTTGCATT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309009</th>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>ATACAGTTATGTCAGTAGTGTAAGGTTACGTACATTACAGTAGTGT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309010</th>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>GTGAACTGCTTTAGGACAGATTCAGTTCTGTGATCAAGATGAAAAA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9086 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       450 451 452 453 454 455 456 457 458 459  ... 542 543 544 545 546 547  \\\n",
              "8680     C   T   T   A   A   A   A   G   A   A  ...   A   T   G   T   G   G   \n",
              "8681     T   C   A   T   C   T   G   T   A   T  ...   T   T   T   T   T   T   \n",
              "8682     T   T   G   T   T   T   C   C   T   G  ...   G   G   A   G   G   G   \n",
              "8683     A   G   A   G   T   A   T   A   A   T  ...   C   A   G   T   G   A   \n",
              "8684     G   C   C   C   T   G   T   G   C   C  ...   G   C   A   T   T   T   \n",
              "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
              "309006   A   A   T   T   A   A   A   A   C   A  ...   C   A   G   C   T   T   \n",
              "309007   G   A   G   A   T   C   T   G   C   C  ...   G   T   A   T   C   T   \n",
              "309008   T   A   T   A   C   T   A   A   C   A  ...   G   C   C   A   T   T   \n",
              "309009   A   T   A   C   A   G   T   T   A   T  ...   T   C   A   C   C   C   \n",
              "309010   G   T   G   A   A   C   T   G   C   T  ...   C   T   C   A   G   G   \n",
              "\n",
              "       548 549 550                                           Sequence  \n",
              "8680     C   C   C  CTTAAAAGAAGTGCTAAGATGGTGCTGAAGTTCATAATCCAAACGT...  \n",
              "8681     T   T   T  TCATCTGTATTGTAGCATGTGTCAGGCCTTCATTTGTTTTTATGGC...  \n",
              "8682     T   T   T  TTGTTTCCTGATGATACGGCTTCTCCAGAGTTTGGGGGGCCTGGAA...  \n",
              "8683     A   C   T  AGAGTATAATTAGAAGACTCTTCTGAACAGAGAATTTTAAGTGGGA...  \n",
              "8684     C   T   T  GCCCTGTGCCTGGTAACGATCGTTCTCACAGTCATGGCCGTAGGGA...  \n",
              "...     ..  ..  ..                                                ...  \n",
              "309006   C   A   A  AATTAAAACAAGTGTTTTAAGATTTCACAGATATCTAAATACAGCA...  \n",
              "309007   T   A   A  GAGATCTGCCCGCCTCAGCCTCCCAAAGTGCTCGGATTATAGGCGT...  \n",
              "309008   T   G   T  TATACTAACAAGTGTGAGATGCTAACTCATGGTTTTATTTTGCATT...  \n",
              "309009   A   G   A  ATACAGTTATGTCAGTAGTGTAAGGTTACGTACATTACAGTAGTGT...  \n",
              "309010   G   A   C  GTGAACTGCTTTAGGACAGATTCAGTTCTGTGATCAAGATGAAAAA...  \n",
              "\n",
              "[9086 rows x 102 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_data_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "hm5U    3696\n",
              "hPsi    3137\n",
              "hTm     2253\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_data_filtered.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "EJjCTy9m5BVQ",
        "outputId": "a5b4a34b-0f23-4ff6-cb26-b9aa16851f7e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "y_counts = y_data_filtered.value_counts()\n",
        "colors = cm.tab20(range(len(y_counts)))\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(y_counts.index, y_counts.values , color = colors)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Value counts of each class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTPaFg0d5BVQ",
        "outputId": "794c6077-0e7c-4358-89ff-7d6c7039f921"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8680      CTTAAAAGAAGTGCTAAGATGGTGCTGAAGTTCATAATCCAAACGT...\n",
              "8681      TCATCTGTATTGTAGCATGTGTCAGGCCTTCATTTGTTTTTATGGC...\n",
              "8682      TTGTTTCCTGATGATACGGCTTCTCCAGAGTTTGGGGGGCCTGGAA...\n",
              "8683      AGAGTATAATTAGAAGACTCTTCTGAACAGAGAATTTTAAGTGGGA...\n",
              "8684      GCCCTGTGCCTGGTAACGATCGTTCTCACAGTCATGGCCGTAGGGA...\n",
              "                                ...                        \n",
              "309006    AATTAAAACAAGTGTTTTAAGATTTCACAGATATCTAAATACAGCA...\n",
              "309007    GAGATCTGCCCGCCTCAGCCTCCCAAAGTGCTCGGATTATAGGCGT...\n",
              "309008    TATACTAACAAGTGTGAGATGCTAACTCATGGTTTTATTTTGCATT...\n",
              "309009    ATACAGTTATGTCAGTAGTGTAAGGTTACGTACATTACAGTAGTGT...\n",
              "309010    GTGAACTGCTTTAGGACAGATTCAGTTCTGTGATCAAGATGAAAAA...\n",
              "Name: Sequence, Length: 9086, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_data_filtered['Sequence']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULG0B0e95BVQ",
        "outputId": "69c76a6c-6b7e-4121-9a88-96d17bf2a5b6"
      },
      "outputs": [],
      "source": [
        "encoded_sequences = [encode_with_k_mer_codon(sequence) for sequence in x_data_filtered['Sequence']]\n",
        "X_encoded = np.array(encoded_sequences)\n",
        "X_encoded_tensor = torch.tensor(X_encoded, dtype=torch.float32)\n",
        "y_encoded = encode_target(y_data_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne-hmuDd5BVR",
        "outputId": "dbebeca1-6b70-4cfd-b2d2-3c011fdfac48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[50., 50., 62.,  ..., 50., 35., 52.],\n",
              "        [ 6., 42., 50.,  ..., 55., 12., 22.],\n",
              "        [17., 44., 30.,  ..., 61., 50., 62.],\n",
              "        ...,\n",
              "        [50., 35., 45.,  ..., 17., 29.,  1.],\n",
              "        [43., 11., 60.,  ..., 34., 50., 43.],\n",
              "        [25., 52., 39.,  ...,  1.,  2., 33.]])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_encoded_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etAEiUuL5BVR",
        "outputId": "3ce21d47-4199-4911-83b0-a095d1ceda83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generate Train and Split..\n"
          ]
        }
      ],
      "source": [
        "print(\"Generate Train and Split..\")\n",
        "# Train set\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Test and Validation set\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxuA3OdC5BVR",
        "outputId": "0df4344b-8c3a-4fbc-c67b-4973076f8446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Y Count :  Counter({1: 2594, 2: 2196, 0: 1570})\n",
            "Test Y Count :  Counter({1: 532, 2: 500, 0: 331})\n"
          ]
        }
      ],
      "source": [
        "X_encoded = None\n",
        "y_encoded = None\n",
        "x_data_filtered , y_data_filtered = None,None\n",
        "x_data , y_data = None , None\n",
        "\n",
        "print(\"Train Y Count : \" ,Counter(y_train))\n",
        "print(\"Test Y Count : \" ,Counter(y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zb-kIy35BVR"
      },
      "source": [
        "### Balance Datset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3tEqKJG25BVR"
      },
      "outputs": [],
      "source": [
        "y_train = torch.tensor(y_train , dtype=torch.long)\n",
        "y_test = torch.tensor(y_test , dtype=torch.long)\n",
        "y_valid = torch.tensor(y_valid , dtype=torch.long)\n",
        "\n",
        "sm = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
        "y_resampled = torch.tensor(y_resampled , dtype=torch.float32) # Keeping float32\n",
        "X_resampled = torch.tensor(X_resampled , dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpftneeP5BVR",
        "outputId": "45c7f234-7cba-475a-85a2-a23c25c9aa29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6360, 99)\n",
            "torch.Size([6360])\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM0C9uYE5BVS",
        "outputId": "3cb2f8f6-abd9-44f5-81d6-5d71e9a1162b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([26., 46., 32.,  3.,  4., 37.,  2.,  3., 32., 12., 13.,  0.,  0.,  0.,\n",
              "        23., 38., 53., 48., 56., 53., 54., 12., 13.,  1., 19., 56., 39.,  9.,\n",
              "        46., 32.,  3., 32., 12., 15., 38., 53., 63., 54., 12., 11., 19.,  9.,\n",
              "        27., 45., 21., 34., 50., 43., 22., 42., 62., 32.,  3., 47., 63., 63.,\n",
              "        54., 61., 62., 47., 63., 59., 37.,  2.,  3., 32., 61., 43., 22., 42.,\n",
              "        62.,  4.,  5.,  1.,  2., 33., 28., 18., 19.,  9., 34., 43., 11., 19.,\n",
              "        31., 18., 60., 54., 12., 11., 36., 37.,  2., 12., 13.,  6., 42., 35.,\n",
              "        45.])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_resampled[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pIOzPJWY5BVS"
      },
      "outputs": [],
      "source": [
        "hyperparameter = {}\n",
        "hyperparameter['INPUT_DIMENSION'] = len(kmer_dict) # For One Hot Encoding Input Dimension would be 4 as there only 4 unique nucleocide\n",
        "hyperparameter['HIDDEN_DIMENSION'] = 32\n",
        "hyperparameter['NO_OF_LAYERS'] = 2\n",
        "hyperparameter['BATCH_SIZE'] = 32\n",
        "hyperparameter['OUTPUT_DIMENSION'] = len(eligible_class_list)\n",
        "hyperparameter['EMBEDDING_DIMENSION'] = 16 # if you are using Word2Vec Encoding then this should be same as Word2Vec Embedding Dim\n",
        "hyperparameter['DROP_OUT'] = 0.1\n",
        "hyperparameter['LEARNING_RATE'] = 0.0001\n",
        "\n",
        "\n",
        "class RNADataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "\n",
        "train_dataset = RNADataset(X_resampled, y_resampled)\n",
        "test_dataset = RNADataset(X_test, y_test)\n",
        "valid_dataset = RNADataset(X_valid, y_valid)\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sXVdBroi5BVS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNATransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, output_dim, dropout=0.5):\n",
        "        super(RNATransformerModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "\n",
        "        # If batch size first is true then it should be batch size , sequence lenght , embedding dimension\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=8, dim_feedforward=hidden_dim , batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.long()\n",
        "        #print(\"Shape of Original X  \", x.shape)\n",
        "        x_embedded = self.embedding(x)\n",
        "        #print(\"Shape of X embedded\" , x_embedded.shape)\n",
        "        x_transformed = self.transformer_encoder(x_embedded)\n",
        "        #print(\"Shape of Transformed X\" , x_transformed.shape)\n",
        "        x_transformed = x_transformed[:, -1, :]  # taking the last token's output\n",
        "\n",
        "        output = self.dropout(x_transformed)\n",
        "        out = self.fc(output)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sP484k65BVS",
        "outputId": "1bf3a3f4-e539-4b89-8f0c-3918db6732ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 99])\n"
          ]
        }
      ],
      "source": [
        "# Check data is in correct shape - batch size , sequece len , embedding dimension size\n",
        "for inputs, labels in train_dataloader:\n",
        "    print(inputs.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-t8RdUvy5BVS"
      },
      "outputs": [],
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "\n",
        "def validate_model(model, test_dataloader , device ,loss_function):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    class_correct = [0] * hyperparameter['OUTPUT_DIMENSION']\n",
        "    class_total = [0] * hyperparameter['OUTPUT_DIMENSION']\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            true_labels.extend(labels.cpu().numpy())  # Capture True Lables for Summary Report\n",
        "            predicted_labels.extend(predicted.cpu().numpy()) # Capture Predicted Labels Lables for Summary Report\n",
        "\n",
        "    validation_loss = running_loss / len(test_dataloader)\n",
        "    validation_accuracy = correct / total\n",
        "\n",
        "    return validation_loss , validation_accuracy , true_labels , predicted_labels\n",
        "\n",
        "\n",
        "def train_model(model, train_dataloader, test_dataloader, device, epochs, optimizer, loss_function):\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement_count = 0\n",
        "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) \n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_dataloader)\n",
        "        val_loss,  validation_accuracy , true_labels , predicted_labels = validate_model(model, test_dataloader, device, loss_function)\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Test Accuracy: {validation_accuracy:.4f} ,Learning Rate: {optimizer.param_groups[0]['lr']} , Time Taken : {elapsed_time}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement_count = 0\n",
        "        else:\n",
        "            no_improvement_count += 1\n",
        "            if no_improvement_count == 5:\n",
        "                print(\"No improvement in validation loss for 5 epochs. Training stopped.\")\n",
        "                break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7wtvOzF5BVS",
        "outputId": "ea97784b-22dc-4b48-f2c6-30f3f397fce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Parameters for Model Training : 8227 \n",
            "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 32, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 32, 'OUTPUT_DIMENSION': 3, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1, 'LEARNING_RATE': 0.0001}\n",
            "Epoch 1, Train Loss: 1.1845, Val Loss: 1.1564, Test Accuracy: 0.3140 ,Learning Rate: 0.0001 , Time Taken : 19.524578332901\n"
          ]
        }
      ],
      "source": [
        "model = RNATransformerModel(input_dim=hyperparameter['INPUT_DIMENSION'],\n",
        "                            embedding_dim=hyperparameter['EMBEDDING_DIMENSION'],\n",
        "                            hidden_dim=hyperparameter['HIDDEN_DIMENSION'] ,\n",
        "                            num_layers = hyperparameter['NO_OF_LAYERS'],\n",
        "                            output_dim=hyperparameter['OUTPUT_DIMENSION'],\n",
        "                            dropout=hyperparameter['DROP_OUT'] )\n",
        "\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()  ## MSELoss of Regression problem  # BCELoss for binary classification\n",
        "optimizer = optim.Adam(model.parameters() ,  lr=hyperparameter['LEARNING_RATE'])\n",
        "\n",
        "# Number of Parameters for Model\n",
        "total_parameters = []\n",
        "for p in model.parameters():\n",
        "    total_parameters.append(p.numel())\n",
        "\n",
        "print(f\"Total Number of Parameters for Model Training : { sum(total_parameters)} \" )\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Model Parameters  : \" , hyperparameter)\n",
        "\n",
        "# Train Model with configured Parameter\n",
        "train_model(model, train_dataloader ,test_dataloader, device ,num_epochs,optimizer,loss_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optuna Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    hyperparameter = {}\n",
        "    hyperparameter['INPUT_DIMENSION'] = len(kmer_dict)\n",
        "    hyperparameter['HIDDEN_DIMENSION'] = trial.suggest_int('HIDDEN_DIMENSION', 16, 128)\n",
        "    hyperparameter['NO_OF_LAYERS'] = trial.suggest_int('NO_OF_LAYERS', 1, 4)\n",
        "    hyperparameter['BATCH_SIZE'] = trial.suggest_categorical('BATCH_SIZE', [16, 32, 64])\n",
        "    hyperparameter['OUTPUT_DIMENSION'] = 5\n",
        "    hyperparameter['EMBEDDING_DIMENSION'] = 16  # Adjust as needed\n",
        "    hyperparameter['DROP_OUT'] = trial.suggest_float('DROP_OUT', 0.1, 0.5)\n",
        "    hyperparameter['LEARNING_RATE'] = trial.suggest_loguniform('LEARNING_RATE', 1e-5, 1e-3)\n",
        "\n",
        "    model = RNATransformerModel(input_dim=hyperparameter['INPUT_DIMENSION'],\n",
        "                                embedding_dim=hyperparameter['EMBEDDING_DIMENSION'],\n",
        "                                hidden_dim=hyperparameter['HIDDEN_DIMENSION'],\n",
        "                                num_layers=hyperparameter['NO_OF_LAYERS'],\n",
        "                                output_dim=hyperparameter['OUTPUT_DIMENSION'],\n",
        "                                dropout=hyperparameter['DROP_OUT'])\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=hyperparameter['LEARNING_RATE'])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
        "\n",
        "\n",
        "    train_model(model, train_dataloader ,test_dataloader, device ,num_epochs,optimizer,loss_function)\n",
        "\n",
        "    _, final_accuracy, true_labels, predicted_labels = validate_model(model, valid_dataloader,device,loss_function)\n",
        "\n",
        "    return final_accuracy\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "    # Print the result\n",
        "trial = study.best_trial\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8rs97X-5BVS",
        "outputId": "26c46104-dafe-484d-85e8-8d51bb5c00ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Accuracy: 0.5229\n",
            "\n",
            " Classification Summary:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.53      0.59       484\n",
            "           1       0.38      0.51      0.44       279\n",
            "\n",
            "    accuracy                           0.52       763\n",
            "   macro avg       0.52      0.52      0.51       763\n",
            "weighted avg       0.55      0.52      0.53       763\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "_, final_accuracy, true_labels, predicted_labels = validate_model(model, valid_dataloader,device,loss_function)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "# Print the classification summary\n",
        "print(\"\\n Classification Summary:\")\n",
        "print(classification_report(true_labels, predicted_labels))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c230947687a8f3ffad2ce5baec6aac89e01c839661a42aacfb7c80a5442a49ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
