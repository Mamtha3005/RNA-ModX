{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkDJ1UJK69ON",
        "outputId": "c1eec5ea-65de-40a5-9c79-41a472c445ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/390.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install optuna  scikit-learn gensim imbalanced-learn xgboost torch pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ohWCGHSq5BVM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shashi.vish\\Python Environment\\RNA_ModX\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        " #Import All Libraries Here\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score ,  roc_curve, auc , classification_report\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import optuna\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import time\n",
        "from collections import Counter\n",
        "# PyTorch Import\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "WINDOW_SIZE = 50\n",
        "\n",
        "# 1 - One Hot Encoding with Pytorch in build Emnedding\n",
        "# 2 - 3-mer coding with number encoding\n",
        "ENCODING_METHOD = 2\n",
        "\n",
        "# 1- Random Over Sampling\n",
        "# 2 - Weighted Over Sampler\n",
        "SAMPLING_METHOD =1\n",
        "\n",
        "# 1 - LSTM with Cross Entropy\n",
        "MODEL = 1\n",
        "\n",
        "\n",
        "FRAMEWORK = \"PYTORCH\"\n",
        "\n",
        "# Startegy to Crop Sequene\n",
        "# MID - Modification is present at Mid of cropped Sequence\n",
        "# END - Modification is present at End of cropepd Sequence\n",
        "CROP_STRATEGY = 'MID'\n",
        "\n",
        "# Y Category Encoding Method\n",
        "# LABEL or ONE_HOT\n",
        "TARGET_ENCODING = 'LABEL'\n",
        "\n",
        "ENCODING_FILE = '3-mer-dictionary.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQvMm5lH5BVO",
        "outputId": "442f7e0b-129a-4add-f95e-c353acecda48"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# INPUT_TRAIN_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/train_in.csv\"\n",
        "# INPUT_TRAIN_OUT = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/train_out.csv\"\n",
        "# INPUT_TEST_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/test_in.csv\"\n",
        "# INPUT_TEST_OUT = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/test_out.csv\"\n",
        "# INPUT_VALIDATION_IN = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/valid_in_nucleo.csv\"\n",
        "# INPUT_VALIDATION_OUT  = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/valid_out.csv\"\n",
        "\n",
        "# Record Constants\n",
        "# Record Constants\n",
        "INPUT_TRAIN_IN = \"../../../data/train_in.csv\"\n",
        "INPUT_TRAIN_OUT = \"../../../data/train_out.csv\"\n",
        "INPUT_TEST_IN = \"../../../data/test_in.csv\"\n",
        "INPUT_TEST_OUT = \"../../../data/test_out.csv\"\n",
        "INPUT_VALIDATION_IN = \"../../../data/valid_in_nucleo.csv\"\n",
        "INPUT_VALIDATION_OUT  = \"../../../data/valid_out.csv\"\n",
        "\n",
        "# TARGET_MODEL_PATH = '../../webapp/model_files'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcUOufcj5BVO",
        "outputId": "10cc65ec-1618-4a0f-dcc7-0727a3a71f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape of X : (304661, 1001) and Tranin Shape of Y : (304661, 1001)\n",
            "Test Shape of X : (1200, 1001) and Test Shape of Y : (1200, 12)\n",
            "Validation Shape of X : (3599, 1001) and Validation Shape of Y : (3599, 12)\n"
          ]
        }
      ],
      "source": [
        "#Read X Varaibles and Y Varaibles\n",
        "\n",
        "x_train_raw =  pd.read_csv(INPUT_TRAIN_IN, header=None , skiprows=1 )\n",
        "y_train_raw =  pd.read_csv(INPUT_TRAIN_OUT, header=None , skiprows=1 )\n",
        "\n",
        "x_test_raw =  pd.read_csv(INPUT_TEST_IN, header=None , skiprows=1 )\n",
        "y_test_raw =  pd.read_csv(INPUT_TEST_OUT, header=None , skiprows=1)\n",
        "\n",
        "x_valid_raw =  pd.read_csv(INPUT_VALIDATION_IN, header=None , skiprows=1 )\n",
        "y_valid_raw =  pd.read_csv(INPUT_VALIDATION_OUT, header=None , skiprows=1 )\n",
        "\n",
        "x_data = pd.concat([x_train_raw, x_test_raw, x_valid_raw], axis=0, ignore_index=True)\n",
        "y_data = pd.concat([y_train_raw, y_test_raw, y_valid_raw], axis=0, ignore_index=True)\n",
        "\n",
        "print(f\"Train Shape of X : {x_train_raw.shape} and Tranin Shape of Y : {x_train_raw.shape}\")\n",
        "print(f\"Test Shape of X : {x_test_raw.shape} and Test Shape of Y : {y_test_raw.shape}\")\n",
        "print(f\"Validation Shape of X : {x_valid_raw.shape} and Validation Shape of Y : {y_valid_raw.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwZ2AFCo5BVO"
      },
      "source": [
        "### Calculate Sequence Positions to extracted from Original Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uWqxeK7J5BVP"
      },
      "outputs": [],
      "source": [
        "middle_index = (x_train_raw.shape[1] // 2) + 1 # This is location for Modified Sequence . Use this as Y Target\n",
        "\n",
        "if CROP_STRATEGY == 'MID':\n",
        "    STRAT_INEDX =middle_index - WINDOW_SIZE -1\n",
        "    END_INDEX =middle_index + WINDOW_SIZE\n",
        "\n",
        "if CROP_STRATEGY == 'END':\n",
        "    STRAT_INEDX =middle_index - (WINDOW_SIZE*2) -1\n",
        "    END_INDEX =middle_index\n",
        "\n",
        "x_data_cropped =  x_data.iloc[:,STRAT_INEDX :END_INDEX]\n",
        "concatenated_column= x_data_cropped.apply(lambda row: ''.join(map(str, row)), axis=1)\n",
        "x_data_cropped = x_data_cropped.assign(Sequence=concatenated_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "jRDnwbiM5BVP",
        "outputId": "0d007b12-6da3-4cca-814a-57e8a3c5e5ba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>450</th>\n",
              "      <th>451</th>\n",
              "      <th>452</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "      <th>457</th>\n",
              "      <th>458</th>\n",
              "      <th>459</th>\n",
              "      <th>...</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>TTGCCACACTGCTGGACGCCTGCAAGGCCAAGGGTACGGAGGTCAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>TTTGAAAAAATATTAGCAATGTGAGGACACTTAAGCAGTTTTGTCA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>AGAAACATTCAACCTCCCTTCTTTTTATTCCAGTTGTCCTTTTCTC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>TTAGTTTTACTATGGAATCATAATAACCCACATAGAAGACTGATAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>CAACAGAAGTTTCTCATCTATAATCAGTAGCACTAAACTCTTGGTT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309455</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>CCAAACTCTTTATCTCTTGAGTTCTCAGCCAATAGGGCCATTGTAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309456</th>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>GATCCAGTTGAAAACGTATCCCTCTACTTTCTTCAGTTGTAGAAAA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309457</th>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>GCCAGGGCAAAGCTGGCTGATTTTACGTGTTTAAGGATGAAATATC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309458</th>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>CTGGGTGCGACAGGCCACTGGACAAGGGCTTGAGTGGATGGGATGG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309459</th>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>GGCTGCTAAGGCAATGTGCTCTCCTAATTTCCCTTTTTCCTTTGTG...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>309460 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       450 451 452 453 454 455 456 457 458 459  ... 542 543 544 545 546 547  \\\n",
              "0        T   T   G   C   C   A   C   A   C   T  ...   C   A   G   T   A   T   \n",
              "1        T   T   T   G   A   A   A   A   A   A  ...   T   C   A   T   C   G   \n",
              "2        A   G   A   A   A   C   A   T   T   C  ...   T   T   C   T   G   T   \n",
              "3        T   T   A   G   T   T   T   T   A   C  ...   A   A   A   A   A   T   \n",
              "4        C   A   A   C   A   G   A   A   G   T  ...   A   A   A   A   T   G   \n",
              "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
              "309455   C   C   A   A   A   C   T   C   T   T  ...   G   G   G   C   A   G   \n",
              "309456   G   A   T   C   C   A   G   T   T   G  ...   A   C   A   G   G   T   \n",
              "309457   G   C   C   A   G   G   G   C   A   A  ...   C   A   A   G   C   T   \n",
              "309458   C   T   G   G   G   T   G   C   G   A  ...   G   C   A   G   A   G   \n",
              "309459   G   G   C   T   G   C   T   A   A   G  ...   C   T   C   A   A   A   \n",
              "\n",
              "       548 549 550                                           Sequence  \n",
              "0        C   T   C  TTGCCACACTGCTGGACGCCTGCAAGGCCAAGGGTACGGAGGTCAT...  \n",
              "1        T   G   C  TTTGAAAAAATATTAGCAATGTGAGGACACTTAAGCAGTTTTGTCA...  \n",
              "2        T   C   A  AGAAACATTCAACCTCCCTTCTTTTTATTCCAGTTGTCCTTTTCTC...  \n",
              "3        T   T   C  TTAGTTTTACTATGGAATCATAATAACCCACATAGAAGACTGATAT...  \n",
              "4        T   A   C  CAACAGAAGTTTCTCATCTATAATCAGTAGCACTAAACTCTTGGTT...  \n",
              "...     ..  ..  ..                                                ...  \n",
              "309455   A   G   A  CCAAACTCTTTATCTCTTGAGTTCTCAGCCAATAGGGCCATTGTAG...  \n",
              "309456   A   A   T  GATCCAGTTGAAAACGTATCCCTCTACTTTCTTCAGTTGTAGAAAA...  \n",
              "309457   G   A   T  GCCAGGGCAAAGCTGGCTGATTTTACGTGTTTAAGGATGAAATATC...  \n",
              "309458   T   C   A  CTGGGTGCGACAGGCCACTGGACAAGGGCTTGAGTGGATGGGATGG...  \n",
              "309459   C   G   A  GGCTGCTAAGGCAATGTGCTCTCCTAATTTCCCTTTTTCCTTTGTG...  \n",
              "\n",
              "[309460 rows x 102 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_data_cropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KLuiCU2X5BVP"
      },
      "outputs": [],
      "source": [
        "x_train_raw = None\n",
        "y_train_raw = None\n",
        "x_test_raw = None\n",
        "y_test_raw = None\n",
        "x_valid_raw = None\n",
        "y_valid_raw = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIM49qM75BVP"
      },
      "source": [
        "### Apply One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tf17dHN95BVP"
      },
      "outputs": [],
      "source": [
        "number_of_unique_kmers = set()\n",
        "def encode_seq(kmer_token):\n",
        "\n",
        "    # A 1 0 0 0\n",
        "    # C 0 1 0 0\n",
        "    # T/U 0 0 0 1\n",
        "    # G 0 0 1 0\n",
        "    # N 0 0 0 0\n",
        "\n",
        "    encoding_dict = {\n",
        "        'A': [1, 0, 0, 0],\n",
        "        'C': [0, 1, 0, 0],\n",
        "        'G': [0, 0, 1, 0],\n",
        "        'T': [0, 0, 0, 1],\n",
        "        'U': [0, 0, 0, 1],\n",
        "        'N': [0, 0, 0, 0],\n",
        "    }\n",
        "\n",
        "    encoded_sequence = []\n",
        "    number_of_unique_kmers.add(kmer_token)\n",
        "    for  base in kmer_token:\n",
        "        encoded_sequence.append(encoding_dict[base])\n",
        "    return np.array(encoded_sequence).flatten()\n",
        "\n",
        "def applyOneHotEncoding(tokenized_sequences):\n",
        "    encoded_sequences = []\n",
        "    for seq in tokenized_sequences:\n",
        "        encoded_sequences.append(encode_seq(seq))\n",
        "\n",
        "    return np.array(encoded_sequences).flatten()\n",
        "\n",
        "def encode_with_one_hot_encoding(x_train_raw):\n",
        "    truncated_df =  x_train_raw.iloc[:,STRAT_INEDX :END_INDEX] # Window Starts from V501 with 50 window size\n",
        "    concatenated_column= truncated_df.apply(lambda row: ''.join(map(str, row)), axis=1)\n",
        "    df_result = truncated_df.assign(Sequence=concatenated_column)\n",
        "    tokenized_sequences =  df_result['Sequence'].apply(applyOneHotEncoding).tolist()\n",
        "\n",
        "    return tokenized_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk_WaSe35BVP"
      },
      "source": [
        "### 3 mer coding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "JwIzW5gY5BVQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "kmer_dict = {}\n",
        "k = 3\n",
        "with open(ENCODING_FILE, 'rb') as f:\n",
        "    kmer_dict = pickle.load(f)\n",
        "\n",
        "\n",
        "def encode_with_k_mer_codon(sequence):\n",
        "    #print(sequence)\n",
        "    encoded_sequence = []\n",
        "    for i in range(len(sequence) - k + 1):\n",
        "        if sequence[i:i+k] not in kmer_dict:\n",
        "            print(\"Key Not Found\" , kmer_dict)\n",
        "        encoded_sequence.append(kmer_dict[sequence[i:i+k]] )\n",
        "    return np.array(encoded_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "Ds7NWJtl5BVQ"
      },
      "outputs": [],
      "source": [
        "## Filter Dataset to Keep only Target Binary Class\n",
        "\n",
        "RMs = ['hAm','hCm','hGm','hTm','hm1A','hm5C','hm5U','hm6A','hm6Am','hm7G','hPsi','Atol','NonMoD']\n",
        "RMEncoding = [12,1,2,3,4,5,6,7,8,9,10,11,0]\n",
        "\n",
        "eligible_class_list = ['hGm', 'hm7G']\n",
        "ARMEncoding = [0,1]\n",
        "\n",
        "def convert_y_to_original_labels(row):\n",
        "    label = \"\"  \n",
        "    for index , n in enumerate(row.tolist()) :\n",
        "        if n == 1 :\n",
        "            label = RMs[index]\n",
        "    if label == '':\n",
        "        return 'NonMoD'\n",
        "    return label\n",
        "\n",
        "def get_original_y_lables( y_data ):\n",
        "    # Convert One Hot Encoded Y to to Original Labels\n",
        "    y_original_labels = y_data.apply(convert_y_to_original_labels,axis=1)\n",
        "    return y_original_labels\n",
        "\n",
        "\n",
        "\n",
        "def encode_target(y_data):\n",
        "    # Write Customer Lable Encoder . This is required since we have train and test alreday splitted. Always creating a new instanc of label encoder will change encoding.\n",
        "\n",
        "    y_encoded = []\n",
        "    for y in y_data:\n",
        "        index = eligible_class_list.index(y)\n",
        "        encoding =  ARMEncoding[index]\n",
        "        y_encoded.append(encoding)\n",
        "    return y_encoded\n",
        "\n",
        "def prepare_data_for_binary_classification(x_data , y_data , prediction_class):\n",
        "    # Convert One Hot Encoded Y to to Original Labels\n",
        "    y_original_labels = y_data.apply(convert_y_to_original_labels,axis=1)\n",
        "    x_data['Label'] = y_original_labels\n",
        "\n",
        "    selected_rna_data = x_data[x_data['Label'].isin(prediction_class)]\n",
        "\n",
        "    y_filtered = selected_rna_data['Label']\n",
        "    x_filtered = selected_rna_data.drop('Label', axis=1)\n",
        "\n",
        "    return x_filtered , y_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "zJEu1A4c5BVQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_data_filtered , y_data_filtered = prepare_data_for_binary_classification(x_data_cropped , y_data , eligible_class_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akLbxB6z5BVQ",
        "outputId": "faaf160a-ff4f-4f06-f16d-29667a37b997"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>450</th>\n",
              "      <th>451</th>\n",
              "      <th>452</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "      <th>457</th>\n",
              "      <th>458</th>\n",
              "      <th>459</th>\n",
              "      <th>...</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2782</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>TTTTAACACAATACTTTAATAAGACACATTTAAACTCAACTTCTGA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2783</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>CCTTTGGGGGGCTAATAGCTCCTATATTCATTCAAAGAAGGAATAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2784</th>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>GGCGCAGGGAAGAGGAAGCGGAGGCACTCGGAAGGTAAGTGGCTAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2785</th>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>AATTATTTTTTTAGGGCCGGGCGCGGTGGCTCACGTCTGTAATCCC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2786</th>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>TGTATTTTTCATGTATGGCCTTTATCATGTTGAGTAAGTTTCTTTC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307506</th>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>TCTGTTGTCATCCTATCATTGACCTGAGATACCAGAGATCGCCAAA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307507</th>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>GGAAAGAGAACACACACCCCAGGTGTCATGCACACCCTCGGAAGAC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307508</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>TTTGGAAAAAGAGATATCCTAGCTCAGGGCAAGCCGTTTGATGGAA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307509</th>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>...</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>TTCAAGCGATTCTCCTGCCTCAGCCTCCCGAGTAGCTGGGATTACA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307510</th>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>...</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>CTGAGCCCAGCACAGCACCAGAGCTTACCCAAGAATTGCAGTTCTT...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5085 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       450 451 452 453 454 455 456 457 458 459  ... 542 543 544 545 546 547  \\\n",
              "2782     T   T   T   T   A   A   C   A   C   A  ...   T   T   T   T   T   T   \n",
              "2783     C   C   T   T   T   G   G   G   G   G  ...   A   A   C   A   G   A   \n",
              "2784     G   G   C   G   C   A   G   G   G   A  ...   G   G   A   T   A   T   \n",
              "2785     A   A   T   T   A   T   T   T   T   T  ...   C   G   A   G   A   C   \n",
              "2786     T   G   T   A   T   T   T   T   T   C  ...   A   T   T   T   C   T   \n",
              "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
              "307506   T   C   T   G   T   T   G   T   C   A  ...   G   T   C   T   G   A   \n",
              "307507   G   G   A   A   A   G   A   G   A   A  ...   T   G   T   G   C   A   \n",
              "307508   T   T   T   G   G   A   A   A   A   A  ...   A   G   A   G   G   G   \n",
              "307509   T   T   C   A   A   G   C   G   A   T  ...   C   A   G   G   G   T   \n",
              "307510   C   T   G   A   G   C   C   C   A   G  ...   T   T   G   C   C   C   \n",
              "\n",
              "       548 549 550                                           Sequence  \n",
              "2782     T   G   A  TTTTAACACAATACTTTAATAAGACACATTTAAACTCAACTTCTGA...  \n",
              "2783     T   C   T  CCTTTGGGGGGCTAATAGCTCCTATATTCATTCAAAGAAGGAATAG...  \n",
              "2784     T   T   A  GGCGCAGGGAAGAGGAAGCGGAGGCACTCGGAAGGTAAGTGGCTAG...  \n",
              "2785     C   A   T  AATTATTTTTTTAGGGCCGGGCGCGGTGGCTCACGTCTGTAATCCC...  \n",
              "2786     T   G   C  TGTATTTTTCATGTATGGCCTTTATCATGTTGAGTAAGTTTCTTTC...  \n",
              "...     ..  ..  ..                                                ...  \n",
              "307506   T   T   T  TCTGTTGTCATCCTATCATTGACCTGAGATACCAGAGATCGCCAAA...  \n",
              "307507   G   A   G  GGAAAGAGAACACACACCCCAGGTGTCATGCACACCCTCGGAAGAC...  \n",
              "307508   C   C   A  TTTGGAAAAAGAGATATCCTAGCTCAGGGCAAGCCGTTTGATGGAA...  \n",
              "307509   T   T   C  TTCAAGCGATTCTCCTGCCTCAGCCTCCCGAGTAGCTGGGATTACA...  \n",
              "307510   A   T   G  CTGAGCCCAGCACAGCACCAGAGCTTACCCAAGAATTGCAGTTCTT...  \n",
              "\n",
              "[5085 rows x 102 columns]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_data_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "hm5C    3207\n",
              "hCm     1878\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_data_filtered.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "EJjCTy9m5BVQ",
        "outputId": "a5b4a34b-0f23-4ff6-cb26-b9aa16851f7e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "y_counts = y_data_filtered.value_counts()\n",
        "colors = cm.tab20(range(len(y_counts)))\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(y_counts.index, y_counts.values , color = colors)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Value counts of each class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTPaFg0d5BVQ",
        "outputId": "794c6077-0e7c-4358-89ff-7d6c7039f921"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6138      AGAGCAAGACCCTGTCTCAAAAAAAAAAAAAGATACACACACACAA...\n",
              "6139      AGCAAACACATCCTTCTACACATGGCAGCAGGAGACAAGTGCCAAG...\n",
              "6140      AGTTGCTTATTCCAGTAACTGTGCTGTTCCACTCTCCCTCTTTCCT...\n",
              "6141      TTAGAATAATAATCTGGATCACTGAGTTGGGAGAGAGACTCTCAGT...\n",
              "6142      GCTCTTTTTTTTCCTTTTGAGATGGAATTTCGCTCTTGTTACCCCA...\n",
              "                                ...                        \n",
              "308706    GGTATGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAGGCCGAG...\n",
              "308707    GCCTGCTTCAGCCAGAGGCCTGCAGCGCCTTCTGCTTCTCCACCGG...\n",
              "308708    GACGGACTCATCTTTGGAACAGGAACCATGGACTCTCAGATCAAGA...\n",
              "308709    GAGGCCTACCCATAATCCAGAGAGGCTTGCCCAGAGGAGGACTACG...\n",
              "308710    GTTCGCGACCCGAGGGGACCGCGGGGGCTGAGGGGAGGGGCCGCGG...\n",
              "Name: Sequence, Length: 2507, dtype: object"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_data_filtered['Sequence']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULG0B0e95BVQ",
        "outputId": "69c76a6c-6b7e-4121-9a88-96d17bf2a5b6"
      },
      "outputs": [],
      "source": [
        "encoded_sequences = [encode_with_k_mer_codon(sequence) for sequence in x_data_filtered['Sequence']]\n",
        "X_encoded = np.array(encoded_sequences)\n",
        "X_encoded_tensor = torch.tensor(X_encoded, dtype=torch.float32)\n",
        "y_encoded = encode_target(y_data_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne-hmuDd5BVR",
        "outputId": "dbebeca1-6b70-4cfd-b2d2-3c011fdfac48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[50., 50., 62.,  ..., 50., 35., 52.],\n",
              "        [ 6., 42., 50.,  ..., 55., 12., 22.],\n",
              "        [17., 44., 30.,  ..., 61., 50., 62.],\n",
              "        ...,\n",
              "        [50., 35., 45.,  ..., 17., 29.,  1.],\n",
              "        [43., 11., 60.,  ..., 34., 50., 43.],\n",
              "        [25., 52., 39.,  ...,  1.,  2., 33.]])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_encoded_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etAEiUuL5BVR",
        "outputId": "3ce21d47-4199-4911-83b0-a095d1ceda83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generate Train and Split..\n"
          ]
        }
      ],
      "source": [
        "print(\"Generate Train and Split..\")\n",
        "# Train set\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Test and Validation set\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxuA3OdC5BVR",
        "outputId": "0df4344b-8c3a-4fbc-c67b-4973076f8446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Y Count :  Counter({0: 2266, 1: 1293})\n",
            "Test Y Count :  Counter({0: 457, 1: 306})\n"
          ]
        }
      ],
      "source": [
        "X_encoded = None\n",
        "y_encoded = None\n",
        "x_data_filtered , y_data_filtered = None,None\n",
        "x_data , y_data = None , None\n",
        "\n",
        "print(\"Train Y Count : \" ,Counter(y_train))\n",
        "print(\"Test Y Count : \" ,Counter(y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zb-kIy35BVR"
      },
      "source": [
        "### Balance Datset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "3tEqKJG25BVR"
      },
      "outputs": [],
      "source": [
        "y_train = torch.tensor(y_train , dtype=torch.long)\n",
        "y_test = torch.tensor(y_test , dtype=torch.long)\n",
        "y_valid = torch.tensor(y_valid , dtype=torch.long)\n",
        "\n",
        "sm = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
        "y_resampled = torch.tensor(y_resampled , dtype=torch.float32) # Keeping float32\n",
        "X_resampled = torch.tensor(X_resampled , dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpftneeP5BVR",
        "outputId": "45c7f234-7cba-475a-85a2-a23c25c9aa29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([96722, 99])\n",
            "torch.Size([96722])\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM0C9uYE5BVS",
        "outputId": "3cb2f8f6-abd9-44f5-81d6-5d71e9a1162b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([54., 61., 43., 22., 42., 62., 32., 12., 13.,  1.,  2., 61., 43., 22.,\n",
              "        25., 28., 29.,  1.,  2., 61., 43., 22., 25., 28., 18.,  2., 12., 13.,\n",
              "         6., 42., 50., 62., 47., 48.,  9., 27., 45., 51., 53., 59., 37.,  2.,\n",
              "        61., 50., 62.,  8., 20., 17., 29.,  1.,  2., 61., 50., 62., 32.,  3.,\n",
              "        32., 61., 43., 11., 60., 59., 37.,  2., 61., 62.,  8.,  9., 46., 32.,\n",
              "        61., 35., 52., 53., 63., 63., 48.,  9., 27., 52., 39., 20., 21., 46.,\n",
              "         4., 58., 14., 22., 42., 43., 22.,  7., 32., 61., 43., 11., 36., 58.,\n",
              "        25.])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_resampled[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "pIOzPJWY5BVS"
      },
      "outputs": [],
      "source": [
        "hyperparameter = {}\n",
        "hyperparameter['INPUT_DIMENSION'] = len(kmer_dict) # For One Hot Encoding Input Dimension would be 4 as there only 4 unique nucleocide\n",
        "hyperparameter['HIDDEN_DIMENSION'] = 32\n",
        "hyperparameter['NO_OF_LAYERS'] = 2\n",
        "hyperparameter['BATCH_SIZE'] = 32\n",
        "hyperparameter['OUTPUT_DIMENSION'] = len(eligible_class_list)\n",
        "hyperparameter['EMBEDDING_DIMENSION'] = 16 # if you are using Word2Vec Encoding then this should be same as Word2Vec Embedding Dim\n",
        "hyperparameter['DROP_OUT'] = 0.1\n",
        "hyperparameter['LEARNING_RATE'] = 0.0001\n",
        "\n",
        "\n",
        "class RNADataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "\n",
        "train_dataset = RNADataset(X_resampled, y_resampled)\n",
        "test_dataset = RNADataset(X_test, y_test)\n",
        "valid_dataset = RNADataset(X_valid, y_valid)\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "sXVdBroi5BVS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNATransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, output_dim, dropout=0.5):\n",
        "        super(RNATransformerModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "\n",
        "        # If batch size first is true then it should be batch size , sequence lenght , embedding dimension\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=8, dim_feedforward=hidden_dim , batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.long()\n",
        "        #print(\"Shape of Original X  \", x.shape)\n",
        "        x_embedded = self.embedding(x)\n",
        "        #print(\"Shape of X embedded\" , x_embedded.shape)\n",
        "        x_transformed = self.transformer_encoder(x_embedded)\n",
        "        #print(\"Shape of Transformed X\" , x_transformed.shape)\n",
        "        x_transformed = x_transformed[:, -1, :]  # taking the last token's output\n",
        "\n",
        "        output = self.dropout(x_transformed)\n",
        "        out = self.fc(output)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sP484k65BVS",
        "outputId": "1bf3a3f4-e539-4b89-8f0c-3918db6732ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 99])\n"
          ]
        }
      ],
      "source": [
        "# Check data is in correct shape - batch size , sequece len , embedding dimension size\n",
        "for inputs, labels in train_dataloader:\n",
        "    print(inputs.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "-t8RdUvy5BVS"
      },
      "outputs": [],
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "\n",
        "def validate_model(model, test_dataloader , device ,loss_function):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    class_correct = [0] * hyperparameter['OUTPUT_DIMENSION']\n",
        "    class_total = [0] * hyperparameter['OUTPUT_DIMENSION']\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            true_labels.extend(labels.cpu().numpy())  # Capture True Lables for Summary Report\n",
        "            predicted_labels.extend(predicted.cpu().numpy()) # Capture Predicted Labels Lables for Summary Report\n",
        "\n",
        "    validation_loss = running_loss / len(test_dataloader)\n",
        "    validation_accuracy = correct / total\n",
        "\n",
        "    return validation_loss , validation_accuracy , true_labels , predicted_labels\n",
        "\n",
        "\n",
        "def train_model(model, train_dataloader, test_dataloader, device, epochs, optimizer, loss_function):\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement_count = 0\n",
        "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) \n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_dataloader)\n",
        "        val_loss,  validation_accuracy , true_labels , predicted_labels = validate_model(model, test_dataloader, device, loss_function)\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Test Accuracy: {validation_accuracy:.4f} ,Learning Rate: {optimizer.param_groups[0]['lr']} , Time Taken : {elapsed_time}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement_count = 0\n",
        "        else:\n",
        "            no_improvement_count += 1\n",
        "            if no_improvement_count == 5:\n",
        "                print(\"No improvement in validation loss for 5 epochs. Training stopped.\")\n",
        "                break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7wtvOzF5BVS",
        "outputId": "ea97784b-22dc-4b48-f2c6-30f3f397fce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Number of Parameters for Model Training : 14882 \n",
            "Model Parameters  :  {'INPUT_DIMENSION': 94, 'HIDDEN_DIMENSION': 32, 'NO_OF_LAYERS': 2, 'BATCH_SIZE': 32, 'OUTPUT_DIMENSION': 2, 'EMBEDDING_DIMENSION': 16, 'DROP_OUT': 0.1, 'LEARNING_RATE': 0.0001}\n",
            "Epoch 1, Train Loss: 0.7474, Val Loss: 0.7315, Test Accuracy: 0.4626 ,Learning Rate: 0.0001 , Time Taken : 19.985374927520752\n",
            "Epoch 2, Train Loss: 0.7155, Val Loss: 0.7080, Test Accuracy: 0.4823 ,Learning Rate: 0.0001 , Time Taken : 20.00195574760437\n",
            "Epoch 3, Train Loss: 0.7049, Val Loss: 0.7094, Test Accuracy: 0.4626 ,Learning Rate: 0.0001 , Time Taken : 20.482758045196533\n",
            "Epoch 4, Train Loss: 0.7026, Val Loss: 0.7014, Test Accuracy: 0.4731 ,Learning Rate: 0.0001 , Time Taken : 20.425384283065796\n",
            "Epoch 5, Train Loss: 0.7015, Val Loss: 0.6957, Test Accuracy: 0.4902 ,Learning Rate: 0.0001 , Time Taken : 20.11075448989868\n",
            "Epoch 6, Train Loss: 0.7030, Val Loss: 0.6977, Test Accuracy: 0.4836 ,Learning Rate: 5e-05 , Time Taken : 19.835322380065918\n",
            "Epoch 7, Train Loss: 0.6969, Val Loss: 0.6967, Test Accuracy: 0.4849 ,Learning Rate: 5e-05 , Time Taken : 19.76147484779358\n",
            "Epoch 8, Train Loss: 0.6958, Val Loss: 0.6959, Test Accuracy: 0.4875 ,Learning Rate: 5e-05 , Time Taken : 19.886401176452637\n",
            "Epoch 9, Train Loss: 0.6997, Val Loss: 0.6989, Test Accuracy: 0.4810 ,Learning Rate: 5e-05 , Time Taken : 19.80041813850403\n",
            "Epoch 10, Train Loss: 0.6995, Val Loss: 0.6960, Test Accuracy: 0.4902 ,Learning Rate: 5e-05 , Time Taken : 61.256760120391846\n",
            "No improvement in validation loss for 5 epochs. Training stopped.\n"
          ]
        }
      ],
      "source": [
        "model = RNATransformerModel(input_dim=hyperparameter['INPUT_DIMENSION'],\n",
        "                            embedding_dim=hyperparameter['EMBEDDING_DIMENSION'],\n",
        "                            hidden_dim=hyperparameter['HIDDEN_DIMENSION'] ,\n",
        "                            num_layers = hyperparameter['NO_OF_LAYERS'],\n",
        "                            output_dim=hyperparameter['OUTPUT_DIMENSION'],\n",
        "                            dropout=hyperparameter['DROP_OUT'] )\n",
        "\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()  ## MSELoss of Regression problem  # BCELoss for binary classification\n",
        "optimizer = optim.Adam(model.parameters() ,  lr=hyperparameter['LEARNING_RATE'])\n",
        "\n",
        "# Number of Parameters for Model\n",
        "total_parameters = []\n",
        "for p in model.parameters():\n",
        "    total_parameters.append(p.numel())\n",
        "\n",
        "print(f\"Total Number of Parameters for Model Training : { sum(total_parameters)} \" )\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Model Parameters  : \" , hyperparameter)\n",
        "\n",
        "# Train Model with configured Parameter\n",
        "train_model(model, train_dataloader ,test_dataloader, device ,num_epochs,optimizer,loss_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optuna Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    hyperparameter = {}\n",
        "    hyperparameter['INPUT_DIMENSION'] = len(kmer_dict)\n",
        "    hyperparameter['HIDDEN_DIMENSION'] = trial.suggest_int('HIDDEN_DIMENSION', 16, 128)\n",
        "    hyperparameter['NO_OF_LAYERS'] = trial.suggest_int('NO_OF_LAYERS', 1, 4)\n",
        "    hyperparameter['BATCH_SIZE'] = trial.suggest_categorical('BATCH_SIZE', [16, 32, 64])\n",
        "    hyperparameter['OUTPUT_DIMENSION'] = 5\n",
        "    hyperparameter['EMBEDDING_DIMENSION'] = 16  # Adjust as needed\n",
        "    hyperparameter['DROP_OUT'] = trial.suggest_float('DROP_OUT', 0.1, 0.5)\n",
        "    hyperparameter['LEARNING_RATE'] = trial.suggest_loguniform('LEARNING_RATE', 1e-5, 1e-3)\n",
        "\n",
        "    model = RNATransformerModel(input_dim=hyperparameter['INPUT_DIMENSION'],\n",
        "                                embedding_dim=hyperparameter['EMBEDDING_DIMENSION'],\n",
        "                                hidden_dim=hyperparameter['HIDDEN_DIMENSION'],\n",
        "                                num_layers=hyperparameter['NO_OF_LAYERS'],\n",
        "                                output_dim=hyperparameter['OUTPUT_DIMENSION'],\n",
        "                                dropout=hyperparameter['DROP_OUT'])\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=hyperparameter['LEARNING_RATE'])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size=hyperparameter['BATCH_SIZE'], shuffle=False)\n",
        "\n",
        "\n",
        "    train_model(model, train_dataloader ,test_dataloader, device ,num_epochs,optimizer,loss_function)\n",
        "\n",
        "    _, final_accuracy, true_labels, predicted_labels = validate_model(model, valid_dataloader,device,loss_function)\n",
        "\n",
        "    return final_accuracy\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "    # Print the result\n",
        "trial = study.best_trial\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8rs97X-5BVS",
        "outputId": "26c46104-dafe-484d-85e8-8d51bb5c00ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Accuracy: 0.5229\n",
            "\n",
            " Classification Summary:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.53      0.59       484\n",
            "           1       0.38      0.51      0.44       279\n",
            "\n",
            "    accuracy                           0.52       763\n",
            "   macro avg       0.52      0.52      0.51       763\n",
            "weighted avg       0.55      0.52      0.53       763\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "_, final_accuracy, true_labels, predicted_labels = validate_model(model, valid_dataloader,device,loss_function)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "# Print the classification summary\n",
        "print(\"\\n Classification Summary:\")\n",
        "print(classification_report(true_labels, predicted_labels))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c230947687a8f3ffad2ce5baec6aac89e01c839661a42aacfb7c80a5442a49ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
